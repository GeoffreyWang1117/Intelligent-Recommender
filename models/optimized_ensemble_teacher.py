#!/usr/bin/env python3
"""
åŸºäºæœ€æ–°è¯„ä¼°ç»“æœçš„ä¼˜åŒ–Ensembleæ¨èå™¨

ç»“åˆSVD(æœ€ä½³æ¨èè´¨é‡) + xDeepFM(æœ€ä½³é¢„æµ‹ç²¾åº¦) + AutoInt(ç»¼åˆå‡è¡¡)
æ„å»ºé«˜æ€§èƒ½Teacheræ¨¡å‹ï¼Œä¸ºåç»­Fisherä¿¡æ¯åˆ†æå’ŒçŸ¥è¯†è’¸é¦åšå‡†å¤‡ã€‚

æ ¸å¿ƒä¼˜åŠ¿:
- åŸºäºçœŸå®æ€§èƒ½æ•°æ®çš„ç®—æ³•é€‰æ‹©å’Œæƒé‡åˆ†é…
- å¤šä»»åŠ¡èåˆï¼šæ’åº + è¯„åˆ†é¢„æµ‹ + ç‰¹å¾å­¦ä¹ 
- ä¸ºFisher Analysisæä¾›å¼ºTeacheræ¨¡å‹
"""

import numpy as np
import pandas as pd
import logging
from typing import List, Dict, Any, Optional, Tuple
import pickle
import os
from pathlib import Path

logger = logging.getLogger(__name__)


class OptimizedEnsembleTeacher:
    """åŸºäºè¯„ä¼°ç»“æœä¼˜åŒ–çš„é›†æˆæ•™å¸ˆæ¨¡å‹"""
    
    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–ä¼˜åŒ–é›†æˆæ¨èå™¨
        
        åŸºäºæœ€æ–°è¯„ä¼°ç»“æœçš„æœ€ä½³ç®—æ³•ç»„åˆ:
        - SVD: æ¨èè´¨é‡æœ€ä½³ (Recall@10: 0.030, NDCG@10: 0.128)
        - xDeepFM: è¯„åˆ†é¢„æµ‹æœ€ä½³ (RMSE: 0.491, MAE: 0.256)  
        - AutoInt: ç»¼åˆæ€§èƒ½å‡è¡¡ (Recall@10: 0.007, RMSE: 0.517)
        """
        # åŸºäºè¯„ä¼°ç»“æœçš„ç®—æ³•é…ç½®
        self.algorithm_config = {
            'svd': {
                'weight': 0.4,           # æ¨èè´¨é‡æœ€ä½³ï¼Œæƒé‡æœ€é«˜
                'primary_task': 'ranking',  # ä¸»è¦è´Ÿè´£æ’åºæ¨è
                'model_path': 'models/saved/SVD_real_movielens.pkl',
                'performance': {
                    'recall_10': 0.030,
                    'precision_10': 0.126, 
                    'ndcg_10': 0.128,
                    'speed': 0.2  # ç§’
                }
            },
            'xdeepfm': {
                'weight': 0.4,           # é¢„æµ‹ç²¾åº¦æœ€ä½³ï¼Œæƒé‡æœ€é«˜
                'primary_task': 'rating',   # ä¸»è¦è´Ÿè´£è¯„åˆ†é¢„æµ‹
                'model_path': 'models/saved/xDeepFM_real_movielens.pkl',
                'performance': {
                    'rmse': 0.491,
                    'mae': 0.256,
                    'speed': 131.9  # ç§’
                }
            },
            'autoint': {
                'weight': 0.2,           # ç»¼åˆå‡è¡¡ï¼Œè¡¥å……æƒé‡
                'primary_task': 'balance',  # å¢å¼ºé²æ£’æ€§
                'model_path': 'models/saved/AutoInt_real_movielens.pkl', 
                'performance': {
                    'recall_10': 0.007,
                    'rmse': 0.517,
                    'speed': 1012.6  # ç§’
                }
            }
        }
        
        self.models = {}
        self.is_trained = False
        self.feature_importance = {}
        self.ensemble_stats = {}
        
        # å¤šä»»åŠ¡èåˆå‚æ•°
        self.task_weights = kwargs.get('task_weights', {
            'ranking': 0.5,    # æ’åºä»»åŠ¡æƒé‡
            'rating': 0.4,     # è¯„åˆ†é¢„æµ‹æƒé‡
            'diversity': 0.1   # å¤šæ ·æ€§æƒé‡
        })
        
        logger.info("åˆå§‹åŒ–ä¼˜åŒ–é›†æˆæ¨èå™¨")
        logger.info("ç®—æ³•é…ç½®: %s", list(self.algorithm_config.keys()))
    
    def load_pretrained_models(self) -> bool:
        """åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹"""
        logger.info("åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
        
        success_count = 0
        for algo_name, config in self.algorithm_config.items():
            model_path = Path(config['model_path'])
            
            try:
                if model_path.exists():
                    with open(model_path, 'rb') as f:
                        model = pickle.load(f)
                    
                    self.models[algo_name] = model
                    success_count += 1
                    logger.info(f"âœ“ æˆåŠŸåŠ è½½ {algo_name} æ¨¡å‹")
                else:
                    logger.error(f"âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                    
            except Exception as e:
                logger.error(f"âœ— åŠ è½½æ¨¡å‹å¤±è´¥ {algo_name}: {str(e)}")
        
        if success_count == len(self.algorithm_config):
            self.is_trained = True
            logger.info(f"æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸ: {success_count}/{len(self.algorithm_config)}")
            return True
        else:
            logger.warning(f"éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥: {success_count}/{len(self.algorithm_config)}")
            return False
    
    def get_user_recommendations(self, user_id: int, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·æ¨è
        
        å¤šä»»åŠ¡èåˆç­–ç•¥:
        1. SVDæä¾›é«˜è´¨é‡æ’åºå€™é€‰
        2. xDeepFMæä¾›ç²¾ç¡®è¯„åˆ†é¢„æµ‹
        3. AutoIntæä¾›ç‰¹å¾å‡è¡¡è¡¥å……
        """
        if not self.is_trained:
            logger.error("æ¨¡å‹æœªè®­ç»ƒæˆ–åŠ è½½")
            return []
        
        try:
            # æ”¶é›†å„ç®—æ³•çš„æ¨èç»“æœ
            algo_recommendations = {}
            algo_scores = {}
            
            for algo_name, model in self.models.items():
                try:
                    # è·å–æ¨è
                    recs = model.get_user_recommendations(user_id, top_k * 2)  # æ‰©å¤§å€™é€‰é›†
                    algo_recommendations[algo_name] = recs
                    
                    # è½¬æ¢ä¸ºitem_id -> scoreæ˜ å°„
                    scores = {}
                    if recs:
                        if isinstance(recs[0], tuple):
                            scores = {item_id: score for item_id, score in recs}
                        elif isinstance(recs[0], dict):
                            scores = {rec.get('item_id', 0): rec.get('score', 0.0) for rec in recs}
                    
                    algo_scores[algo_name] = scores
                    
                except Exception as e:
                    logger.debug(f"ç®—æ³• {algo_name} æ¨èå¤±è´¥: {str(e)}")
                    algo_recommendations[algo_name] = []
                    algo_scores[algo_name] = {}
            
            # å¤šä»»åŠ¡èåˆç­–ç•¥
            final_scores = self._fuse_recommendations(algo_scores, user_id)
            
            # ç”Ÿæˆæœ€ç»ˆæ¨è
            final_recommendations = []
            for item_id, score in sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]:
                rec = {
                    'item_id': int(item_id),
                    'score': float(score),
                    'explanation': self._generate_explanation(user_id, item_id, algo_scores),
                    'algorithm_details': {
                        algo: {'score': float(algo_scores[algo].get(item_id, 0.0)), 
                               'weight': self.algorithm_config[algo]['weight']}
                        for algo in self.algorithm_config.keys()
                        if item_id in algo_scores.get(algo, {})
                    }
                }
                final_recommendations.append(rec)
            
            return final_recommendations
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¨èå¤±è´¥: {str(e)}")
            return []
    
    def _fuse_recommendations(self, algo_scores: Dict[str, Dict[int, float]], user_id: int) -> Dict[int, float]:
        """
        å¤šä»»åŠ¡æ¨èèåˆ
        
        èåˆç­–ç•¥:
        1. åŸºäºä»»åŠ¡æƒé‡çš„åŠ æƒèåˆ
        2. è€ƒè™‘ç®—æ³•ç‰¹é•¿åˆ†é…ä»»åŠ¡
        3. åŠ å…¥å¤šæ ·æ€§å’Œæ–°é¢–æ€§è°ƒèŠ‚
        """
        all_items = set()
        for scores in algo_scores.values():
            all_items.update(scores.keys())
        
        final_scores = {}
        
        for item_id in all_items:
            # ä»»åŠ¡ç‰¹å®šå¾—åˆ†è®¡ç®—
            ranking_score = 0.0
            rating_score = 0.0
            balance_score = 0.0
            
            # SVDè´¡çŒ® - ä¸»è¦è´Ÿè´£æ’åº
            if 'svd' in algo_scores and item_id in algo_scores['svd']:
                svd_score = algo_scores['svd'][item_id]
                ranking_score += svd_score * self.algorithm_config['svd']['weight']
            
            # xDeepFMè´¡çŒ® - ä¸»è¦è´Ÿè´£è¯„åˆ†é¢„æµ‹
            if 'xdeepfm' in algo_scores and item_id in algo_scores['xdeepfm']:
                xdeepfm_score = algo_scores['xdeepfm'][item_id]
                rating_score += xdeepfm_score * self.algorithm_config['xdeepfm']['weight']
            
            # AutoIntè´¡çŒ® - ç»¼åˆå‡è¡¡
            if 'autoint' in algo_scores and item_id in algo_scores['autoint']:
                autoint_score = algo_scores['autoint'][item_id]
                balance_score += autoint_score * self.algorithm_config['autoint']['weight']
            
            # å¤šä»»åŠ¡èåˆ
            final_score = (
                ranking_score * self.task_weights['ranking'] +
                rating_score * self.task_weights['rating'] +
                balance_score * (1 - self.task_weights['ranking'] - self.task_weights['rating'])
            )
            
            # å¤šæ ·æ€§è°ƒèŠ‚ï¼ˆå¯é€‰ï¼‰
            diversity_bonus = self._calculate_diversity_bonus(item_id, user_id)
            final_score += diversity_bonus * self.task_weights.get('diversity', 0.1)
            
            final_scores[item_id] = final_score
        
        return final_scores
    
    def _calculate_diversity_bonus(self, item_id: int, user_id: int) -> float:
        """è®¡ç®—å¤šæ ·æ€§å¥–åŠ±"""
        # ç®€åŒ–çš„å¤šæ ·æ€§è®¡ç®—
        # å®é™…åº”ç”¨ä¸­å¯ä»¥åŸºäºç±»å‹ã€ç‰¹å¾ç­‰è®¡ç®—
        return np.random.uniform(0, 0.1)  # 0-10%çš„éšæœºå¤šæ ·æ€§å¥–åŠ±
    
    def _generate_explanation(self, user_id: int, item_id: int, algo_scores: Dict[str, Dict[int, float]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨èè§£é‡Š"""
        explanation = {
            'primary_reason': '',
            'supporting_factors': [],
            'confidence': 0.0,
            'algorithm_contributions': {}
        }
        
        # åˆ†æå„ç®—æ³•è´¡çŒ®
        contributions = []
        for algo_name, scores in algo_scores.items():
            if item_id in scores:
                score = scores[item_id]
                weight = self.algorithm_config[algo_name]['weight']
                contribution = score * weight
                
                contributions.append((algo_name, contribution, score))
                explanation['algorithm_contributions'][algo_name] = {
                    'score': float(score),
                    'weight': float(weight),
                    'contribution': float(contribution)
                }
        
        # ç¡®å®šä¸»è¦æ¨èç†ç”±
        if contributions:
            # æŒ‰è´¡çŒ®æ’åº
            contributions.sort(key=lambda x: x[1], reverse=True)
            top_algo = contributions[0][0]
            
            if top_algo == 'svd':
                explanation['primary_reason'] = "åŸºäºååŒè¿‡æ»¤çš„é«˜è´¨é‡æ¨è"
                explanation['supporting_factors'].append("æ’åºè´¨é‡æœ€ä½³")
            elif top_algo == 'xdeepfm':
                explanation['primary_reason'] = "åŸºäºæ·±åº¦ç‰¹å¾å­¦ä¹ çš„ç²¾å‡†é¢„æµ‹"
                explanation['supporting_factors'].append("è¯„åˆ†é¢„æµ‹æœ€å‡†ç¡®")
            elif top_algo == 'autoint':
                explanation['primary_reason'] = "åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç»¼åˆæ¨è"
                explanation['supporting_factors'].append("ç‰¹å¾äº¤äº’å‡è¡¡")
            
            # è®¡ç®—ç½®ä¿¡åº¦
            total_contribution = sum(c[1] for c in contributions)
            explanation['confidence'] = min(total_contribution / len(contributions), 1.0)
        
        return explanation
    
    def predict(self, user_id: int, item_id: int) -> float:
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        
        ä¸»è¦ç”±xDeepFMè´Ÿè´£ï¼Œå…¶ä»–ç®—æ³•æä¾›è¾…åŠ©
        """
        if not self.is_trained:
            return 0.0
        
        predictions = []
        weights = []
        
        for algo_name, model in self.models.items():
            try:
                pred = model.predict(user_id, item_id)
                if pred is not None and not np.isnan(pred):
                    predictions.append(pred)
                    
                    # xDeepFMåœ¨è¯„åˆ†é¢„æµ‹ä¸Šæƒé‡æ›´é«˜
                    if algo_name == 'xdeepfm':
                        weights.append(0.6)  # è¯„åˆ†é¢„æµ‹ä¸»å¯¼
                    elif algo_name == 'autoint':
                        weights.append(0.3)  # è¾…åŠ©é¢„æµ‹
                    else:  # svdè¯„åˆ†é¢„æµ‹è¾ƒå¼±
                        weights.append(0.1)  # æœ€å°æƒé‡
                        
            except Exception as e:
                logger.debug(f"ç®—æ³• {algo_name} é¢„æµ‹å¤±è´¥: {str(e)}")
        
        if predictions:
            # åŠ æƒå¹³å‡
            weights = np.array(weights)
            weights = weights / weights.sum()  # å½’ä¸€åŒ–
            return float(np.average(predictions, weights=weights))
        else:
            return 3.0  # é»˜è®¤è¯„åˆ†
    
    def get_model_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹æ€§èƒ½æ‘˜è¦"""
        return {
            'algorithm_config': self.algorithm_config,
            'task_weights': self.task_weights,
            'models_loaded': list(self.models.keys()),
            'ensemble_strategy': {
                'ranking_leader': 'svd',
                'rating_leader': 'xdeepfm', 
                'balance_support': 'autoint',
                'fusion_method': 'weighted_multi_task'
            },
            'expected_performance': {
                'ranking_quality': 'high',      # åŸºäºSVDçš„å¼ºæ’åºèƒ½åŠ›
                'rating_accuracy': 'high',      # åŸºäºxDeepFMçš„å¼ºé¢„æµ‹èƒ½åŠ›
                'computational_cost': 'medium', # å¹³è¡¡çš„è®¡ç®—å¼€é”€
                'recommendation_speed': 'fast'  # SVDçš„é«˜æ•ˆæ¨è
            }
        }
    
    def save_ensemble(self, save_path: str) -> bool:
        """ä¿å­˜é›†æˆæ¨¡å‹"""
        try:
            ensemble_data = {
                'algorithm_config': self.algorithm_config,
                'task_weights': self.task_weights,
                'models': self.models,
                'feature_importance': self.feature_importance,
                'ensemble_stats': self.ensemble_stats,
                'is_trained': self.is_trained
            }
            
            with open(save_path, 'wb') as f:
                pickle.dump(ensemble_data, f)
            
            logger.info(f"é›†æˆæ¨¡å‹å·²ä¿å­˜: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜é›†æˆæ¨¡å‹å¤±è´¥: {str(e)}")
            return False
    
    def load_ensemble(self, load_path: str) -> bool:
        """åŠ è½½é›†æˆæ¨¡å‹"""
        try:
            with open(load_path, 'rb') as f:
                ensemble_data = pickle.load(f)
            
            self.algorithm_config = ensemble_data['algorithm_config']
            self.task_weights = ensemble_data['task_weights']
            self.models = ensemble_data['models']
            self.feature_importance = ensemble_data.get('feature_importance', {})
            self.ensemble_stats = ensemble_data.get('ensemble_stats', {})
            self.is_trained = ensemble_data['is_trained']
            
            logger.info(f"é›†æˆæ¨¡å‹å·²åŠ è½½: {load_path}")
            return True
            
        except Exception as e:
            logger.error(f"åŠ è½½é›†æˆæ¨¡å‹å¤±è´¥: {str(e)}")
            return False


def main():
    """æµ‹è¯•ä¼˜åŒ–é›†æˆæ¨èå™¨"""
    # åˆ›å»ºé›†æˆæ¨èå™¨
    ensemble = OptimizedEnsembleTeacher()
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    if ensemble.load_pretrained_models():
        logger.info("âœ… ä¼˜åŒ–é›†æˆæ¨èå™¨å‡†å¤‡å°±ç»ª")
        
        # æµ‹è¯•æ¨è
        test_user_id = 1
        recommendations = ensemble.get_user_recommendations(test_user_id, top_k=5)
        
        print(f"\nğŸ¯ ç”¨æˆ· {test_user_id} çš„æ¨èç»“æœ:")
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. ç‰©å“ {rec['item_id']}: åˆ†æ•° {rec['score']:.3f}")
            print(f"   æ¨èç†ç”±: {rec['explanation']['primary_reason']}")
            print(f"   ç®—æ³•è´¡çŒ®: {list(rec['algorithm_details'].keys())}")
        
        # è¾“å‡ºæ€§èƒ½æ‘˜è¦
        summary = ensemble.get_model_performance_summary()
        print(f"\nğŸ“Š é›†æˆæ¨¡å‹æ€§èƒ½æ‘˜è¦:")
        print(f"   æ’åºé¢†å¯¼è€…: {summary['ensemble_strategy']['ranking_leader']}")
        print(f"   è¯„åˆ†é¢†å¯¼è€…: {summary['ensemble_strategy']['rating_leader']}")
        print(f"   é¢„æœŸæ€§èƒ½: {summary['expected_performance']}")
        
    else:
        logger.error("âŒ ä¼˜åŒ–é›†æˆæ¨èå™¨åˆå§‹åŒ–å¤±è´¥")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()
