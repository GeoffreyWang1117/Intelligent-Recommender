#!/usr/bin/env python3
"""
Amazon Reviews 2023 æ•°æ®ä¸‹è½½å™¨
ä½¿ç”¨datasetsåº“ä¸‹è½½å¹¶ä¿å­˜ä¸ºparquetæ ¼å¼

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-08-27
"""

import pandas as pd
from pathlib import Path
import time

# å¯¼å…¥datasetsåº“
try:
    from datasets import load_dataset
    DATASETS_AVAILABLE = True
except ImportError:
    DATASETS_AVAILABLE = False
    print("âŒ datasetsåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install datasets")

class AmazonDataDownloader:
    """Amazon Reviews 2023æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        # é¡¹ç›®æ ¹ç›®å½•å’Œæ•°æ®ç›®å½•
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data" / "amazon"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Amazon Reviews 2023ä¸»è¦ç±»åˆ«
        self.main_categories = [
            "All_Beauty",
            "Amazon_Fashion", 
            "Arts_Crafts_and_Sewing",
            "Automotive",
            "Books",
            "CDs_and_Vinyl",
            "Cell_Phones_and_Accessories",
            "Clothing_Shoes_and_Jewelry",
            "Electronics",
            "Gift_Cards",
            "Grocery_and_Gourmet_Food",
            "Health_and_Household",
            "Home_and_Kitchen",
            "Industrial_and_Scientific",
            "Kindle_Store",
            "Movies_and_TV",
            "Musical_Instruments",
            "Office_Products",
            "Patio_Lawn_and_Garden",
            "Pet_Supplies",
            "Sports_and_Outdoors",
            "Tools_and_Home_Improvement",
            "Toys_and_Games",
            "Video_Games"
        ]
    
    def download_category(self, category: str) -> bool:
        """ä¸‹è½½å•ä¸ªç±»åˆ«çš„æ•°æ®
        
        Args:
            category: ç±»åˆ«åç§°
            
        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        if not DATASETS_AVAILABLE:
            print("âŒ datasetsåº“ä¸å¯ç”¨")
            return False
        
        print(f"\nğŸ“š ä¸‹è½½ç±»åˆ«: {category}")
        print("-" * 40)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        reviews_file = self.data_dir / f"{category}_reviews.parquet"
        meta_file = self.data_dir / f"{category}_meta.parquet"
        
        if reviews_file.exists() and meta_file.exists():
            print(f"âœ… {category} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return True
        
        success_count = 0
        
        try:
            # ä¸‹è½½è¯„è®ºæ•°æ®
            if not reviews_file.exists():
                print(f"ğŸ”½ ä¸‹è½½ {category} è¯„è®ºæ•°æ®...")
                dataset_name = f"raw_review_{category}"
                
                dataset = load_dataset(
                    "McAuley-Lab/Amazon-Reviews-2023", 
                    dataset_name,
                    trust_remote_code=True
                )
                
                # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
                df = dataset["full"].to_pandas()
                df.to_parquet(reviews_file, index=False)
                
                print(f"âœ… è¯„è®ºæ•°æ®å·²ä¿å­˜: {len(df):,} æ¡ -> {reviews_file.name}")
                success_count += 1
            else:
                print(f"âœ… è¯„è®ºæ•°æ®å·²å­˜åœ¨: {reviews_file.name}")
                success_count += 1
            
        except Exception as e:
            print(f"âŒ è¯„è®ºæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        
        try:
            # ä¸‹è½½å…ƒæ•°æ®
            if not meta_file.exists():
                print(f"ğŸ”½ ä¸‹è½½ {category} å…ƒæ•°æ®...")
                dataset_name = f"raw_meta_{category}"
                
                dataset = load_dataset(
                    "McAuley-Lab/Amazon-Reviews-2023", 
                    dataset_name,
                    trust_remote_code=True
                )
                
                # è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
                df = dataset["full"].to_pandas()
                df.to_parquet(meta_file, index=False)
                
                print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {len(df):,} æ¡ -> {meta_file.name}")
                success_count += 1
            else:
                print(f"âœ… å…ƒæ•°æ®å·²å­˜åœ¨: {meta_file.name}")
                success_count += 1
                
        except Exception as e:
            print(f"âŒ å…ƒæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
        
        print(f"ğŸ“Š {category} å®Œæˆ: {success_count}/2 ä¸ªæ–‡ä»¶")
        return success_count == 2
    
    def download_main_categories(self, categories=None):
        """ä¸‹è½½ä¸»è¦ç±»åˆ«çš„æ•°æ®
        
        Args:
            categories: è¦ä¸‹è½½çš„ç±»åˆ«åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºå‰10ä¸ªä¸»è¦ç±»åˆ«
        """
        if categories is None:
            categories = [
                "All_Beauty", "Books", "Electronics", "Movies_and_TV", 
                "Home_and_Kitchen", "Sports_and_Outdoors", "Toys_and_Games",
                "Automotive", "Arts_Crafts_and_Sewing", "Office_Products"
            ]
        
        print("ğŸš€ å¼€å§‹ä¸‹è½½Amazon Reviews 2023æ•°æ®")
        print("=" * 50)
        print(f"ğŸ“Š ç›®æ ‡ç±»åˆ«: {len(categories)} ä¸ª")
        print(f"ğŸ’¾ ä¿å­˜ç›®å½•: {self.data_dir}")
        print("=" * 50)
        
        success_count = 0
        
        for i, category in enumerate(categories, 1):
            print(f"\n[{i}/{len(categories)}] å¤„ç†ç±»åˆ«: {category}")
            
            if self.download_category(category):
                success_count += 1
            
            # çŸ­æš‚ä¼‘æ¯
            time.sleep(2)
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ä¸‹è½½æ€»ç»“")
        print("=" * 50)
        print(f"âœ… æˆåŠŸä¸‹è½½: {success_count}/{len(categories)} ä¸ªç±»åˆ«")
        print(f"ğŸ’¾ æ–‡ä»¶ä¿å­˜åœ¨: {self.data_dir}")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        self.list_downloaded_files()
    
    def download_all_categories(self):
        """ä¸‹è½½æ‰€æœ‰æ”¯æŒçš„ç±»åˆ«"""
        print("ğŸš€ ä¸‹è½½æ‰€æœ‰Amazon Reviews 2023ç±»åˆ«")
        print("=" * 50)
        print(f"ğŸ“Š æ€»ç±»åˆ«æ•°: {len(self.main_categories)}")
        print("âš ï¸  è¿™å°†ä¸‹è½½å¤§é‡æ•°æ®ï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´")
        print("=" * 50)
        
        confirm = input("ç¡®è®¤ä¸‹è½½æ‰€æœ‰ç±»åˆ«? (y/N): ").strip().lower()
        if confirm != 'y':
            print("âŒ å–æ¶ˆä¸‹è½½")
            return
        
        self.download_main_categories(self.main_categories)
    
    def list_downloaded_files(self):
        """åˆ—å‡ºå·²ä¸‹è½½çš„æ–‡ä»¶"""
        print("\nğŸ“‹ å·²ä¸‹è½½çš„æ–‡ä»¶:")
        print("-" * 40)
        
        parquet_files = list(self.data_dir.glob("*.parquet"))
        
        if not parquet_files:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°parquetæ–‡ä»¶")
            return
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        categories = set()
        for file in parquet_files:
            if "_reviews.parquet" in file.name:
                category = file.name.replace("_reviews.parquet", "")
                categories.add(category)
            elif "_meta.parquet" in file.name:
                category = file.name.replace("_meta.parquet", "")
                categories.add(category)
        
        total_size = 0
        for category in sorted(categories):
            review_file = self.data_dir / f"{category}_reviews.parquet"
            meta_file = self.data_dir / f"{category}_meta.parquet"
            
            review_size = review_file.stat().st_size if review_file.exists() else 0
            meta_size = meta_file.stat().st_size if meta_file.exists() else 0
            
            review_mb = review_size / (1024*1024)
            meta_mb = meta_size / (1024*1024)
            
            status = "âœ…" if review_file.exists() and meta_file.exists() else "âš ï¸ "
            
            print(f"   {status} {category}:")
            if review_file.exists():
                print(f"      ğŸ“Š reviews: {review_mb:.1f} MB")
            if meta_file.exists():
                print(f"      ğŸ·ï¸  meta: {meta_mb:.1f} MB")
            
            total_size += review_size + meta_size
        
        print("-" * 40)
        print(f"ğŸ“Š æ€»å¤§å°: {total_size/(1024*1024):.1f} MB")
    
    def verify_files(self):
        """éªŒè¯ä¸‹è½½çš„æ–‡ä»¶"""
        print("\nğŸ” éªŒè¯Parquetæ–‡ä»¶:")
        print("-" * 30)
        
        parquet_files = list(self.data_dir.glob("*.parquet"))
        valid_count = 0
        
        for file in parquet_files:
            try:
                df = pd.read_parquet(file)
                print(f"âœ… {file.name}: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")
                valid_count += 1
            except Exception as e:
                print(f"âŒ {file.name}: è¯»å–å¤±è´¥ - {e}")
        
        print("-" * 30)
        print(f"ğŸ“Š éªŒè¯ç»“æœ: {valid_count}/{len(parquet_files)} ä¸ªæ–‡ä»¶æœ‰æ•ˆ")

def main():
    """ä¸»å‡½æ•°"""
    downloader = AmazonDataDownloader()
    
    print("Amazon Reviews 2023 æ•°æ®ä¸‹è½½å™¨")
    print("1. ä¸‹è½½ä¸»è¦ç±»åˆ« (æ¨è)")
    print("2. ä¸‹è½½æ‰€æœ‰ç±»åˆ«")
    print("3. ä¸‹è½½å•ä¸ªç±»åˆ«")
    print("4. æŸ¥çœ‹å·²ä¸‹è½½æ–‡ä»¶")
    print("5. éªŒè¯æ–‡ä»¶")
    
    choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
    
    if choice == "1":
        # ä¸‹è½½ä¸»è¦ç±»åˆ«
        downloader.download_main_categories()
    
    elif choice == "2":
        # ä¸‹è½½æ‰€æœ‰ç±»åˆ«
        downloader.download_all_categories()
    
    elif choice == "3":
        # ä¸‹è½½å•ä¸ªç±»åˆ«
        print(f"\nå¯é€‰ç±»åˆ«:")
        for i, cat in enumerate(downloader.main_categories[:15], 1):
            print(f"{i:2d}. {cat}")
        if len(downloader.main_categories) > 15:
            print(f"    ... è¿˜æœ‰ {len(downloader.main_categories) - 15} ä¸ªç±»åˆ«")
        
        category = input("\nè¾“å…¥ç±»åˆ«åç§°: ").strip()
        if category in downloader.main_categories:
            downloader.download_category(category)
        else:
            print("âŒ æ— æ•ˆç±»åˆ«")
    
    elif choice == "4":
        # æŸ¥çœ‹å·²ä¸‹è½½æ–‡ä»¶
        downloader.list_downloaded_files()
    
    elif choice == "5":
        # éªŒè¯æ–‡ä»¶
        downloader.verify_files()
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()
