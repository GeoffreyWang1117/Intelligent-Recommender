#!/usr/bin/env python3
"""
å®Œæ•´çš„6ä¸ªTeacheræ¨¡å‹CUDAå®éªŒ - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬
ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½èƒ½æ­£ç¡®ç”Ÿæˆæ¨èå¹¶å‚ä¸ä¸€è‡´æ€§åˆ†æ
åŒ…å«æœ€æ–°çš„é”™è¯¯ä¿®å¤å’Œæ¥å£ç»Ÿä¸€
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import time
import logging
from typing import Dict, List
from collections import defaultdict
import traceback

# CUDAä¼˜åŒ–è®¾ç½®
import torch
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

from models import create_recommender

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def simple_jaccard_similarity(set1: set, set2: set) -> float:
    """è®¡ç®—Jaccardç›¸ä¼¼åº¦"""
    if not set1 and not set2:
        return 1.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0.0


def check_cuda_environment():
    """æ£€æŸ¥CUDAç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥CUDAç¯å¢ƒ...")
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
            print(f"   æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
        
        torch.cuda.empty_cache()
        
        try:
            test_tensor = torch.randn(100, 100).cuda()
            result = torch.mm(test_tensor, test_tensor.t())
            del test_tensor, result
            torch.cuda.empty_cache()
            print("   âœ… CUDAåŸºæœ¬æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"   âŒ CUDAæµ‹è¯•å¤±è´¥: {e}")
            return False
    else:
        print("   âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False
    
    return True


def test_model_recommendation(model, model_name: str, test_user_ids: List[int]) -> Dict:
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„æ¨èåŠŸèƒ½"""
    print(f"ğŸ” æµ‹è¯• {model_name} çš„æ¨èåŠŸèƒ½...")
    
    success_count = 0
    error_count = 0
    sample_recommendations = []
    errors = []
    
    for user_id in test_user_ids[:10]:  # å…ˆæµ‹è¯•10ä¸ªç”¨æˆ·
        try:
            recs = model.get_user_recommendations(user_id, top_k=5)
            if recs and len(recs) > 0:
                success_count += 1
                if len(sample_recommendations) < 3:
                    sample_recommendations.append((user_id, recs[:2]))
            else:
                error_count += 1
                errors.append(f"ç”¨æˆ·{user_id}: ç©ºæ¨è")
        except Exception as e:
            error_count += 1
            error_msg = str(e)
            errors.append(f"ç”¨æˆ·{user_id}: {error_msg[:50]}")
            if len(errors) <= 3:  # åªè®°å½•å‰3ä¸ªé”™è¯¯
                print(f"   âš ï¸ ç”¨æˆ·{user_id}æ¨èå¤±è´¥: {error_msg[:50]}")
    
    success_rate = success_count / len(test_user_ids[:10])
    
    result = {
        'success_rate': success_rate,
        'success_count': success_count,
        'error_count': error_count,
        'sample_recommendations': sample_recommendations,
        'errors': errors,
        'working': success_rate > 0.5  # è¶…è¿‡50%æˆåŠŸç‡è®¤ä¸ºå¯ç”¨
    }
    
    if result['working']:
        print(f"   âœ… {model_name} æ¨èåŠŸèƒ½æ­£å¸¸ (æˆåŠŸç‡: {success_rate:.1%})")
        if sample_recommendations:
            print(f"   ğŸ“ æ¨èç¤ºä¾‹: ç”¨æˆ·{sample_recommendations[0][0]} -> {[r.get('item_id', r) for r in sample_recommendations[0][1]]}")
    else:
        print(f"   âŒ {model_name} æ¨èåŠŸèƒ½å¼‚å¸¸ (æˆåŠŸç‡: {success_rate:.1%})")
        if errors:
            print(f"   ğŸ” ä¸»è¦é”™è¯¯: {errors[0]}")
    
    return result


def run_complete_teacher_experiment():
    """è¿è¡Œå®Œæ•´çš„6ä¸ªTeacheræ¨¡å‹å®éªŒ"""
    print("ğŸ“ å®Œæ•´6ä¸ªTeacheræ¨¡å‹CUDAå®éªŒ")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAç¯å¢ƒ
    cuda_available = check_cuda_environment()
    device = torch.device('cuda' if cuda_available else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®
    print("\\nğŸ“Š åˆ›å»ºæ¨¡æ‹Ÿæ¨èæ•°æ®...")
    np.random.seed(42)
    
    num_interactions = 6000 if cuda_available else 3000
    num_users = 250 if cuda_available else 200
    num_items = 200 if cuda_available else 150
    
    interactions = []
    for _ in range(num_interactions):
        user_id = np.random.randint(1, num_users + 1)
        item_id = np.random.randint(1, num_items + 1)
        rating = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        timestamp = int(time.time()) + np.random.randint(-86400*30, 86400*30)
        
        interactions.append({
            'user_id': user_id,
            'item_id': item_id,
            'rating': rating,
            'timestamp': timestamp
        })
    
    train_data = pd.DataFrame(interactions)
    train_data = train_data.drop_duplicates(['user_id', 'item_id'])
    
    print(f"âœ… ç”Ÿæˆäº† {len(train_data)} æ¡å”¯ä¸€äº¤äº’æ•°æ®")
    print(f"   ç”¨æˆ·æ•°: {train_data['user_id'].nunique()}")
    print(f"   ç‰©å“æ•°: {train_data['item_id'].nunique()}")
    
    # 6ä¸ªTeacheræ¨¡å‹é…ç½®
    algorithms = ['deepfm', 'autoint', 'transformer4rec', 'xdeepfm', 'din', 'dcnv2']
    
    if cuda_available:
        model_configs = {
            'deepfm': {
                'embedding_dim': 32,
                'learning_rate': 0.001,
                'epochs': 15,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            },
            'autoint': {
                'embedding_dim': 32,
                'learning_rate': 0.001,
                'epochs': 15,
                'num_heads': 8,
                'num_layers': 4,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            },
            'transformer4rec': {
                'embedding_dim': 64,
                'num_heads': 8,
                'num_layers': 4,
                'learning_rate': 0.001,
                'epochs': 12,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            },
            'xdeepfm': {
                'embedding_dim': 32,
                'cin_layer_sizes': [128, 64],
                'dnn_hidden_dims': [256, 128],
                'learning_rate': 0.001,
                'epochs': 12,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            },
            'din': {
                'embedding_dim': 32,
                'hidden_dims': [256, 128, 64],
                'attention_hidden_dim': 128,
                'learning_rate': 0.001,
                'epochs': 12,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            },
            'dcnv2': {
                'embedding_dim': 32,
                'cross_layers': 4,
                'deep_layers': [256, 128, 64],
                'learning_rate': 0.001,
                'epochs': 12,
                'batch_size': 128,
                'early_stopping': True,
                'patience': 3
            }
        }
    else:
        model_configs = {
            'deepfm': {'embedding_dim': 16, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 64, 'early_stopping': False},
            'autoint': {'embedding_dim': 16, 'learning_rate': 0.001, 'epochs': 10, 'num_heads': 4, 'num_layers': 3, 'early_stopping': False},
            'transformer4rec': {'embedding_dim': 32, 'num_heads': 4, 'num_layers': 3, 'learning_rate': 0.001, 'epochs': 8, 'batch_size': 64, 'early_stopping': False},
            'xdeepfm': {'embedding_dim': 16, 'cin_layer_sizes': [64, 32], 'dnn_hidden_dims': [128, 64], 'learning_rate': 0.001, 'epochs': 8, 'batch_size': 64, 'early_stopping': False},
            'din': {'embedding_dim': 16, 'hidden_dims': [128, 64], 'attention_hidden_dim': 64, 'learning_rate': 0.001, 'epochs': 8, 'batch_size': 64, 'early_stopping': False},
            'dcnv2': {'embedding_dim': 16, 'cross_layers': 3, 'deep_layers': [128, 64], 'learning_rate': 0.001, 'epochs': 8, 'batch_size': 64, 'early_stopping': False}
        }
    
    print(f"\\nğŸ¯ å°†è®­ç»ƒ {len(algorithms)} ä¸ªTeacheræ¨¡å‹:")
    for algo in algorithms:
        print(f"   - {algo}")
    
    # è®­ç»ƒæ¨¡å‹
    trained_models = {}
    training_times = {}
    training_errors = {}
    
    for algo_name in algorithms:
        print(f"\\nğŸ“š è®­ç»ƒTeacheræ¨¡å‹: {algo_name}")
        config = model_configs[algo_name]
        
        try:
            start_time = time.time()
            
            if cuda_available:
                torch.cuda.empty_cache()
            
            model = create_recommender(algo_name, **config)
            
            if model is None:
                print(f"âŒ æ— æ³•åˆ›å»ºç®—æ³•: {algo_name}")
                training_errors[algo_name] = "ç®—æ³•åˆ›å»ºå¤±è´¥"
                continue
            
            if hasattr(model, 'device'):
                model.device = device
            
            try:
                model.fit(train_data, **config)
                end_time = time.time()
                
                training_time = end_time - start_time
                training_times[algo_name] = training_time
                
                if model.is_trained:
                    trained_models[algo_name] = model
                    print(f"âœ… {algo_name} è®­ç»ƒæˆåŠŸ! è€—æ—¶: {training_time:.2f}ç§’")
                else:
                    print(f"âŒ {algo_name} è®­ç»ƒå¤±è´¥ - æ¨¡å‹æœªå®Œæˆè®­ç»ƒ")
                    training_errors[algo_name] = "è®­ç»ƒæœªå®Œæˆ"
                    
            except RuntimeError as e:
                if "CUDA" in str(e) or "out of memory" in str(e):
                    print(f"âš ï¸ {algo_name} CUDAé”™è¯¯ï¼Œå°è¯•CPUæ¨¡å¼...")
                    
                    if cuda_available:
                        torch.cuda.empty_cache()
                    
                    cpu_config = config.copy()
                    cpu_config['batch_size'] = min(cpu_config.get('batch_size', 64), 32)
                    cpu_config['epochs'] = min(cpu_config.get('epochs', 10), 6)
                    
                    model = create_recommender(algo_name, **cpu_config)
                    if hasattr(model, 'device'):
                        model.device = torch.device('cpu')
                    
                    model.fit(train_data, **cpu_config)
                    end_time = time.time()
                    
                    training_time = end_time - start_time
                    training_times[algo_name] = training_time
                    
                    if model.is_trained:
                        trained_models[algo_name] = model
                        print(f"âœ… {algo_name} CPUæ¨¡å¼è®­ç»ƒæˆåŠŸ! è€—æ—¶: {training_time:.2f}ç§’")
                    else:
                        print(f"âŒ {algo_name} CPUæ¨¡å¼ä¹Ÿå¤±è´¥")
                        training_errors[algo_name] = f"CUDAå’ŒCPUéƒ½å¤±è´¥"
                else:
                    raise e
                    
        except Exception as e:
            training_time = time.time() - start_time
            training_times[algo_name] = training_time
            training_errors[algo_name] = f"{type(e).__name__}: {str(e)[:50]}"
            print(f"âŒ è®­ç»ƒ {algo_name} æ—¶å‡ºé”™: {str(e)[:50]}...")
            
            if cuda_available:
                torch.cuda.empty_cache()
    
    print(f"\\nğŸ¯ è®­ç»ƒé˜¶æ®µå®Œæˆ!")
    print(f"   æˆåŠŸè®­ç»ƒ: {len(trained_models)} ä¸ªTeacheræ¨¡å‹")
    print(f"   æˆåŠŸçš„æ¨¡å‹: {list(trained_models.keys())}")
    
    if training_errors:
        print(f"   å¤±è´¥çš„æ¨¡å‹: {list(training_errors.keys())}")
    
    if len(trained_models) < 2:
        print("âŒ è®­ç»ƒæˆåŠŸçš„æ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
        return None
    
    # æµ‹è¯•æ¨èåŠŸèƒ½
    print("\\nğŸ” æµ‹è¯•æ‰€æœ‰æ¨¡å‹çš„æ¨èåŠŸèƒ½...")
    test_users = list(train_data['user_id'].unique())[:50]
    
    working_models = {}
    recommendation_tests = {}
    
    for algo_name, model in trained_models.items():
        test_result = test_model_recommendation(model, algo_name, test_users)
        recommendation_tests[algo_name] = test_result
        
        if test_result['working']:
            working_models[algo_name] = model
    
    print(f"\\nğŸ“Š æ¨èåŠŸèƒ½æµ‹è¯•ç»“æœ:")
    print(f"   å¯ç”¨æ¨¡å‹: {list(working_models.keys())}")
    if len(working_models) != len(trained_models):
        failed_recs = set(trained_models.keys()) - set(working_models.keys())
        print(f"   æ¨èå¤±è´¥: {list(failed_recs)}")
    
    if len(working_models) < 2:
        print("âŒ å¯ç”¨äºæ¨èçš„æ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
        return None
    
    # ç”Ÿæˆæ¨èå¹¶åˆ†æä¸€è‡´æ€§
    print("\\nğŸ“Š ç”Ÿæˆå®Œæ•´æ¨èæ•°æ®é›†...")
    test_users_full = list(train_data['user_id'].unique())[:100 if cuda_available else 50]
    
    all_recommendations = {}
    performance_stats = {}
    
    for algo_name, model in working_models.items():
        print(f"ğŸ” ç”Ÿæˆ {algo_name} çš„æ¨è...")
        
        recommendations = {}
        success_count = 0
        total_rec_count = 0
        error_count = 0
        
        for user_id in test_users_full:
            try:
                recs = model.get_user_recommendations(user_id, top_k=10)
                if recs and len(recs) > 0:
                    # ç¡®ä¿æ¨èæ ¼å¼æ­£ç¡®
                    if isinstance(recs[0], dict) and 'item_id' in recs[0]:
                        rec_items = [rec['item_id'] for rec in recs]
                    elif isinstance(recs[0], tuple):
                        rec_items = [rec[0] for rec in recs]
                    else:
                        rec_items = recs
                    
                    recommendations[user_id] = rec_items
                    success_count += 1
                    total_rec_count += len(rec_items)
            except Exception as e:
                error_count += 1
                continue
        
        if recommendations:
            all_recommendations[algo_name] = recommendations
            performance_stats[algo_name] = {
                'success_rate': success_count / len(test_users_full),
                'avg_rec_length': total_rec_count / success_count if success_count > 0 else 0,
                'total_recommendations': len(recommendations),
                'training_time': training_times.get(algo_name, 0),
                'error_count': error_count
            }
            print(f"   âœ… æˆåŠŸä¸º {len(recommendations)} ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è")
            print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_count/len(test_users_full):.2%}")
            if error_count > 0:
                print(f"   âš ï¸ é”™è¯¯æ•°: {error_count}")
    
    # è®¡ç®—ä¸€è‡´æ€§çŸ©é˜µ
    print("\\nğŸ” è®¡ç®—Teacheræ¨¡å‹é—´ä¸€è‡´æ€§...")
    
    if len(all_recommendations) < 2:
        print("âŒ æ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ - æ¨èç”Ÿæˆå¤±è´¥")
        return None
    
    algorithms_list = list(all_recommendations.keys())
    jaccard_matrix = {}
    
    print(f"ğŸ“Š åˆ†æ {len(algorithms_list)} ä¸ªæ¨¡å‹é—´çš„ä¸€è‡´æ€§:")
    
    for i, algo1 in enumerate(algorithms_list):
        jaccard_matrix[algo1] = {}
        
        for j, algo2 in enumerate(algorithms_list):
            if algo1 == algo2:
                jaccard_matrix[algo1][algo2] = 1.0
            else:
                similarities = []
                
                common_users = set(all_recommendations[algo1].keys()) & set(all_recommendations[algo2].keys())
                
                for user_id in common_users:
                    recs1 = set(all_recommendations[algo1][user_id][:10])
                    recs2 = set(all_recommendations[algo2][user_id][:10])
                    
                    sim = simple_jaccard_similarity(recs1, recs2)
                    similarities.append(sim)
                
                avg_similarity = np.mean(similarities) if similarities else 0.0
                jaccard_matrix[algo1][algo2] = avg_similarity
        
        print(f"   âœ… å®Œæˆ {algo1} çš„ä¸€è‡´æ€§è®¡ç®—")
    
    # åˆ†æç»“æœ
    print("\\nğŸ“ˆ åˆ†æTeacheræ¨¡å‹ä¸€è‡´æ€§ç»“æœ...")
    
    min_jaccard = float('inf')
    max_jaccard = 0.0
    min_pair = None
    max_pair = None
    
    all_similarities = []
    
    for algo1 in algorithms_list:
        for algo2 in algorithms_list:
            if algo1 != algo2:
                similarity = jaccard_matrix[algo1][algo2]
                all_similarities.append(similarity)
                
                if similarity < min_jaccard:
                    min_jaccard = similarity
                    min_pair = (algo1, algo2)
                if similarity > max_jaccard:
                    max_jaccard = similarity
                    max_pair = (algo1, algo2)
    
    avg_jaccard = np.mean(all_similarities) if all_similarities else 0.0
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\\nğŸ“ ç”Ÿæˆå®Œæ•´Teacheræ¨¡å‹åˆ†ææŠ¥å‘Š...")
    
    report = []
    report.append("# ğŸ“ å®Œæ•´6ä¸ªTeacheræ¨¡å‹ä¸€è‡´æ€§åˆ†ææŠ¥å‘Š")
    report.append(f"**å®éªŒæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"**è¿è¡Œè®¾å¤‡**: {device}")
    report.append("")
    
    report.append("## ğŸ“Š å®éªŒæ¦‚è¿°")
    report.append(f"- **ç›®æ ‡Teacheræ¨¡å‹**: {', '.join(algorithms)}")
    report.append(f"- **æˆåŠŸè®­ç»ƒæ¨¡å‹**: {', '.join(trained_models.keys())}")
    report.append(f"- **æ¨èå¯ç”¨æ¨¡å‹**: {', '.join(working_models.keys())}")
    report.append(f"- **å‚ä¸ä¸€è‡´æ€§åˆ†æ**: {', '.join(algorithms_list)}")
    report.append(f"- **æ•°æ®é›†è§„æ¨¡**: {len(train_data)} æ¡äº¤äº’")
    report.append(f"- **æµ‹è¯•ç”¨æˆ·æ•°**: {len(test_users_full)}")
    report.append(f"- **è¿è¡Œæ¨¡å¼**: {'CUDAåŠ é€Ÿ' if cuda_available else 'CPUæ¨¡å¼'}")
    report.append("")
    
    # è®­ç»ƒæ€§èƒ½
    report.append("## â±ï¸ Teacheræ¨¡å‹è®­ç»ƒæ€§èƒ½")
    report.append("")
    report.append("| æ¨¡å‹ | è®­ç»ƒæ—¶é—´(ç§’) | è®­ç»ƒçŠ¶æ€ | æ¨èçŠ¶æ€ |")
    report.append("|------|-------------|----------|----------|")
    
    for algo in algorithms:
        train_status = "âœ… æˆåŠŸ" if algo in trained_models else "âŒ å¤±è´¥"
        rec_status = "âœ… å¯ç”¨" if algo in working_models else "âŒ ä¸å¯ç”¨"
        train_time = training_times.get(algo, 0)
        if train_time > 0:
            report.append(f"| {algo} | {train_time:.2f} | {train_status} | {rec_status} |")
        else:
            report.append(f"| {algo} | - | {train_status} | {rec_status} |")
    report.append("")
    
    # æ¨èæ€§èƒ½
    if performance_stats:
        report.append("## ğŸ† Teacheræ¨¡å‹æ¨èæ€§èƒ½")
        report.append("")
        report.append("| æ¨¡å‹ | æˆåŠŸç‡ | å¹³å‡æ¨èæ•° | æ€»æ¨èæ•° | è®­ç»ƒæ—¶é—´(ç§’) |")
        report.append("|------|--------|------------|----------|-------------|")
        
        for algo_name, stats in performance_stats.items():
            report.append(f"| {algo_name} | {stats['success_rate']:.2%} | {stats['avg_rec_length']:.1f} | {stats['total_recommendations']} | {stats['training_time']:.2f} |")
        report.append("")
    
    # ä¸€è‡´æ€§åˆ†æ
    if len(algorithms_list) >= 2:
        report.append("## ğŸ”„ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æ")
        report.append("")
        
        report.append("### ğŸ“Š å…³é”®æŒ‡æ ‡")
        report.append(f"- **å‚ä¸åˆ†æçš„æ¨¡å‹æ•°**: {len(algorithms_list)}")
        report.append(f"- **å¹³å‡Jaccardç›¸ä¼¼åº¦**: {avg_jaccard:.4f}")
        if min_pair:
            report.append(f"- **æœ€å¼ºäº’è¡¥ç»„åˆ**: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})")
        if max_pair:
            report.append(f"- **æœ€ç›¸ä¼¼ç»„åˆ**: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})")
        report.append("")
        
        # Jaccardç›¸ä¼¼åº¦çŸ©é˜µ
        report.append("### ğŸ”¢ å®Œæ•´Jaccardç›¸ä¼¼åº¦çŸ©é˜µ")
        report.append("")
        
        header = "| ç®—æ³• |" + "".join([f" {algo} |" for algo in algorithms_list])
        separator = "|" + "".join(["------|" for _ in range(len(algorithms_list) + 1)])
        
        report.append(header)
        report.append(separator)
        
        for algo1 in algorithms_list:
            row = f"| **{algo1}** |"
            for algo2 in algorithms_list:
                if algo1 == algo2:
                    row += " 1.0000 |"
                else:
                    similarity = jaccard_matrix[algo1][algo2]
                    row += f" {similarity:.4f} |"
            report.append(row)
        
        report.append("")
        
        # Ensembleå»ºè®®
        report.append("## ğŸ¯ å®Œæ•´Teacheræ¨¡å‹Ensembleç­–ç•¥")
        report.append("")
        
        if min_pair and max_pair:
            report.append("### ğŸ¥‡ åŸºäºå®Œæ•´åˆ†æçš„æœ€ä½³ç»„åˆ")
            report.append("")
            report.append(f"**æœ€å¼ºäº’è¡¥ç­–ç•¥**: {min_pair[0]} + {min_pair[1]}")
            report.append(f"- **Jaccardç›¸ä¼¼åº¦**: {min_jaccard:.4f}")
            report.append(f"- **ç‰¹ç‚¹**: åœ¨æ‰€æœ‰{len(algorithms_list)}ä¸ªå¯ç”¨æ¨¡å‹ä¸­æ¨èé‡å åº¦æœ€ä½")
            report.append("")
            
            report.append(f"**æœ€å¼ºä¸€è‡´ç­–ç•¥**: {max_pair[0]} + {max_pair[1]}")
            report.append(f"- **Jaccardç›¸ä¼¼åº¦**: {max_jaccard:.4f}")  
            report.append(f"- **ç‰¹ç‚¹**: åœ¨æ‰€æœ‰{len(algorithms_list)}ä¸ªå¯ç”¨æ¨¡å‹ä¸­æ¨èä¸€è‡´æ€§æœ€é«˜")
            report.append("")
    
    # ä¿®å¤æ€»ç»“
    if len(working_models) == len(algorithms):
        report.append("## âœ… å®Œæ•´å®éªŒæˆåŠŸæ€»ç»“")
        report.append("")
        report.append("- **æ‰€æœ‰6ä¸ªTeacheræ¨¡å‹éƒ½æˆåŠŸè®­ç»ƒå¹¶å¯ç”¨äºæ¨è**")
        report.append("- **æ‰€æœ‰æ¨¡å‹éƒ½å‚ä¸äº†ä¸€è‡´æ€§åˆ†æ**")
        report.append("- **æ¨èæ¥å£ç»Ÿä¸€ï¼Œæ•°æ®æ ¼å¼ä¸€è‡´**")
        report.append("- **CUDAç¯å¢ƒè¿è¡Œç¨³å®š**")
    else:
        report.append("## âš ï¸ éƒ¨åˆ†å®éªŒæˆåŠŸæ€»ç»“")
        report.append("")
        report.append(f"- **{len(working_models)}/{len(algorithms)} ä¸ªTeacheræ¨¡å‹å¯ç”¨äºæ¨è**")
        report.append(f"- **å‚ä¸ä¸€è‡´æ€§åˆ†æçš„æ¨¡å‹: {len(algorithms_list)} ä¸ª**")
        if len(working_models) < len(trained_models):
            failed_models = set(trained_models.keys()) - set(working_models.keys())
            report.append(f"- **æ¨èåŠŸèƒ½å¼‚å¸¸çš„æ¨¡å‹**: {', '.join(failed_models)}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = "\\n".join(report)
    
    with open("COMPLETE_TEACHER_MODEL_ANALYSIS.md", "w", encoding='utf-8') as f:
        f.write(report_content)
    
    print("âœ… å®Œæ•´Teacheræ¨¡å‹åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° COMPLETE_TEACHER_MODEL_ANALYSIS.md")
    
    # æ˜¾ç¤ºå…³é”®ç»“æœ
    print("\\nğŸ‰ å®Œæ•´6ä¸ªTeacheræ¨¡å‹å®éªŒå®Œæˆï¼")
    print("\\nğŸ“Š å…³é”®ç»“æœ:")
    print(f"ğŸ“ˆ æˆåŠŸè®­ç»ƒçš„Teacheræ¨¡å‹ ({len(trained_models)}/{len(algorithms)}): {list(trained_models.keys())}")
    print(f"ğŸ”§ æ¨èå¯ç”¨çš„æ¨¡å‹ ({len(working_models)}/{len(algorithms)}): {list(working_models.keys())}")
    print(f"ğŸ“Š å‚ä¸ä¸€è‡´æ€§åˆ†æ: {len(algorithms_list)} ä¸ªæ¨¡å‹")
    
    if avg_jaccard is not None:
        print(f"ğŸ“Š å¹³å‡Jaccardç›¸ä¼¼åº¦: {avg_jaccard:.4f}")
    
    if min_pair:
        print(f"ğŸ† æœ€ä½³äº’è¡¥ç»„åˆ: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})")
    
    if max_pair:
        print(f"âš ï¸  æœ€ç›¸ä¼¼ç»„åˆ: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})")
    
    # æ˜¾ç¤ºå®Œæ•´ä¸€è‡´æ€§çŸ©é˜µ
    if len(algorithms_list) >= 2:
        print("\\nğŸ“‹ å®Œæ•´Jaccardç›¸ä¼¼åº¦çŸ©é˜µ:")
        print("     ", end="")
        for algo in algorithms_list:
            print(f"{algo:>12}", end="")
        print()
        
        for algo1 in algorithms_list:
            print(f"{algo1:>8}", end="")
            for algo2 in algorithms_list:
                if algo1 == algo2:
                    print(f"{'1.0000':>12}", end="")
                else:
                    print(f"{jaccard_matrix[algo1][algo2]:>12.4f}", end="")
            print()
    
    # æ¸…ç†GPUå†…å­˜
    if cuda_available:
        torch.cuda.empty_cache()
    
    return {
        'trained_models': list(trained_models.keys()),
        'working_models': list(working_models.keys()),
        'analyzed_models': algorithms_list,
        'jaccard_matrix': jaccard_matrix if len(algorithms_list) >= 2 else None,
        'best_complementary': min_pair,
        'most_similar': max_pair,
        'avg_jaccard': avg_jaccard,
        'performance_stats': performance_stats,
        'device': str(device),
        'recommendation_tests': recommendation_tests
    }


if __name__ == "__main__":
    result = run_complete_teacher_experiment()
    if result:
        analyzed_count = len(result['analyzed_models'])
        total_count = 6
        print(f"\\nâœ… å®éªŒå®Œæˆï¼å‚ä¸ä¸€è‡´æ€§åˆ†æçš„æ¨¡å‹: {analyzed_count}/{total_count}")
        print(f"ğŸ”§ è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹ COMPLETE_TEACHER_MODEL_ANALYSIS.md")
        
        if analyzed_count == total_count:
            print("ğŸ‰ æ‰€æœ‰6ä¸ªTeacheræ¨¡å‹éƒ½æˆåŠŸå‚ä¸äº†ä¸€è‡´æ€§åˆ†æï¼")
        else:
            print(f"âš ï¸ è¿˜æœ‰ {total_count - analyzed_count} ä¸ªæ¨¡å‹éœ€è¦è¿›ä¸€æ­¥ä¿®å¤")
    else:
        print(f"\\nâŒ å®éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
