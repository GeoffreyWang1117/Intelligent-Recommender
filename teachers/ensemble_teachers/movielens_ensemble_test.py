#!/usr/bin/env python3
"""
MovieLensæ•°æ®é›†ä¸Šçš„é›†æˆæ•™å¸ˆæ¨¡å‹æµ‹è¯•
åœ¨çœŸå®æ•°æ®ä¸ŠéªŒè¯Traditional Teachers Ensembleçš„æ€§èƒ½

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-08-27
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
import time
import logging
from typing import Dict, List, Tuple, Any, Optional
import torch

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MovieLensDataLoader:
    """MovieLensæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, data_path: str = "data/movielens/"):
        self.data_path = data_path
        self.ratings_df = None
        self.movies_df = None
        
    def load_data(self):
        """åŠ è½½MovieLensæ•°æ®"""
        logger.info("ğŸ“š åŠ è½½MovieLensæ•°æ®...")
        
        # åŠ è½½è¯„åˆ†æ•°æ®
        ratings_file = os.path.join(self.data_path, "ratings.csv")
        if not os.path.exists(ratings_file):
            raise FileNotFoundError(f"è¯„åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {ratings_file}")
            
        self.ratings_df = pd.read_csv(ratings_file)
        
        # åŠ è½½ç”µå½±æ•°æ®
        movies_file = os.path.join(self.data_path, "movies.csv") 
        if os.path.exists(movies_file):
            self.movies_df = pd.read_csv(movies_file)
        
        # æ•°æ®ç»Ÿè®¡
        logger.info(f"   è¯„åˆ†è®°å½•: {len(self.ratings_df)}")
        logger.info(f"   ç”¨æˆ·æ•°: {self.ratings_df['user_id'].nunique()}")
        logger.info(f"   ç”µå½±æ•°: {self.ratings_df['item_id'].nunique()}")
        logger.info(f"   è¯„åˆ†èŒƒå›´: {self.ratings_df['rating'].min()}-{self.ratings_df['rating'].max()}")
        
        return self.ratings_df, self.movies_df
    
    def prepare_train_test_split(self, test_ratio: float = 0.2):
        """å‡†å¤‡è®­ç»ƒæµ‹è¯•æ•°æ®åˆ†å‰²"""
        logger.info(f"ğŸ”„ å‡†å¤‡è®­ç»ƒ/æµ‹è¯•æ•°æ®åˆ†å‰² (æµ‹è¯•æ¯”ä¾‹: {test_ratio})")
        
        if self.ratings_df is None:
            self.load_data()
        
        if self.ratings_df is None:
            raise ValueError("æ— æ³•åŠ è½½è¯„åˆ†æ•°æ®")
        
        # ç®€å•çš„æ—¶é—´åˆ†å‰²ï¼šæœ€æ–°çš„20%ä½œä¸ºæµ‹è¯•é›†
        sorted_data = self.ratings_df.sort_values('timestamp')
        split_idx = int(len(sorted_data) * (1 - test_ratio))
        
        train_df = sorted_data.iloc[:split_idx]
        test_df = sorted_data.iloc[split_idx:]
        
        logger.info(f"   è®­ç»ƒæ•°æ®: {len(train_df)} æ¡")
        logger.info(f"   æµ‹è¯•æ•°æ®: {len(test_df)} æ¡")
        
        return train_df, test_df


class SimpleRecommender:
    """ç®€å•æ¨èå™¨åŸºç±»"""
    
    def __init__(self, name: str, strategy: str = "user_avg"):
        self.name = name
        self.strategy = strategy
        self.is_trained = False
        self.global_mean = 3.5
        self.user_means = {}
        self.item_means = {}
        self.user_item_matrix = {}
        
    def fit(self, train_data: pd.DataFrame):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info(f"ğŸ”§ è®­ç»ƒ {self.name}...")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self.global_mean = train_data['rating'].mean()
        self.user_means = train_data.groupby('user_id')['rating'].mean().to_dict()
        self.item_means = train_data.groupby('item_id')['rating'].mean().to_dict()
        
        # æ„å»ºç”¨æˆ·-ç‰©å“çŸ©é˜µ
        for _, row in train_data.iterrows():
            user_id = int(row['user_id'])
            item_id = int(row['item_id'])
            rating = float(row['rating'])
            
            if user_id not in self.user_item_matrix:
                self.user_item_matrix[user_id] = {}
            self.user_item_matrix[user_id][item_id] = rating
        
        self.is_trained = True
        logger.info(f"   âœ… {self.name} è®­ç»ƒå®Œæˆ")
        
    def predict(self, user_id: int, item_id: int) -> float:
        """é¢„æµ‹è¯„åˆ†"""
        if not self.is_trained:
            return self.global_mean
        
        # å¦‚æœæœ‰ç›´æ¥è¯„åˆ†ï¼Œè¿”å›è¯¥è¯„åˆ†
        if user_id in self.user_item_matrix and item_id in self.user_item_matrix[user_id]:
            return self.user_item_matrix[user_id][item_id]
        
        # æ ¹æ®ç­–ç•¥é¢„æµ‹
        if self.strategy == "user_avg":
            return self.user_means.get(user_id, self.global_mean)
        elif self.strategy == "item_avg":
            return self.item_means.get(item_id, self.global_mean)
        elif self.strategy == "combined":
            user_avg = self.user_means.get(user_id, self.global_mean)
            item_avg = self.item_means.get(item_id, self.global_mean)
            return 0.5 * user_avg + 0.5 * item_avg
        else:
            return self.global_mean
    
    def get_recommendations(self, user_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """è·å–æ¨è"""
        if not self.is_trained:
            return []
        
        # è·å–ç”¨æˆ·å·²è¯„åˆ†çš„ç‰©å“
        rated_items = set()
        if user_id in self.user_item_matrix:
            rated_items = set(self.user_item_matrix[user_id].keys())
        
        # ä»æ‰€æœ‰ç‰©å“ä¸­é€‰æ‹©å€™é€‰
        all_items = set(self.item_means.keys())
        candidate_items = list(all_items - rated_items)
        
        # å¦‚æœå€™é€‰å¤ªå°‘ï¼Œå–æ‰€æœ‰ç‰©å“
        if len(candidate_items) < top_k:
            candidate_items = list(all_items)[:100]
        
        # é¢„æµ‹å¹¶æ’åº
        item_scores = []
        for item_id in candidate_items:
            score = self.predict(user_id, item_id)
            item_scores.append((item_id, score))
        
        item_scores.sort(key=lambda x: x[1], reverse=True)
        return item_scores[:top_k]


class EnsembleRecommender:
    """é›†æˆæ¨èå™¨"""
    
    def __init__(self):
        self.models = {}
        self.weights = {}
        self.is_trained = False
        
    def add_model(self, name: str, model: SimpleRecommender, weight: float):
        """æ·»åŠ æ¨¡å‹"""
        self.models[name] = model
        self.weights[name] = weight
        
    def fit(self, train_data: pd.DataFrame):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸ“ è®­ç»ƒé›†æˆæ¨¡å‹...")
        
        for name, model in self.models.items():
            model.fit(train_data)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.weights.values())
        self.weights = {k: v/total_weight for k, v in self.weights.items()}
        
        self.is_trained = True
        logger.info(f"   âœ… é›†æˆè®­ç»ƒå®Œæˆï¼Œæƒé‡: {self.weights}")
        
    def predict(self, user_id: int, item_id: int) -> float:
        """é›†æˆé¢„æµ‹"""
        if not self.is_trained:
            return 3.5
        
        weighted_sum = 0
        total_weight = 0
        
        for name, model in self.models.items():
            try:
                pred = model.predict(user_id, item_id)
                weight = self.weights[name]
                weighted_sum += weight * pred
                total_weight += weight
            except:
                continue
        
        return weighted_sum / total_weight if total_weight > 0 else 3.5
    
    def get_recommendations(self, user_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """é›†æˆæ¨è"""
        if not self.is_trained:
            return []
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„æ¨è
        all_candidates = {}
        
        for name, model in self.models.items():
            try:
                recs = model.get_recommendations(user_id, top_k=20)
                weight = self.weights[name]
                
                for item_id, score in recs:
                    if item_id not in all_candidates:
                        all_candidates[item_id] = 0
                    all_candidates[item_id] += weight * score
            except:
                continue
        
        # æ’åºè¿”å›
        sorted_items = sorted(all_candidates.items(), key=lambda x: x[1], reverse=True)
        return sorted_items[:top_k]


def evaluate_model(model, test_data: pd.DataFrame, model_name: str) -> Dict[str, float]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    logger.info(f"ğŸ“Š è¯„ä¼° {model_name}...")
    
    # é¢„æµ‹å‡†ç¡®æ€§è¯„ä¼°
    predictions = []
    actuals = []
    
    # é™åˆ¶æµ‹è¯•æ•°æ®é‡ä»¥åŠ å¿«é€Ÿåº¦
    test_sample = test_data.head(500)
    
    for _, row in test_sample.iterrows():
        try:
            user_id = int(row['user_id'])
            item_id = int(row['item_id'])
            actual = row['rating']
            
            if hasattr(model, 'predict'):
                pred = model.predict(user_id, item_id)
            else:
                continue
                
            predictions.append(pred)
            actuals.append(actual)
        except:
            continue
    
    if len(predictions) == 0:
        return {'rmse': float('inf'), 'mae': float('inf'), 'coverage': 0.0}
    
    # è®¡ç®—æŒ‡æ ‡
    rmse = np.sqrt(np.mean([(p - a) ** 2 for p, a in zip(predictions, actuals)]))
    mae = np.mean([abs(p - a) for p, a in zip(predictions, actuals)])
    
    # æ¨èè¦†ç›–ç‡æµ‹è¯•
    test_users = test_data['user_id'].unique()[:20]
    successful_recs = 0
    
    for user_id in test_users:
        try:
            if hasattr(model, 'get_recommendations'):
                recs = model.get_recommendations(int(user_id), top_k=5)
            else:
                continue
            if recs and len(recs) > 0:
                successful_recs += 1
        except:
            continue
    
    coverage = successful_recs / len(test_users)
    
    logger.info(f"   {model_name} - RMSE: {rmse:.3f}, MAE: {mae:.3f}, è¦†ç›–ç‡: {coverage:.1%}")
    
    return {
        'rmse': float(rmse),
        'mae': float(mae),
        'coverage': float(coverage),
        'prediction_count': len(predictions)
    }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ MovieLensé›†æˆæ•™å¸ˆæ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    try:
        # 1. æ£€æŸ¥CUDAç¯å¢ƒ
        if torch.cuda.is_available():
            print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.get_device_name()}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼")
        
        # 2. åŠ è½½æ•°æ®
        data_loader = MovieLensDataLoader()
        train_data, test_data = data_loader.prepare_train_test_split()
        
        # 3. åˆ›å»ºå•ä¸ªæ¨¡å‹
        models = {
            'user_based': SimpleRecommender('ç”¨æˆ·ååŒè¿‡æ»¤', 'user_avg'),
            'item_based': SimpleRecommender('ç‰©å“ååŒè¿‡æ»¤', 'item_avg'),
            'combined': SimpleRecommender('æ··åˆæ¨¡å‹', 'combined'),
            'baseline1': SimpleRecommender('åŸºçº¿æ¨¡å‹1', 'user_avg'),
            'baseline2': SimpleRecommender('åŸºçº¿æ¨¡å‹2', 'item_avg'),
            'baseline3': SimpleRecommender('åŸºçº¿æ¨¡å‹3', 'combined')
        }
        
        # 4. è®­ç»ƒå•ä¸ªæ¨¡å‹
        print("\nğŸ”§ è®­ç»ƒå•ä¸ªæ¨¡å‹...")
        for name, model in models.items():
            model.fit(train_data)
        
        # 5. è¯„ä¼°å•ä¸ªæ¨¡å‹
        print("\nğŸ“Š è¯„ä¼°å•ä¸ªæ¨¡å‹æ€§èƒ½...")
        individual_results = {}
        for name, model in models.items():
            individual_results[name] = evaluate_model(model, test_data, name)
        
        # 6. åˆ›å»ºé›†æˆæ¨¡å‹
        print("\nğŸ¯ åˆ›å»ºé›†æˆæ¨¡å‹...")
        ensemble = EnsembleRecommender()
        
        # åŸºäºæ€§èƒ½è®¾å®šæƒé‡
        weights = {
            'user_based': 0.25,
            'item_based': 0.20,
            'combined': 0.30,
            'baseline1': 0.10,
            'baseline2': 0.10,
            'baseline3': 0.05
        }
        
        for name, model in models.items():
            ensemble.add_model(name, model, weights[name])
        
        ensemble.fit(train_data)
        
        # 7. è¯„ä¼°é›†æˆæ¨¡å‹
        print("\nğŸ† è¯„ä¼°é›†æˆæ¨¡å‹...")
        ensemble_result = evaluate_model(ensemble, test_data, "é›†æˆæ¨¡å‹")
        
        # 8. ç»“æœå¯¹æ¯”
        print("\nğŸ“‹ æ€§èƒ½å¯¹æ¯”:")
        print("æ¨¡å‹åç§°\t\tRMSE\tMAE\tè¦†ç›–ç‡")
        print("-" * 50)
        
        for name, result in individual_results.items():
            print(f"{name:15}\t{result['rmse']:.3f}\t{result['mae']:.3f}\t{result['coverage']:.1%}")
        
        print(f"{'é›†æˆæ¨¡å‹':15}\t{ensemble_result['rmse']:.3f}\t{ensemble_result['mae']:.3f}\t{ensemble_result['coverage']:.1%}")
        
        # 9. æ¨èç¤ºä¾‹
        print("\nğŸ¬ æ¨èç¤ºä¾‹:")
        try:
            # é€‰æ‹©ä¸€ä¸ªæœ‰è¯„åˆ†çš„ç”¨æˆ·
            sample_user = int(train_data['user_id'].iloc[0])
            print(f"   ç”¨æˆ· {sample_user} çš„å†å²è¯„åˆ†:")
            
            user_history = train_data[train_data['user_id'] == sample_user].head(3)
            for _, row in user_history.iterrows():
                print(f"     ç”µå½± {row['item_id']}: {row['rating']} åˆ†")
            
            print(f"\n   é›†æˆæ¨¡å‹æ¨è Top-5:")
            recs = ensemble.get_recommendations(sample_user, top_k=5)
            for i, (item_id, score) in enumerate(recs):
                print(f"     {i+1}. ç”µå½± {item_id}: {score:.3f}")
                
        except Exception as e:
            print(f"   æ¨èç¤ºä¾‹å¤±è´¥: {e}")
        
        # 10. æ€§èƒ½æ”¹è¿›åˆ†æ
        print("\nğŸ“ˆ æ€§èƒ½æ”¹è¿›åˆ†æ:")
        individual_rmses = [r['rmse'] for r in individual_results.values()]
        best_individual = min(individual_rmses)
        ensemble_rmse = ensemble_result['rmse']
        
        improvement = (best_individual - ensemble_rmse) / best_individual * 100
        
        print(f"   æœ€ä½³å•æ¨¡å‹RMSE: {best_individual:.3f}")
        print(f"   é›†æˆæ¨¡å‹RMSE: {ensemble_rmse:.3f}")
        print(f"   æ€§èƒ½æ”¹è¿›: {improvement:+.1f}%")
        
        if improvement > 0:
            print("âœ… é›†æˆæ¨¡å‹è¡¨ç°ä¼˜äºå•ä¸ªæ¨¡å‹ï¼")
        else:
            print("âš ï¸ é›†æˆæ¨¡å‹éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’:")
        print("   1. é›†æˆçœŸå®çš„Traditional Teacheræ¨¡å‹(DCNv2, DINç­‰)")
        print("   2. å®ç°Fisher Information per-layerè®¡ç®—")
        print("   3. æ·»åŠ pruning-awareè’¸é¦æœºåˆ¶")
        print("   4. åœ¨Amazonæ•°æ®ä¸ŠéªŒè¯æ³›åŒ–èƒ½åŠ›")
        
        return {
            'individual_results': individual_results,
            'ensemble_result': ensemble_result,
            'improvement': improvement
        }
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()
