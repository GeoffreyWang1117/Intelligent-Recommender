#!/usr/bin/env python3
"""
Traditional Teachers Ensemble Model
ä¼ ç»Ÿæ¨èç®—æ³•é›†æˆæ•™å¸ˆæ¨¡å‹

åŸºäºPhase 1çš„6ä¸ªSOTAç®—æ³•æ€§èƒ½æ’åæ„å»ºåŠ æƒé›†æˆ:
- DCNv2 (æƒé‡: 0.25) - æœ€ä¼˜ç®—æ³•
- DIN (æƒé‡: 0.20) - æ¬¡ä¼˜ç®—æ³•  
- xDeepFM (æƒé‡: 0.18) - ç¬¬ä¸‰å
- DeepFM (æƒé‡: 0.15) - åŸºç¡€æ¨¡å‹
- AutoInt (æƒé‡: 0.12) - æ³¨æ„åŠ›æ¨¡å‹
- Transformer4Rec (æƒé‡: 0.10) - åºåˆ—æ¨¡å‹

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-08-27
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Any, Optional, Union
import logging
from collections import defaultdict
import pickle
import json

# å¯¼å…¥6ä¸ªtraditional teacheræ¨¡å‹
try:
    from models.algorithm_factory import create_recommender
    from models.base_recommender import BaseRecommender
except ImportError:
    # å¤‡ç”¨å¯¼å…¥è·¯å¾„
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'models'))
    from algorithm_factory import create_recommender
    from base_recommender import BaseRecommender

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnsembleTeacher:
    """6ä¸ªSOTAç®—æ³•çš„é›†æˆæ•™å¸ˆæ¨¡å‹"""
    
    def __init__(self, model_weights: Optional[Dict[str, float]] = None, device: str = 'auto'):
        """
        åˆå§‹åŒ–é›†æˆæ•™å¸ˆæ¨¡å‹
        
        Args:
            model_weights: æ¨¡å‹æƒé‡å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æƒé‡
            device: è®¡ç®—è®¾å¤‡
        """
        # åŸºäºPhase 1æ€§èƒ½ç»“æœçš„é»˜è®¤æƒé‡
        self.default_weights = {
            'dcnv2': 0.25,         # æœ€ä¼˜: ç»¼åˆå¾—åˆ† 0.3676
            'din': 0.20,           # æ¬¡ä¼˜: æ³¨æ„åŠ›æœºåˆ¶å¼º
            'xdeepfm': 0.18,       # ç¬¬ä¸‰: æ˜¾å¼+éšå¼äº¤äº’
            'deepfm': 0.15,        # åŸºç¡€: FM+DNNç»“åˆ
            'autoint': 0.12,       # è‡ªåŠ¨ç‰¹å¾äº¤äº’
            'transformer4rec': 0.10 # åºåˆ—å»ºæ¨¡
        }
        
        self.weights = model_weights if model_weights else self.default_weights
        self.device = self._setup_device(device)
        self.models = {}
        self.is_trained = False
        
        # é›†æˆç­–ç•¥é…ç½®
        self.ensemble_strategy = 'weighted_average'  # 'weighted_average', 'rank_fusion', 'adaptive'
        self.consensus_threshold = 0.7  # ä¸€è‡´æ€§é˜ˆå€¼
        
        logger.info(f"åˆå§‹åŒ–Ensemble Teacherï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        logger.info(f"æ¨¡å‹æƒé‡: {self.weights}")
    
    def _setup_device(self, device: str) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == 'auto':
            if torch.cuda.is_available():
                device = 'cuda'
                logger.info(f"æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
            else:
                device = 'cpu'
                logger.info("æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPU")
        return torch.device(device)
    
    def load_trained_models(self, model_dir: str = "teachers/traditional_teachers/models/saved/"):
        """
        åŠ è½½å·²è®­ç»ƒçš„6ä¸ªæ¨¡å‹
        
        Args:
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        logger.info("ğŸ”„ åŠ è½½å·²è®­ç»ƒçš„Traditional Teacheræ¨¡å‹...")
        
        model_configs = {
            'dcnv2': {'name': 'DCNv2', 'type': 'dcnv2'},
            'din': {'name': 'DIN', 'type': 'din'},
            'xdeepfm': {'name': 'xDeepFM', 'type': 'xdeepfm'},
            'deepfm': {'name': 'DeepFM', 'type': 'deepfm'},
            'autoint': {'name': 'AutoInt', 'type': 'autoint'},
            'transformer4rec': {'name': 'Transformer4Rec', 'type': 'transformer4rec'}
        }
        
        successful_loads = 0
        
        for model_key, config in model_configs.items():
            try:
                # åˆ›å»ºæ¨¡å‹å®ä¾‹
                model = create_recommender(
                    config['type'],
                    num_users=610,  # MovieLensé»˜è®¤
                    num_items=9742,
                    embedding_dim=64
                )
                
                if model is None:
                    logger.warning(f"âš ï¸ {config['name']} åˆ›å»ºå¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                model_path = os.path.join(model_dir, f"{model_key}_best.pth")
                if os.path.exists(model_path):
                    try:
                        # å¯¹äºPyTorchæ¨¡å‹ï¼Œå°è¯•åŠ è½½state_dict
                        if hasattr(model, 'load_state_dict') and hasattr(model, 'state_dict'):
                            state_dict = torch.load(model_path, map_location=self.device)
                            model.load_state_dict(state_dict)
                            logger.info(f"âœ… {config['name']} PyTorchæƒé‡åŠ è½½æˆåŠŸ")
                        else:
                            # å¯¹äºéPyTorchæ¨¡å‹ï¼Œä½¿ç”¨pickleåŠ è½½
                            model.load_model(model_path)
                            logger.info(f"âœ… {config['name']} æ¨¡å‹åŠ è½½æˆåŠŸ")
                    except Exception as load_e:
                        logger.warning(f"âš ï¸ {config['name']} æƒé‡åŠ è½½å¤±è´¥: {load_e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
                else:
                    logger.warning(f"âš ï¸ {config['name']} æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
                
                # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå¦‚æœæ”¯æŒï¼‰
                if hasattr(model, 'eval'):
                    model.eval()
                if hasattr(model, 'to'):
                    model.to(self.device)
                
                # åŒ…è£…ä¸ºEnsembleMember
                self.models[model_key] = EnsembleMember(
                    model=model,
                    weight=self.weights[model_key],
                    name=config['name'],
                    model_type=config['type']
                )
                
                successful_loads += 1
                
            except Exception as e:
                logger.error(f"âŒ {config['name']} åŠ è½½å¤±è´¥: {str(e)}")
                # ç§»é™¤å¤±è´¥æ¨¡å‹çš„æƒé‡
                if model_key in self.weights:
                    del self.weights[model_key]
        
        # é‡æ–°å½’ä¸€åŒ–æƒé‡
        if successful_loads > 0:
            total_weight = sum(self.weights.values())
            self.weights = {k: v/total_weight for k, v in self.weights.items()}
            self.is_trained = True
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {successful_loads}/6 ä¸ªæ¨¡å‹")
            logger.info(f"é‡æ–°å½’ä¸€åŒ–æƒé‡: {self.weights}")
        else:
            raise RuntimeError("âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•æ„å»ºEnsemble")
    
    def get_ensemble_predictions(self, user_ids: List[int], item_ids: List[int]) -> Dict[str, Any]:
        """
        è·å–é›†æˆé¢„æµ‹ç»“æœ
        
        Args:
            user_ids: ç”¨æˆ·IDåˆ—è¡¨
            item_ids: ç‰©å“IDåˆ—è¡¨
            
        Returns:
            åŒ…å«é¢„æµ‹ç»“æœå’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        if not self.is_trained:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨load_trained_models()")
        
        logger.info(f"ğŸ”® é›†æˆé¢„æµ‹: {len(user_ids)} ç”¨æˆ· Ã— {len(item_ids)} ç‰©å“")
        
        # æ”¶é›†å„æ¨¡å‹é¢„æµ‹
        model_predictions = {}
        model_confidences = {}
        
        for model_key, member in self.models.items():
            try:
                with torch.no_grad():
                    # è·å–æ¨¡å‹é¢„æµ‹
                    predictions = member.predict(user_ids, item_ids)
                    confidences = member.get_confidence(predictions)
                    
                    model_predictions[model_key] = predictions
                    model_confidences[model_key] = confidences
                    
                logger.debug(f"{member.name} é¢„æµ‹å®Œæˆ: {predictions.shape}")
                
            except Exception as e:
                logger.error(f"{member.name} é¢„æµ‹å¤±è´¥: {str(e)}")
                continue
        
        # æ‰§è¡Œé›†æˆ
        if self.ensemble_strategy == 'weighted_average':
            ensemble_pred = self._weighted_average_ensemble(model_predictions)
        elif self.ensemble_strategy == 'rank_fusion':
            ensemble_pred = self._rank_fusion_ensemble(model_predictions)
        elif self.ensemble_strategy == 'adaptive':
            ensemble_pred = self._adaptive_ensemble(model_predictions, model_confidences)
        else:
            raise ValueError(f"æœªçŸ¥çš„é›†æˆç­–ç•¥: {self.ensemble_strategy}")
        
        return {
            'ensemble_predictions': ensemble_pred,
            'individual_predictions': model_predictions,
            'model_confidences': model_confidences,
            'weights_used': self.weights,
            'strategy': self.ensemble_strategy
        }
    
    def get_user_recommendations(self, user_id: int, top_k: int = 10, 
                               candidate_items: Optional[List[int]] = None) -> List[Tuple[int, float]]:
        """
        ä¸ºå•ä¸ªç”¨æˆ·è·å–Top-Kæ¨è
        
        Args:
            user_id: ç”¨æˆ·ID
            top_k: æ¨èæ•°é‡
            candidate_items: å€™é€‰ç‰©å“åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰ç‰©å“
            
        Returns:
            [(item_id, score), ...] æ¨èåˆ—è¡¨
        """
        if candidate_items is None:
            # é»˜è®¤å€™é€‰ç‰©å“èŒƒå›´ï¼ˆå¯æ ¹æ®å®é™…æ•°æ®è°ƒæ•´ï¼‰
            candidate_items = list(range(1, 1000))  # ç¤ºä¾‹èŒƒå›´
        
        # è·å–é¢„æµ‹åˆ†æ•°
        result = self.get_ensemble_predictions([user_id], candidate_items)
        predictions = result['ensemble_predictions']
        
        # ç»„åˆç‰©å“IDå’Œåˆ†æ•°
        item_scores = list(zip(candidate_items, predictions[0]))
        
        # æŒ‰åˆ†æ•°é™åºæ’åºå¹¶è¿”å›Top-K
        item_scores.sort(key=lambda x: x[1], reverse=True)
        
        return item_scores[:top_k]
    
    def _weighted_average_ensemble(self, model_predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """åŠ æƒå¹³å‡é›†æˆ"""
        if not model_predictions:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹é¢„æµ‹")
        
        # åˆå§‹åŒ–ç»“æœ
        first_pred = next(iter(model_predictions.values()))
        ensemble_pred = np.zeros_like(first_pred)
        total_weight = 0
        
        # åŠ æƒæ±‚å’Œ
        for model_key, predictions in model_predictions.items():
            if model_key in self.weights:
                weight = self.weights[model_key]
                ensemble_pred += weight * predictions
                total_weight += weight
        
        # å½’ä¸€åŒ–
        if total_weight > 0:
            ensemble_pred /= total_weight
        
        return ensemble_pred
    
    def _rank_fusion_ensemble(self, model_predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """æ’åºèåˆé›†æˆï¼ˆé€‚ç”¨äºæ¨èåœºæ™¯ï¼‰"""
        if not model_predictions:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹é¢„æµ‹")
        
        # å°†é¢„æµ‹è½¬æ¢ä¸ºæ’åº
        model_ranks = {}
        for model_key, predictions in model_predictions.items():
            # å¯¹æ¯ä¸ªç”¨æˆ·çš„é¢„æµ‹è¿›è¡Œæ’åº
            ranks = np.argsort(np.argsort(-predictions, axis=1), axis=1)
            model_ranks[model_key] = ranks
        
        # åŠ æƒæ’åºèåˆ
        ensemble_ranks = self._weighted_average_ensemble(model_ranks)
        
        # å°†æ’åºè½¬æ¢å›åˆ†æ•°ï¼ˆå€’æ’åºï¼‰
        max_rank = ensemble_ranks.max()
        ensemble_pred = max_rank - ensemble_ranks
        
        return ensemble_pred
    
    def _adaptive_ensemble(self, model_predictions: Dict[str, np.ndarray], 
                          model_confidences: Dict[str, np.ndarray]) -> np.ndarray:
        """è‡ªé€‚åº”é›†æˆï¼ˆåŸºäºæ¨¡å‹ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´æƒé‡ï¼‰"""
        if not model_predictions:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹é¢„æµ‹")
        
        # åŠ¨æ€æƒé‡è®¡ç®—
        adaptive_weights = {}
        for model_key in model_predictions.keys():
            if model_key in self.weights and model_key in model_confidences:
                base_weight = self.weights[model_key]
                confidence = model_confidences[model_key].mean()
                adaptive_weights[model_key] = base_weight * confidence
        
        # å½’ä¸€åŒ–è‡ªé€‚åº”æƒé‡
        total_weight = sum(adaptive_weights.values())
        if total_weight > 0:
            adaptive_weights = {k: v/total_weight for k, v in adaptive_weights.items()}
        
        # ä½¿ç”¨è‡ªé€‚åº”æƒé‡è¿›è¡ŒåŠ æƒå¹³å‡
        first_pred = next(iter(model_predictions.values()))
        ensemble_pred = np.zeros_like(first_pred)
        
        for model_key, predictions in model_predictions.items():
            if model_key in adaptive_weights:
                ensemble_pred += adaptive_weights[model_key] * predictions
        
        return ensemble_pred
    
    def analyze_model_consensus(self, user_ids: List[int], item_ids: List[int]) -> Dict[str, Any]:
        """
        åˆ†ææ¨¡å‹ä¸€è‡´æ€§
        
        Returns:
            ä¸€è‡´æ€§åˆ†æç»“æœ
        """
        result = self.get_ensemble_predictions(user_ids, item_ids)
        predictions = result['individual_predictions']
        
        if len(predictions) < 2:
            return {'consensus_score': 1.0, 'agreement_matrix': None}
        
        # è®¡ç®—ä¸¤ä¸¤ç›¸å…³æ€§
        model_keys = list(predictions.keys())
        n_models = len(model_keys)
        agreement_matrix = np.zeros((n_models, n_models))
        
        for i, key1 in enumerate(model_keys):
            for j, key2 in enumerate(model_keys):
                if i <= j:
                    corr = np.corrcoef(predictions[key1].flatten(), 
                                     predictions[key2].flatten())[0, 1]
                    agreement_matrix[i, j] = agreement_matrix[j, i] = corr if not np.isnan(corr) else 0
        
        # è®¡ç®—å¹³å‡ä¸€è‡´æ€§
        consensus_score = agreement_matrix[np.triu_indices(n_models, k=1)].mean()
        
        return {
            'consensus_score': consensus_score,
            'agreement_matrix': agreement_matrix,
            'model_keys': model_keys,
            'high_consensus': consensus_score > self.consensus_threshold
        }
    
    def save_ensemble_config(self, save_path: str):
        """ä¿å­˜é›†æˆé…ç½®"""
        config = {
            'weights': self.weights,
            'ensemble_strategy': self.ensemble_strategy,
            'consensus_threshold': self.consensus_threshold,
            'device': str(self.device)
        }
        
        with open(save_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        logger.info(f"é›†æˆé…ç½®å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_ensemble_config(self, config_path: str):
        """åŠ è½½é›†æˆé…ç½®"""
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        self.weights = config['weights']
        self.ensemble_strategy = config['ensemble_strategy']
        self.consensus_threshold = config['consensus_threshold']
        
        logger.info(f"é›†æˆé…ç½®å·²åŠ è½½: {config_path}")


class EnsembleMember:
    """é›†æˆæˆå‘˜åŒ…è£…å™¨"""
    
    def __init__(self, model: BaseRecommender, weight: float, name: str, model_type: str):
        self.model = model
        self.weight = weight
        self.name = name
        self.model_type = model_type
    
    def predict(self, user_ids: List[int], item_ids: List[int]) -> np.ndarray:
        """è·å–æ¨¡å‹é¢„æµ‹"""
        predictions = []
        
        # å¯¹æ¯ä¸ªç”¨æˆ·-ç‰©å“å¯¹è¿›è¡Œé¢„æµ‹
        for user_id in user_ids:
            user_predictions = []
            for item_id in item_ids:
                try:
                    score = self.model.predict(user_id, item_id)
                    user_predictions.append(float(score))
                except Exception as e:
                    # é¢„æµ‹å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
                    user_predictions.append(0.0)
            predictions.append(user_predictions)
        
        return np.array(predictions)
    
    def get_confidence(self, predictions: np.ndarray) -> np.ndarray:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼šä½¿ç”¨é¢„æµ‹åˆ†å¸ƒç‰¹å¾ï¼‰"""
        # åŸºäºé¢„æµ‹å€¼çš„åˆ†å¸ƒè®¡ç®—ç½®ä¿¡åº¦
        # 1. è®¡ç®—æ¯è¡Œçš„æ ‡å‡†å·®ï¼ˆé¢„æµ‹ä¸€è‡´æ€§ï¼‰
        std_per_user = np.std(predictions, axis=1, keepdims=True)
        
        # 2. è®¡ç®—æ¯è¡Œçš„å¹³å‡å€¼ï¼ˆé¢„æµ‹å¼ºåº¦ï¼‰
        mean_per_user = np.mean(predictions, axis=1, keepdims=True)
        
        # 3. ç½®ä¿¡åº¦ = é¢„æµ‹å¼ºåº¦ / (1 + é¢„æµ‹æ–¹å·®)
        # é¢„æµ‹è¶Šå¼ºã€æ–¹å·®è¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        confidence = np.abs(mean_per_user) / (1.0 + std_per_user + 1e-8)
        
        return confidence
    
    def get_user_recommendations(self, user_id: int, top_k: int = 10) -> List[Tuple[int, float]]:
        """è·å–ç”¨æˆ·æ¨èï¼ˆå§”æ‰˜ç»™åº•å±‚æ¨¡å‹ï¼‰"""
        try:
            recs = self.model.get_user_recommendations(user_id, top_k)
            result = []
            
            for rec in recs:
                if isinstance(rec, dict) and 'item_id' in rec and 'score' in rec:
                    result.append((int(rec['item_id']), float(rec['score'])))
                elif isinstance(rec, (list, tuple)) and len(rec) >= 2:
                    result.append((int(rec[0]), float(rec[1])))
                    
            return result
        except Exception as e:
            logger.warning(f"{self.name} æ¨èå¤±è´¥: {e}")
            return []


def demo_ensemble_teacher():
    """æ¼”ç¤ºEnsemble Teacherä½¿ç”¨"""
    print("ğŸš€ æ¼”ç¤ºTraditional Teachers Ensemble...")
    
    # åˆ›å»ºé›†æˆæ•™å¸ˆ
    ensemble = EnsembleTeacher()
    
    try:
        # åŠ è½½æ¨¡å‹
        ensemble.load_trained_models()
        
        # ç¤ºä¾‹ç”¨æˆ·å’Œç‰©å“
        test_users = [1, 2, 3, 4, 5]
        test_items = [10, 20, 30, 40, 50]
        
        # è·å–é›†æˆé¢„æµ‹
        result = ensemble.get_ensemble_predictions(test_users, test_items)
        
        print(f"âœ… é›†æˆé¢„æµ‹å®Œæˆ")
        print(f"   é›†æˆç­–ç•¥: {result['strategy']}")
        print(f"   ä½¿ç”¨æƒé‡: {result['weights_used']}")
        print(f"   é¢„æµ‹å½¢çŠ¶: {result['ensemble_predictions'].shape}")
        
        # è·å–ç”¨æˆ·æ¨è
        user_recs = ensemble.get_user_recommendations(user_id=1, top_k=5)
        print(f"\nğŸ“‹ ç”¨æˆ·1çš„Top-5æ¨è:")
        for i, (item_id, score) in enumerate(user_recs):
            print(f"   {i+1}. ç‰©å“{item_id}: {score:.4f}")
        
        # åˆ†ææ¨¡å‹ä¸€è‡´æ€§
        consensus = ensemble.analyze_model_consensus(test_users, test_items)
        print(f"\nğŸ¤ æ¨¡å‹ä¸€è‡´æ€§åˆ†æ:")
        print(f"   ä¸€è‡´æ€§å¾—åˆ†: {consensus['consensus_score']:.4f}")
        print(f"   é«˜ä¸€è‡´æ€§: {consensus['high_consensus']}")
        
        print("\nğŸ‰ Ensemble Teacheræ¼”ç¤ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    demo_ensemble_teacher()
