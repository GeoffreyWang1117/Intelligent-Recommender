#!/usr/bin/env python3
"""
MovieLensæ•°æ®é›†å¤„ç†å’ŒLLMæ¨èéªŒè¯ç³»ç»Ÿ
Real MovieLens Data Integration for LLM Recommendation Validation

åŠŸèƒ½:
1. åŠ è½½çœŸå®MovieLensæ•°æ®é›†
2. æ„å»ºç”¨æˆ·ç”»åƒå’Œç”µå½±ç‰¹å¾
3. LLMæ¨èç”Ÿæˆ
4. æ¨èç³»ç»Ÿæ ‡å‡†è¯„ä»·æŒ‡æ ‡éªŒè¯

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-08-18
"""

import pandas as pd
import numpy as np
import requests
import json
import time
from pathlib import Path
from typing import Dict, List, Tuple, Any
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class MovieLensLLMValidator:
    """åŸºäºçœŸå®MovieLensæ•°æ®çš„LLMæ¨èéªŒè¯å™¨"""
    
    def __init__(self, data_path: str = "data/movielens", ollama_endpoint: str = "http://localhost:11434/api/generate"):
        self.data_path = Path(data_path)
        self.ollama_endpoint = ollama_endpoint
        
        # LLMæ¨¡å‹é…ç½®
        self.primary_model = "llama3:latest"    # è‹±æ–‡ä¸»åŠ›
        self.secondary_model = "qwen3:latest"   # ä¸­æ–‡å¯¹ç…§
        
        # æ•°æ®å­˜å‚¨
        self.ratings = None
        self.movies = None
        self.users = None
        self.user_profiles = {}
        self.movie_features = {}
        
        # éªŒè¯æŒ‡æ ‡
        self.metrics_results = {}
        
    def load_movielens_data(self, dataset_size: str = "sample") -> bool:
        """
        åŠ è½½MovieLensæ•°æ®é›†
        
        Args:
            dataset_size: "sample" (data/movielens) æˆ– "small" (100k) æˆ– "medium" (1M) æˆ– "large" (25M)
        """
        try:
            if dataset_size == "sample":
                # ä½¿ç”¨data/movielensæ–‡ä»¶å¤¹ä¸­çš„æ ·æœ¬æ•°æ®
                ratings_file = Path("data/movielens/ratings.csv")
                movies_file = Path("data/movielens/movies.csv")
                users_file = Path("data/movielens/users.csv")
                
                if not all([ratings_file.exists(), movies_file.exists(), users_file.exists()]):
                    print("âŒ MovieLensæ ·æœ¬æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
                    print("è¯·æ£€æŸ¥ data/movielens/ æ–‡ä»¶å¤¹")
                    return False
                
                # åŠ è½½è¯„åˆ†æ•°æ®
                self.ratings = pd.read_csv(ratings_file)
                # ç¡®ä¿åˆ—åä¸€è‡´
                if 'item_id' in self.ratings.columns:
                    self.ratings = self.ratings.rename(columns={'item_id': 'movie_id'})
                
                # åŠ è½½ç”µå½±æ•°æ®
                self.movies = pd.read_csv(movies_file)
                if 'item_id' in self.movies.columns:
                    self.movies = self.movies.rename(columns={'item_id': 'movie_id'})
                
                # åŠ è½½ç”¨æˆ·æ•°æ®
                self.users = pd.read_csv(users_file)
                
            elif dataset_size == "small":
                # MovieLens 100K dataset
                ratings_file = self.data_path / "u.data"
                movies_file = self.data_path / "u.item"
                users_file = self.data_path / "u.user"
                
                if not all([ratings_file.exists(), movies_file.exists(), users_file.exists()]):
                    print("âŒ MovieLensæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆä¸‹è½½æ•°æ®é›†")
                    print("è¯·è®¿é—®: https://grouplens.org/datasets/movielens/100k/")
                    return False
                
                # åŠ è½½è¯„åˆ†æ•°æ®
                self.ratings = pd.read_csv(
                    ratings_file, 
                    sep='\t', 
                    names=['user_id', 'movie_id', 'rating', 'timestamp'],
                    dtype={'user_id': int, 'movie_id': int, 'rating': int, 'timestamp': int}
                )
                
                # åŠ è½½ç”µå½±æ•°æ®
                movie_columns = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url'] + \
                               [f'genre_{i}' for i in range(19)]  # 19ä¸ªç±»å‹æ ‡ç­¾
                
                self.movies = pd.read_csv(
                    movies_file,
                    sep='|',
                    names=movie_columns,
                    encoding='latin-1',
                    dtype={'movie_id': int}
                )
                
                # åŠ è½½ç”¨æˆ·æ•°æ®
                self.users = pd.read_csv(
                    users_file,
                    sep='|',
                    names=['user_id', 'age', 'gender', 'occupation', 'zip_code'],
                    dtype={'user_id': int, 'age': int}
                )
                
            else:
                print(f"âŒ æš‚ä¸æ”¯æŒ{dataset_size}æ•°æ®é›†ï¼Œè¯·ä½¿ç”¨smallç‰ˆæœ¬")
                return False
                
            print(f"âœ… æˆåŠŸåŠ è½½MovieLensæ•°æ®:")
            print(f"   ç”¨æˆ·æ•°: {len(self.users)}")
            print(f"   ç”µå½±æ•°: {len(self.movies)}")
            print(f"   è¯„åˆ†æ•°: {len(self.ratings)}")
            print(f"   è¯„åˆ†èŒƒå›´: {self.ratings['rating'].min()}-{self.ratings['rating'].max()}")
            print(f"   ç¨€ç–åº¦: {(1 - len(self.ratings) / (len(self.users) * len(self.movies))) * 100:.2f}%")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½MovieLensæ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def create_sample_data(self) -> bool:
        """åˆ›å»ºæ ·æœ¬æ•°æ®ç”¨äºæµ‹è¯•ï¼ˆå½“çœŸå®æ•°æ®ä¸å¯ç”¨æ—¶ï¼‰"""
        print("ğŸ“ åˆ›å»ºMovieLensæ ·æœ¬æ•°æ®ç”¨äºæµ‹è¯•...")
        
        # åˆ›å»ºæ ·æœ¬ç”¨æˆ·
        self.users = pd.DataFrame({
            'user_id': range(1, 101),
            'age': np.random.randint(18, 65, 100),
            'gender': np.random.choice(['M', 'F'], 100),
            'occupation': np.random.choice(['student', 'engineer', 'teacher', 'doctor'], 100),
            'zip_code': [f'{np.random.randint(10000, 99999)}' for _ in range(100)]
        })
        
        # åˆ›å»ºæ ·æœ¬ç”µå½±
        movie_titles = [
            "The Matrix", "Inception", "Interstellar", "Blade Runner 2049", "The Dark Knight",
            "Pulp Fiction", "The Godfather", "Schindler's List", "The Shawshank Redemption",
            "Forrest Gump", "Goodfellas", "The Silence of the Lambs", "Saving Private Ryan",
            "Titanic", "Avatar", "The Avengers", "Iron Man", "Spider-Man", "Batman Begins",
            "Jurassic Park", "Star Wars", "Lord of the Rings", "Harry Potter", "Pirates of the Caribbean",
            "Mission Impossible", "Fast & Furious", "John Wick", "Mad Max", "Terminator", "Alien"
        ]
        
        self.movies = pd.DataFrame({
            'movie_id': range(1, len(movie_titles) + 1),
            'title': movie_titles,
            'release_date': ['01-Jan-' + str(np.random.randint(1990, 2024)) for _ in movie_titles],
            'video_release_date': [''] * len(movie_titles),
            'imdb_url': [f'http://us.imdb.com/M/title-exact?{title.replace(" ", "+")}' for title in movie_titles]
        })
        
        # æ·»åŠ ç±»å‹ä¿¡æ¯
        genres = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary',
                 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',
                 'Sci-Fi', 'Thriller', 'War', 'Western']
        
        for i, genre in enumerate(genres):
            self.movies[f'genre_{i}'] = np.random.choice([0, 1], len(movie_titles), p=[0.8, 0.2])
        
        # åˆ›å»ºæ ·æœ¬è¯„åˆ†
        n_ratings = 5000
        user_ids = np.random.choice(self.users['user_id'], n_ratings)
        movie_ids = np.random.choice(self.movies['movie_id'], n_ratings)
        ratings = np.random.choice([1, 2, 3, 4, 5], n_ratings, p=[0.1, 0.1, 0.2, 0.4, 0.2])
        timestamps = np.random.randint(800000000, 1600000000, n_ratings)
        
        self.ratings = pd.DataFrame({
            'user_id': user_ids,
            'movie_id': movie_ids,
            'rating': ratings,
            'timestamp': timestamps
        }).drop_duplicates(subset=['user_id', 'movie_id'])
        
        print(f"âœ… æ ·æœ¬æ•°æ®åˆ›å»ºå®Œæˆ:")
        print(f"   ç”¨æˆ·æ•°: {len(self.users)}")
        print(f"   ç”µå½±æ•°: {len(self.movies)}")
        print(f"   è¯„åˆ†æ•°: {len(self.ratings)}")
        
        return True
    
    def build_user_profiles(self) -> Dict:
        """æ„å»ºç”¨æˆ·ç”»åƒ"""
        print("ğŸ‘¤ æ„å»ºç”¨æˆ·ç”»åƒ...")
        
        user_profiles = {}
        
        for user_id in self.users['user_id'].unique():
            # åŸºæœ¬ä¿¡æ¯
            user_info = self.users[self.users['user_id'] == user_id].iloc[0]
            user_ratings = self.ratings[self.ratings['user_id'] == user_id]
            
            if len(user_ratings) == 0:
                continue
            
            # è¯„åˆ†ç»Ÿè®¡
            avg_rating = user_ratings['rating'].mean()
            total_ratings = len(user_ratings)
            
            # ç±»å‹åå¥½åˆ†æ
            favorite_genres = self._analyze_genre_preferences(user_id)
            
            # è¯„åˆ†è¡Œä¸ºåˆ†æ
            rating_distribution = user_ratings['rating'].value_counts().to_dict()
            
            user_profiles[user_id] = {
                'user_id': user_id,
                'age': int(user_info['age']),
                'gender': user_info['gender'],
                'occupation': user_info['occupation'],
                'avg_rating': round(avg_rating, 2),
                'total_ratings': total_ratings,
                'favorite_genres': favorite_genres,
                'rating_distribution': rating_distribution,
                'viewing_history': user_ratings['movie_id'].tolist()[-10:]  # æœ€è¿‘10éƒ¨ç”µå½±
            }
        
        self.user_profiles = user_profiles
        print(f"âœ… ç”¨æˆ·ç”»åƒæ„å»ºå®Œæˆï¼Œè¦†ç›–{len(user_profiles)}ä¸ªç”¨æˆ·")
        
        return user_profiles
    
    def _analyze_genre_preferences(self, user_id: int) -> List[str]:
        """åˆ†æç”¨æˆ·ç±»å‹åå¥½"""
        user_ratings = self.ratings[self.ratings['user_id'] == user_id]
        
        # è·å–ç”¨æˆ·è¯„åˆ†è¿‡çš„ç”µå½±
        user_movies = self.movies[self.movies['movie_id'].isin(user_ratings['movie_id'])]
        
        # è®¡ç®—å„ç±»å‹çš„å¹³å‡è¯„åˆ†
        genre_cols = [col for col in self.movies.columns if col.startswith('genre_')]
        genre_names = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary',
                      'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance',
                      'Sci-Fi', 'Thriller', 'War', 'Western']
        
        genre_scores = {}
        
        for i, genre_col in enumerate(genre_cols):
            if i < len(genre_names):
                genre_movies = user_movies[user_movies[genre_col] == 1]
                if len(genre_movies) > 0:
                    # è®¡ç®—è¯¥ç±»å‹ç”µå½±çš„å¹³å‡è¯„åˆ†
                    genre_ratings = user_ratings[user_ratings['movie_id'].isin(genre_movies['movie_id'])]
                    if len(genre_ratings) > 0:
                        avg_score = genre_ratings['rating'].mean()
                        genre_scores[genre_names[i]] = avg_score
        
        # è¿”å›è¯„åˆ†æœ€é«˜çš„å‰3ä¸ªç±»å‹
        sorted_genres = sorted(genre_scores.items(), key=lambda x: x[1], reverse=True)
        return [genre for genre, score in sorted_genres[:3]]
    
    def get_llm_recommendations(self, user_id: int, candidate_movies: List[Dict], 
                               model_choice: str = "primary", top_k: int = 10) -> Dict:
        """è·å–LLMæ¨èç»“æœ"""
        
        if user_id not in self.user_profiles:
            return {"error": f"ç”¨æˆ·{user_id}ç”»åƒä¸å­˜åœ¨"}
        
        user_profile = self.user_profiles[user_id]
        model_name = self.primary_model if model_choice == "primary" else self.secondary_model
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_recommendation_prompt(user_profile, candidate_movies, model_choice, top_k)
        
        try:
            print(f"ğŸ¤– ä½¿ç”¨{model_name}ä¸ºç”¨æˆ·{user_id}ç”Ÿæˆæ¨è...")
            
            response = requests.post(self.ollama_endpoint, json={
                "model": model_name,
                "prompt": prompt,
                "stream": False
            }, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                return self._parse_llm_response(result['response'], model_choice)
            else:
                return {"error": f"LLM APIè°ƒç”¨å¤±è´¥: {response.status_code}"}
                
        except Exception as e:
            return {"error": f"LLMæ¨èç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _build_recommendation_prompt(self, user_profile: Dict, candidate_movies: List[Dict], 
                                   model_choice: str, top_k: int) -> str:
        """æ„å»ºæ¨èæç¤ºè¯"""
        
        # è·å–ç”¨æˆ·è§‚å½±å†å²çš„ç”µå½±æ ‡é¢˜
        history_movies = self.movies[self.movies['movie_id'].isin(user_profile['viewing_history'])]
        history_titles = history_movies['title'].tolist()
        
        if model_choice == "primary":  # Llama3è‹±æ–‡æç¤ºè¯
            candidates_text = "\n".join([
                f"- Movie {movie['movie_id']}: {movie['title']} ({movie.get('genres', 'Unknown')})"
                for movie in candidate_movies
            ])
            
            prompt = f"""You are an expert movie recommendation system trained on MovieLens data. Analyze this real user profile and recommend the top {top_k} movies.

REAL USER PROFILE:
- User ID: {user_profile['user_id']}
- Age: {user_profile['age']} years old
- Gender: {user_profile['gender']}
- Occupation: {user_profile['occupation']}
- Average Rating: {user_profile['avg_rating']}/5.0 ({user_profile['total_ratings']} movies rated)
- Favorite Genres: {', '.join(user_profile['favorite_genres'])}
- Recent Viewing History: {', '.join(history_titles[-5:]) if history_titles else 'No history available'}

CANDIDATE MOVIES:
{candidates_text}

INSTRUCTIONS:
1. Consider the user's genre preferences and rating patterns
2. Account for the user's demographic profile (age, gender, occupation)
3. Predict realistic ratings based on the user's average rating behavior
4. Provide confidence scores based on profile match
5. Give brief explanations for recommendations

OUTPUT FORMAT (JSON only):
[
  {{"movie_id": 1, "title": "Movie Title", "predicted_rating": 4.2, "confidence": 0.85, "reason": "Brief explanation"}}
]
"""
        
        else:  # Qwen3ä¸­æ–‡æç¤ºè¯
            candidates_text = "\n".join([
                f"- ç”µå½±{movie['movie_id']}: {movie['title']} ({movie.get('genres', 'æœªçŸ¥ç±»å‹')})"
                for movie in candidate_movies
            ])
            
            prompt = f"""ä½ æ˜¯åŸºäºMovieLensæ•°æ®è®­ç»ƒçš„ä¸“ä¸šç”µå½±æ¨èç³»ç»Ÿã€‚åˆ†æçœŸå®ç”¨æˆ·æ¡£æ¡ˆï¼Œæ¨èæœ€é€‚åˆçš„{top_k}éƒ¨ç”µå½±ã€‚

çœŸå®ç”¨æˆ·æ¡£æ¡ˆï¼š
- ç”¨æˆ·IDï¼š{user_profile['user_id']}
- å¹´é¾„ï¼š{user_profile['age']}å²
- æ€§åˆ«ï¼š{user_profile['gender']}
- èŒä¸šï¼š{user_profile['occupation']}
- å¹³å‡è¯„åˆ†ï¼š{user_profile['avg_rating']}/5.0 (å·²è¯„åˆ†{user_profile['total_ratings']}éƒ¨ç”µå½±)
- åå¥½ç±»å‹ï¼š{', '.join(user_profile['favorite_genres'])}
- è¿‘æœŸè§‚å½±ï¼š{', '.join(history_titles[-5:]) if history_titles else 'æ— è§‚å½±è®°å½•'}

å€™é€‰ç”µå½±ï¼š
{candidates_text}

ä»»åŠ¡è¦æ±‚ï¼š
1. è€ƒè™‘ç”¨æˆ·çš„ç±»å‹åå¥½å’Œè¯„åˆ†æ¨¡å¼
2. ç»“åˆç”¨æˆ·äººå£ç»Ÿè®¡ç‰¹å¾ (å¹´é¾„ã€æ€§åˆ«ã€èŒä¸š)
3. åŸºäºç”¨æˆ·å¹³å‡è¯„åˆ†è¡Œä¸ºé¢„æµ‹çœŸå®è¯„åˆ†
4. æ ¹æ®æ¡£æ¡ˆåŒ¹é…åº¦æä¾›ç½®ä¿¡åº¦åˆ†æ•°
5. ä¸ºæ¨èæä¾›ç®€æ´è§£é‡Š

è¾“å‡ºæ ¼å¼ (ä»…JSON):
[
  {{"movie_id": 1, "title": "ç”µå½±æ ‡é¢˜", "predicted_rating": 4.2, "confidence": 0.85, "reason": "ç®€è¦è§£é‡Š"}}
]
"""
        
        return prompt
    
    def _parse_llm_response(self, response_text: str, model_choice: str) -> Dict:
        """è§£æLLMå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            start_idx = response_text.find('[')
            end_idx = response_text.rfind(']') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_text = response_text[start_idx:end_idx]
                recommendations = json.loads(json_text)
                
                return {
                    "model": f"Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                    "recommendations": recommendations,
                    "status": "success"
                }
            else:
                return {
                    "model": f"Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                    "raw_response": response_text[:500] + "..." if len(response_text) > 500 else response_text,
                    "status": "parse_failed"
                }
                
        except json.JSONDecodeError as e:
            return {
                "model": f"Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                "error": f"JSONè§£æå¤±è´¥: {str(e)}",
                "raw_response": response_text[:500] + "..." if len(response_text) > 500 else response_text,
                "status": "json_error"
            }


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºçœŸå®MovieLensæ•°æ®çš„LLMæ¨è"""
    print("ğŸ¬ MovieLensæ•°æ®é›† + LLMæ¨èéªŒè¯ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆå§‹åŒ–éªŒè¯å™¨
    validator = MovieLensLLMValidator()
    
    # å°è¯•åŠ è½½çœŸå®æ•°æ®ï¼Œå¤±è´¥åˆ™ä½¿ç”¨æ ·æœ¬æ•°æ®
    if not validator.load_movielens_data("small"):
        print("âš ï¸  çœŸå®MovieLensæ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ·æœ¬æ•°æ®è¿›è¡Œæ¼”ç¤º")
        if not validator.create_sample_data():
            print("âŒ æ ·æœ¬æ•°æ®åˆ›å»ºå¤±è´¥")
            return
    
    # æ„å»ºç”¨æˆ·ç”»åƒ
    user_profiles = validator.build_user_profiles()
    
    if not user_profiles:
        print("âŒ ç”¨æˆ·ç”»åƒæ„å»ºå¤±è´¥")
        return
    
    # é€‰æ‹©æµ‹è¯•ç”¨æˆ· (è¯„åˆ†æ•°é‡è¶³å¤Ÿçš„ç”¨æˆ·)
    test_users = []
    for user_id, profile in user_profiles.items():
        if profile['total_ratings'] >= 5:  # è‡³å°‘è¯„åˆ†è¿‡5éƒ¨ç”µå½±
            test_users.append(user_id)
        if len(test_users) >= 3:  # æµ‹è¯•3ä¸ªç”¨æˆ·
            break
    
    if not test_users:
        test_users = list(user_profiles.keys())[:3]
    
    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•ç”¨æˆ·: {test_users}")
    
    # ä¸ºæ¯ä¸ªæµ‹è¯•ç”¨æˆ·ç”Ÿæˆæ¨è
    for user_id in test_users:
        print(f"\n" + "="*50)
        print(f"ğŸ‘¤ æµ‹è¯•ç”¨æˆ· {user_id}")
        print("="*50)
        
        user_profile = user_profiles[user_id]
        print(f"ç”¨æˆ·ä¿¡æ¯: {user_profile['age']}å² {user_profile['gender']} {user_profile['occupation']}")
        print(f"è¯„åˆ†ç»Ÿè®¡: å¹³å‡{user_profile['avg_rating']}/5.0, å·²è¯„åˆ†{user_profile['total_ratings']}éƒ¨")
        print(f"åå¥½ç±»å‹: {', '.join(user_profile['favorite_genres'])}")
        
        # è·å–å€™é€‰ç”µå½± (ç”¨æˆ·æœªè¯„åˆ†è¿‡çš„ç”µå½±)
        user_rated_movies = set(validator.ratings[validator.ratings['user_id'] == user_id]['movie_id'])
        all_movies = set(validator.movies['movie_id'])
        candidate_movie_ids = list(all_movies - user_rated_movies)[:20]  # éšæœºé€‰æ‹©20éƒ¨å€™é€‰ç”µå½±
        
        candidate_movies = []
        for movie_id in candidate_movie_ids:
            movie_info = validator.movies[validator.movies['movie_id'] == movie_id].iloc[0]
            candidate_movies.append({
                'movie_id': movie_id,
                'title': movie_info['title'],
                'genres': 'Mixed'  # ç®€åŒ–å¤„ç†
            })
        
        print(f"å€™é€‰ç”µå½±: {len(candidate_movies)}éƒ¨")
        
        # è·å–LLMæ¨è (ä»…æµ‹è¯•ä¸»åŠ›æ¨¡å‹ä»¥èŠ‚çœæ—¶é—´)
        llm_result = validator.get_llm_recommendations(
            user_id, candidate_movies, "primary", top_k=5
        )
        
        print(f"\nğŸ¤– Llama3æ¨èç»“æœ:")
        if llm_result.get("status") == "success":
            for i, rec in enumerate(llm_result["recommendations"][:5], 1):
                print(f"   {i}. {rec.get('title', 'N/A')} "
                      f"(é¢„æµ‹è¯„åˆ†: {rec.get('predicted_rating', 'N/A'):.1f}, "
                      f"ç½®ä¿¡åº¦: {rec.get('confidence', 'N/A'):.2f})")
                if 'reason' in rec:
                    print(f"      ç†ç”±: {rec['reason']}")
        else:
            print(f"   âŒ æ¨èå¤±è´¥: {llm_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    print(f"\nğŸ‰ MovieLens + LLMæ¨èæµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
