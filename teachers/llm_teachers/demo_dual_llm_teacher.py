#!/usr/bin/env python3
"""
åŒè¯­LLM Teacheræ¨èç³»ç»Ÿæ¼”ç¤º
Demo: Dual Language LLM Teacher Recommendation System

æ”¯æŒçš„æ¨¡å‹:
- Llama3 (è‹±æ–‡ä¸»åŠ›) - é€‚é…MovieLensè‹±æ–‡æ•°æ®
- Qwen3 (ä¸­æ–‡å¯¹ç…§) - è·¨è¯­è¨€æ¨èç ”ç©¶

ä½œè€…: GitHub Copilot
æ—¥æœŸ: 2025-08-18
"""

import json
import requests
import time
from typing import Dict, List, Any

class DualLanguageLLMTeacher:
    """åŒè¯­LLMæ¨èTeacher - è‹±æ–‡ä¸»åŠ›+ä¸­æ–‡å¯¹ç…§"""
    
    def __init__(self, ollama_endpoint="http://localhost:11434/api/generate"):
        self.ollama_endpoint = ollama_endpoint
        self.primary_model = "llama3:latest"    # è‹±æ–‡ä¸»åŠ› (MovieLensé€‚é…)
        self.secondary_model = "qwen3:latest"   # ä¸­æ–‡å¯¹ç…§ (è·¨è¯­è¨€ç ”ç©¶)
        
    def get_recommendation(self, user_profile: Dict, candidates: List[Dict], 
                          model_choice: str = "primary", top_k: int = 5) -> Dict:
        """
        è·å–LLMæ¨èç»“æœ
        
        Args:
            user_profile: ç”¨æˆ·æ¡£æ¡ˆ
            candidates: å€™é€‰ç”µå½±åˆ—è¡¨
            model_choice: "primary" (Llama3) æˆ– "secondary" (Qwen3)
            top_k: æ¨èæ•°é‡
        """
        model_name = self.primary_model if model_choice == "primary" else self.secondary_model
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(user_profile, candidates, model_choice, top_k)
        
        try:
            print(f"ğŸ¤– Using {model_name} ({'è‹±æ–‡ä¸»åŠ›' if model_choice == 'primary' else 'ä¸­æ–‡å¯¹ç…§'})...")
            
            # è°ƒç”¨Ollama API
            response = requests.post(self.ollama_endpoint, json={
                "model": model_name,
                "prompt": prompt,
                "stream": False
            }, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                return self._parse_response(result['response'], model_choice)
            else:
                return {"error": f"APIè°ƒç”¨å¤±è´¥: {response.status_code}"}
                
        except Exception as e:
            return {"error": f"æ¨èç”Ÿæˆå¤±è´¥: {str(e)}"}
    
    def _build_prompt(self, user_profile: Dict, candidates: List[Dict], 
                     model_choice: str, top_k: int) -> str:
        """æ„å»ºé’ˆå¯¹ä¸åŒè¯­è¨€æ¨¡å‹çš„æç¤ºè¯"""
        
        if model_choice == "primary":  # Llama3 è‹±æ–‡æç¤ºè¯
            candidates_text = "\n".join([
                f"- Movie {i+1}: {movie['title']} (Genre: {movie['genre']}, Year: {movie['year']})"
                for i, movie in enumerate(candidates)
            ])
            
            prompt = f"""You are an expert movie recommendation system. Based on the user's profile, recommend the top {top_k} movies from the candidate list.

User Profile:
- User ID: {user_profile['user_id']}
- Age: {user_profile['age']}
- Favorite Genres: {', '.join(user_profile['favorite_genres'])}
- Previous Ratings: {user_profile['avg_rating']:.1f}/5.0 average
- Viewing History: {user_profile['movies_watched']} movies watched

Candidate Movies:
{candidates_text}

Please analyze the user's preferences and recommend the most suitable movies. 
Output format: JSON array with movie_id, title, predicted_rating (1-5), confidence (0-1), and brief reason.

Example output:
[
  {{"movie_id": 1, "title": "Movie Title", "predicted_rating": 4.2, "confidence": 0.85, "reason": "Matches user's preference for action films"}}
]
"""
        
        else:  # Qwen3 ä¸­æ–‡æç¤ºè¯
            candidates_text = "\n".join([
                f"- ç”µå½±{i+1}: {movie['title']} (ç±»å‹: {movie['genre']}, å¹´ä»½: {movie['year']})"
                for i, movie in enumerate(candidates)
            ])
            
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µå½±æ¨èç³»ç»Ÿä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æ¡£æ¡ˆï¼Œä»å€™é€‰ç”µå½±ä¸­æ¨èæœ€é€‚åˆçš„{top_k}éƒ¨ç”µå½±ã€‚

ç”¨æˆ·æ¡£æ¡ˆï¼š
- ç”¨æˆ·IDï¼š{user_profile['user_id']}
- å¹´é¾„ï¼š{user_profile['age']}å²
- åå¥½ç±»å‹ï¼š{', '.join(user_profile['favorite_genres'])}
- å†å²è¯„åˆ†ï¼šå¹³å‡{user_profile['avg_rating']:.1f}/5.0åˆ†
- è§‚å½±æ•°é‡ï¼šå·²è§‚çœ‹{user_profile['movies_watched']}éƒ¨ç”µå½±

å€™é€‰ç”µå½±ï¼š
{candidates_text}

è¯·åˆ†æç”¨æˆ·åå¥½ï¼Œæ¨èæœ€é€‚åˆçš„ç”µå½±ã€‚
è¾“å‡ºæ ¼å¼ï¼šJSONæ•°ç»„ï¼ŒåŒ…å«movie_id, title, predicted_rating (1-5), confidence (0-1), reasonã€‚

ç¤ºä¾‹è¾“å‡ºï¼š
[
  {{"movie_id": 1, "title": "ç”µå½±æ ‡é¢˜", "predicted_rating": 4.2, "confidence": 0.85, "reason": "ç¬¦åˆç”¨æˆ·å¯¹åŠ¨ä½œç‰‡çš„åå¥½"}}
]
"""
        
        return prompt
    
    def _parse_response(self, response_text: str, model_choice: str) -> Dict:
        """è§£æLLMå“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response_text.find('[')
            end_idx = response_text.rfind(']') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_text = response_text[start_idx:end_idx]
                recommendations = json.loads(json_text)
                
                return {
                    "model": "Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                    "recommendations": recommendations,
                    "status": "success"
                }
            else:
                return {
                    "model": "Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                    "raw_response": response_text,
                    "status": "parse_failed"
                }
                
        except json.JSONDecodeError:
            return {
                "model": "Llama3 (è‹±æ–‡)" if model_choice == "primary" else "Qwen3 (ä¸­æ–‡)",
                "raw_response": response_text,
                "status": "json_error"
            }
    
    def compare_dual_recommendations(self, user_profile: Dict, candidates: List[Dict], 
                                   top_k: int = 5) -> Dict:
        """å¯¹æ¯”åŒè¯­æ¨¡å‹æ¨èæ•ˆæœ"""
        print("ğŸŒ å¼€å§‹åŒè¯­LLMæ¨èå¯¹æ¯”å®éªŒ...")
        
        # è·å–Llama3è‹±æ–‡æ¨è
        llama3_result = self.get_recommendation(user_profile, candidates, "primary", top_k)
        time.sleep(1)  # é¿å…APIè°ƒç”¨è¿‡å¿«
        
        # è·å–Qwen3ä¸­æ–‡æ¨è
        qwen3_result = self.get_recommendation(user_profile, candidates, "secondary", top_k)
        
        # è®¡ç®—é‡å åº¦
        overlap_score = self._calculate_overlap(llama3_result, qwen3_result)
        
        return {
            "llama3_english": llama3_result,
            "qwen3_chinese": qwen3_result,
            "overlap_score": overlap_score,
            "comparison_summary": self._generate_comparison_summary(llama3_result, qwen3_result)
        }
    
    def _calculate_overlap(self, result1: Dict, result2: Dict) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ¨èç»“æœçš„é‡å åº¦"""
        try:
            if (result1.get("status") != "success" or 
                result2.get("status") != "success"):
                return 0.0
            
            recs1 = {rec["movie_id"] for rec in result1["recommendations"]}
            recs2 = {rec["movie_id"] for rec in result2["recommendations"]}
            
            if not recs1 or not recs2:
                return 0.0
            
            intersection = len(recs1 & recs2)
            union = len(recs1 | recs2)
            
            return intersection / union if union > 0 else 0.0
            
        except:
            return 0.0
    
    def _generate_comparison_summary(self, llama3_result: Dict, qwen3_result: Dict) -> str:
        """ç”Ÿæˆå¯¹æ¯”æ‘˜è¦"""
        summary = []
        
        if llama3_result.get("status") == "success":
            summary.append("âœ… Llama3è‹±æ–‡æ¨èæˆåŠŸ")
        else:
            summary.append("âŒ Llama3è‹±æ–‡æ¨èå¤±è´¥")
        
        if qwen3_result.get("status") == "success":
            summary.append("âœ… Qwen3ä¸­æ–‡æ¨èæˆåŠŸ")
        else:
            summary.append("âŒ Qwen3ä¸­æ–‡æ¨èå¤±è´¥")
        
        return " | ".join(summary)


def demo_movie_recommendation():
    """æ¼”ç¤ºåŒè¯­ç”µå½±æ¨è"""
    print("ğŸ¬ åŒè¯­LLM Teacherç”µå½±æ¨èç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–åŒè¯­æ¨èç³»ç»Ÿ
    dual_teacher = DualLanguageLLMTeacher()
    
    # æ¨¡æ‹Ÿç”¨æˆ·æ¡£æ¡ˆ (MovieLensé£æ ¼)
    user_profile = {
        "user_id": 123,
        "age": 28,
        "favorite_genres": ["Action", "Sci-Fi", "Thriller"],
        "avg_rating": 4.2,
        "movies_watched": 156
    }
    
    # æ¨¡æ‹Ÿå€™é€‰ç”µå½±
    candidates = [
        {"movie_id": 1, "title": "The Matrix", "genre": "Sci-Fi", "year": 1999},
        {"movie_id": 2, "title": "John Wick", "genre": "Action", "year": 2014},
        {"movie_id": 3, "title": "Inception", "genre": "Sci-Fi", "year": 2010},
        {"movie_id": 4, "title": "The Notebook", "genre": "Romance", "year": 2004},
        {"movie_id": 5, "title": "Mad Max: Fury Road", "genre": "Action", "year": 2015},
        {"movie_id": 6, "title": "Interstellar", "genre": "Sci-Fi", "year": 2014},
        {"movie_id": 7, "title": "Die Hard", "genre": "Action", "year": 1988},
        {"movie_id": 8, "title": "Blade Runner 2049", "genre": "Sci-Fi", "year": 2017}
    ]
    
    print(f"ğŸ‘¤ ç”¨æˆ·æ¡£æ¡ˆ:")
    print(f"   ID: {user_profile['user_id']}")
    print(f"   å¹´é¾„: {user_profile['age']}å²")
    print(f"   åå¥½ç±»å‹: {', '.join(user_profile['favorite_genres'])}")
    print(f"   å¹³å‡è¯„åˆ†: {user_profile['avg_rating']}/5.0")
    print(f"   è§‚å½±æ•°é‡: {user_profile['movies_watched']}éƒ¨")
    print()
    
    print(f"ğŸ­ å€™é€‰ç”µå½± ({len(candidates)}éƒ¨):")
    for movie in candidates:
        print(f"   [{movie['movie_id']}] {movie['title']} ({movie['genre']}, {movie['year']})")
    print()
    
    # æ‰§è¡ŒåŒè¯­æ¨èå¯¹æ¯”
    comparison_result = dual_teacher.compare_dual_recommendations(
        user_profile, candidates, top_k=5
    )
    
    # å±•ç¤ºç»“æœ
    print("ğŸ“Š åŒè¯­æ¨èå¯¹æ¯”ç»“æœ:")
    print("=" * 50)
    
    # Llama3è‹±æ–‡ç»“æœ
    llama3_result = comparison_result["llama3_english"]
    print("ğŸ‡ºğŸ‡¸ Llama3 (è‹±æ–‡ä¸»åŠ›) æ¨èç»“æœ:")
    if llama3_result.get("status") == "success":
        for i, rec in enumerate(llama3_result["recommendations"][:5], 1):
            print(f"   {i}. {rec.get('title', 'N/A')} "
                  f"(é¢„æµ‹è¯„åˆ†: {rec.get('predicted_rating', 'N/A')}, "
                  f"ç½®ä¿¡åº¦: {rec.get('confidence', 'N/A')})")
            if 'reason' in rec:
                print(f"      ç†ç”±: {rec['reason']}")
    else:
        print(f"   âŒ æ¨èå¤±è´¥: {llama3_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    print()
    
    # Qwen3ä¸­æ–‡ç»“æœ
    qwen3_result = comparison_result["qwen3_chinese"]
    print("ğŸ‡¨ğŸ‡³ Qwen3 (ä¸­æ–‡å¯¹ç…§) æ¨èç»“æœ:")
    if qwen3_result.get("status") == "success":
        for i, rec in enumerate(qwen3_result["recommendations"][:5], 1):
            print(f"   {i}. {rec.get('title', 'N/A')} "
                  f"(é¢„æµ‹è¯„åˆ†: {rec.get('predicted_rating', 'N/A')}, "
                  f"ç½®ä¿¡åº¦: {rec.get('confidence', 'N/A')})")
            if 'reason' in rec:
                print(f"      ç†ç”±: {rec['reason']}")
    else:
        print(f"   âŒ æ¨èå¤±è´¥: {qwen3_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    print()
    
    # å¯¹æ¯”åˆ†æ
    print("ğŸ”„ è·¨è¯­è¨€æ¨èåˆ†æ:")
    print(f"   é‡å åº¦: {comparison_result['overlap_score']:.3f}")
    print(f"   çŠ¶æ€æ‘˜è¦: {comparison_result['comparison_summary']}")
    
    return comparison_result


if __name__ == "__main__":
    try:
        # æ£€æŸ¥OllamaæœåŠ¡
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
            demo_result = demo_movie_recommendation()
        else:
            print("âŒ OllamaæœåŠ¡æ— æ³•è®¿é—®")
    
    except requests.exceptions.RequestException:
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
        print("   å¯åŠ¨å‘½ä»¤: ollama serve")
