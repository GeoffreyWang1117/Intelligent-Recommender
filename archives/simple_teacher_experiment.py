#!/usr/bin/env python3
"""
ç®€åŒ–CPU Teacheræ¨¡å‹å®éªŒ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import time
import logging
from typing import Dict, List
from collections import defaultdict

# å¼ºåˆ¶CPUæ¨¡å¼
import torch
torch.device('cpu')

from models import create_recommender

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def simple_jaccard_similarity(set1: set, set2: set) -> float:
    """è®¡ç®—Jaccardç›¸ä¼¼åº¦"""
    if not set1 and not set2:
        return 1.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0.0


def run_simple_teacher_experiment():
    """è¿è¡Œç®€åŒ–Teacheræ¨¡å‹å®éªŒ"""
    print("ğŸ“ ç®€åŒ–Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®
    print("ğŸ“Š åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®...")
    np.random.seed(42)
    
    interactions = []
    for _ in range(3000):
        user_id = np.random.randint(1, 201)  # 200ç”¨æˆ·
        item_id = np.random.randint(1, 151)  # 150ç‰©å“
        rating = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        timestamp = int(time.time()) + np.random.randint(-86400*30, 86400*30)
        
        interactions.append({
            'user_id': user_id,
            'item_id': item_id,
            'rating': rating,
            'timestamp': timestamp
        })
    
    train_data = pd.DataFrame(interactions)
    train_data = train_data.drop_duplicates(['user_id', 'item_id'])
    
    print(f"âœ… ç”Ÿæˆäº† {len(train_data)} æ¡å”¯ä¸€äº¤äº’æ•°æ®")
    
    # Teacheræ¨¡å‹é…ç½®
    algorithms = ['deepfm', 'autoint', 'transformer4rec', 'xdeepfm']
    
    model_configs = {
        'deepfm': {
            'embedding_dim': 8,
            'learning_rate': 0.001,
            'epochs': 10,
            'batch_size': 64,
            'early_stopping': False
        },
        'autoint': {
            'embedding_dim': 8,
            'learning_rate': 0.001,
            'epochs': 10,
            'num_heads': 2,
            'num_layers': 2,
            'early_stopping': False
        },
        'transformer4rec': {
            'embedding_dim': 16,
            'num_heads': 2,
            'num_layers': 2,
            'learning_rate': 0.001,
            'epochs': 8,
            'batch_size': 64,
            'early_stopping': False
        },
        'xdeepfm': {
            'embedding_dim': 8,
            'cin_layer_sizes': [32, 32],
            'dnn_hidden_dims': [64, 32],
            'learning_rate': 0.001,
            'epochs': 8,
            'batch_size': 64,
            'early_stopping': False
        }
    }
    
    # è®­ç»ƒæ¨¡å‹
    trained_models = {}
    
    for algo_name in algorithms:
        print(f"\nğŸ“š è®­ç»ƒ {algo_name}...")
        
        try:
            config = model_configs[algo_name]
            
            start_time = time.time()
            model = create_recommender(algo_name, **config)
            
            if model is None:
                print(f"âŒ æ— æ³•åˆ›å»ºç®—æ³•: {algo_name}")
                continue
            
            # å¼ºåˆ¶CPUæ¨¡å¼
            if hasattr(model, 'device'):
                model.device = torch.device('cpu')
            
            model.fit(train_data, **config)
            end_time = time.time()
            
            if model.is_trained:
                trained_models[algo_name] = model
                print(f"âœ… {algo_name} è®­ç»ƒæˆåŠŸ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
            else:
                print(f"âŒ {algo_name} è®­ç»ƒå¤±è´¥")
                
        except Exception as e:
            print(f"âŒ è®­ç»ƒ {algo_name} æ—¶å‡ºé”™: {str(e)[:100]}...")
    
    print(f"\nğŸ¯ è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒäº† {len(trained_models)} ä¸ªTeacheræ¨¡å‹")
    print(f"æˆåŠŸçš„æ¨¡å‹: {list(trained_models.keys())}")
    
    if len(trained_models) < 2:
        print("âŒ è®­ç»ƒæˆåŠŸçš„æ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
        return
    
    # ç”Ÿæˆæ¨è
    print("\nğŸ“Š ç”Ÿæˆæ¨èå¹¶åˆ†æä¸€è‡´æ€§...")
    test_users = train_data['user_id'].unique()[:30]  # æµ‹è¯•30ä¸ªç”¨æˆ·
    
    all_recommendations = {}
    performance_stats = {}
    
    for algo_name, model in trained_models.items():
        print(f"ç”Ÿæˆ {algo_name} çš„æ¨è...")
        
        recommendations = {}
        success_count = 0
        
        for user_id in test_users:
            try:
                recs = model.get_user_recommendations(user_id, top_k=10)
                if recs and len(recs) > 0:
                    recommendations[user_id] = [rec['item_id'] for rec in recs]
                    success_count += 1
            except Exception as e:
                continue
        
        if recommendations:
            all_recommendations[algo_name] = recommendations
            performance_stats[algo_name] = {
                'success_rate': success_count / len(test_users),
                'avg_rec_length': np.mean([len(recs) for recs in recommendations.values()]),
                'total_recommendations': len(recommendations)
            }
            print(f"  æˆåŠŸä¸º {len(recommendations)} ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è (æˆåŠŸç‡: {success_count/len(test_users):.2%})")
    
    # è®¡ç®—ä¸€è‡´æ€§
    print("\nğŸ” è®¡ç®—Teacheræ¨¡å‹é—´ä¸€è‡´æ€§...")
    
    if len(all_recommendations) < 2:
        print("âŒ æ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
        return
    
    algorithms_list = list(all_recommendations.keys())
    jaccard_matrix = {}
    
    # è®¡ç®—Jaccardç›¸ä¼¼åº¦çŸ©é˜µ
    for algo1 in algorithms_list:
        jaccard_matrix[algo1] = {}
        for algo2 in algorithms_list:
            if algo1 == algo2:
                jaccard_matrix[algo1][algo2] = 1.0
            else:
                similarities = []
                
                # æ‰¾åˆ°ä¸¤ä¸ªç®—æ³•éƒ½æœ‰æ¨èçš„ç”¨æˆ·
                common_users = set(all_recommendations[algo1].keys()) & set(all_recommendations[algo2].keys())
                
                for user_id in common_users:
                    recs1 = set(all_recommendations[algo1][user_id][:10])
                    recs2 = set(all_recommendations[algo2][user_id][:10])
                    sim = simple_jaccard_similarity(recs1, recs2)
                    similarities.append(sim)
                
                avg_similarity = np.mean(similarities) if similarities else 0.0
                jaccard_matrix[algo1][algo2] = avg_similarity\n    \n    # ç”ŸæˆæŠ¥å‘Š\n    print(\"\\nğŸ“ ç”ŸæˆTeacheræ¨¡å‹åˆ†ææŠ¥å‘Š...\")\n    \n    report = []\n    report.append(\"# ğŸ“ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†ææŠ¥å‘Š (ç®€åŒ–ç‰ˆ)\")\n    report.append(f\"å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n    report.append(\"\")\n    \n    report.append(\"## ğŸ“Š å®éªŒæ¦‚è¿°\")\n    report.append(f\"- **æˆåŠŸè®­ç»ƒæ¨¡å‹**: {list(trained_models.keys())}\")\n    report.append(f\"- **æ•°æ®é›†è§„æ¨¡**: {len(train_data)} æ¡äº¤äº’\")\n    report.append(f\"- **æµ‹è¯•ç”¨æˆ·æ•°**: {len(test_users)}\")\n    report.append(f\"- **è¿è¡Œæ¨¡å¼**: CPU (ç®€åŒ–ç‰ˆ)\")\n    report.append(\"\")\n    \n    # æ€§èƒ½ç»Ÿè®¡\n    report.append(\"## ğŸ† Teacheræ¨¡å‹æ€§èƒ½ç»Ÿè®¡\")\n    report.append(\"\")\n    report.append(\"| æ¨¡å‹ | æˆåŠŸç‡ | å¹³å‡æ¨èæ•° | æ€»æ¨èæ•° |\")\n    report.append(\"|------|--------|------------|----------|\")\n    \n    for algo_name, stats in performance_stats.items():\n        report.append(f\"| {algo_name} | {stats['success_rate']:.2%} | {stats['avg_rec_length']:.1f} | {stats['total_recommendations']} |\")\n    report.append(\"\")\n    \n    # Jaccardç›¸ä¼¼åº¦çŸ©é˜µ\n    report.append(\"## ğŸ”„ Teacheræ¨¡å‹Jaccardç›¸ä¼¼åº¦çŸ©é˜µ\")\n    report.append(\"\")\n    \n    # æ‰¾åˆ°æœ€ä½å’Œæœ€é«˜ç›¸ä¼¼åº¦\n    min_jaccard = float('inf')\n    max_jaccard = 0.0\n    min_pair = None\n    max_pair = None\n    \n    for algo1 in algorithms_list:\n        for algo2 in algorithms_list:\n            if algo1 != algo2:\n                similarity = jaccard_matrix[algo1][algo2]\n                if similarity < min_jaccard:\n                    min_jaccard = similarity\n                    min_pair = (algo1, algo2)\n                if similarity > max_jaccard:\n                    max_jaccard = similarity\n                    max_pair = (algo1, algo2)\n    \n    report.append(\"### ğŸ¯ å…³é”®å‘ç°\")\n    if min_pair:\n        report.append(f\"- **æœ€å¼ºäº’è¡¥ç»„åˆ**: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})\")\n    if max_pair:\n        report.append(f\"- **æœ€ç›¸ä¼¼ç»„åˆ**: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})\")\n    report.append(\"\")\n    \n    # ç›¸ä¼¼åº¦çŸ©é˜µè¡¨æ ¼\n    report.append(\"### Jaccardç›¸ä¼¼åº¦çŸ©é˜µ\")\n    report.append(\"\")\n    \n    # åˆ›å»ºè¡¨æ ¼æ ‡é¢˜\n    header = \"| ç®—æ³• |\" + \"|\".join([f\" {algo} \" for algo in algorithms_list]) + \"|\"\n    separator = \"|\" + \"|\".join([\"------\" for _ in range(len(algorithms_list) + 1)]) + \"|\"\n    \n    report.append(header)\n    report.append(separator)\n    \n    for algo1 in algorithms_list:\n        row = f\"| {algo1} |\"\n        for algo2 in algorithms_list:\n            if algo1 == algo2:\n                row += \" 1.0000 |\"\n            else:\n                row += f\" {jaccard_matrix[algo1][algo2]:.4f} |\"\n        report.append(row)\n    \n    report.append(\"\")\n    \n    # Teacher ensembleå»ºè®®\n    report.append(\"## ğŸ¯ Teacheræ¨¡å‹Ensembleç­–ç•¥å»ºè®®\")\n    report.append(\"\")\n    \n    if min_pair:\n        report.append(\"### ğŸ¥‡ æ¨èçš„æœ€ä½³Teacher ensembleç»„åˆ\")\n        report.append(f\"**æœ€å¼ºäº’è¡¥ç­–ç•¥**: {min_pair[0]} + {min_pair[1]}\")\n        report.append(f\"- Jaccardç›¸ä¼¼åº¦: {min_jaccard:.4f}\")\n        report.append(f\"- ç‰¹ç‚¹: é‡å åº¦æœ€ä½ï¼Œæ¨èå¤šæ ·æ€§æœ€é«˜\")\n        report.append(\"\")\n    \n    # ä¸‰æ¨¡å‹ç»„åˆ\n    if len(algorithms_list) >= 3:\n        # æŒ‰å¹³å‡ç›¸ä¼¼åº¦æ’åºï¼Œé€‰æ‹©æœ€å¤šæ ·åŒ–çš„3ä¸ªæ¨¡å‹\n        avg_similarities = {}\n        for algo in algorithms_list:\n            other_sims = [jaccard_matrix[algo][other] for other in algorithms_list if other != algo]\n            avg_similarities[algo] = np.mean(other_sims)\n        \n        most_diverse_3 = sorted(avg_similarities.items(), key=lambda x: x[1])[:3]\n        \n        report.append(\"### ğŸ¥ˆ å¤šæ ·åŒ–ä¸‰æ¨¡å‹ç»„åˆ\")\n        report.append(f\"**æ¨èç»„åˆ**: {' + '.join([algo for algo, _ in most_diverse_3])}\")\n        report.append(f\"- åŸºäºæœ€ä½å¹³å‡ç›¸ä¼¼åº¦é€‰æ‹©\")\n        report.append(f\"- ç‰¹ç‚¹: å¹³è¡¡å¤šæ ·æ€§ä¸è¦†ç›–åº¦\")\n        report.append(\"\")\n    \n    # å®æ–½å»ºè®®\n    report.append(\"## ğŸš€ å®æ–½å»ºè®®\")\n    report.append(\"\")\n    report.append(\"1. **Teacheræ¨¡å‹ç‰¹ç‚¹**:\")\n    report.append(\"   - æ¯”simpleç‰ˆæœ¬æä¾›æ›´å¥½çš„ç‰¹å¾å­¦ä¹ èƒ½åŠ›\")\n    report.append(\"   - è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ç¦»çº¿è®­ç»ƒ\")\n    report.append(\"   - é€‚åˆå¯¹æ¨èè´¨é‡è¦æ±‚è¾ƒé«˜çš„åœºæ™¯\")\n    report.append(\"\")\n    report.append(\"2. **Ensembleç­–ç•¥**:\")\n    if min_pair:\n        report.append(f\"   - å¤šæ ·æ€§ä¼˜å…ˆ: ä½¿ç”¨ {min_pair[0]} + {min_pair[1]} ç»„åˆ\")\n    report.append(\"   - å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´æƒé‡åˆ†é…\")\n    report.append(\"\")\n    report.append(\"3. **ä¼˜åŒ–æ–¹å‘**:\")\n    report.append(\"   - å¢åŠ è®­ç»ƒæ•°æ®é‡å’Œepochsæå‡æ¨¡å‹æ•ˆæœ\")\n    report.append(\"   - ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹\")\n    report.append(\"   - å®šæœŸé‡æ–°è¯„ä¼°æ¨¡å‹ä¸€è‡´æ€§\")\n    \n    # ä¿å­˜æŠ¥å‘Š\n    report_content = \"\\n\".join(report)\n    \n    with open(\"SIMPLIFIED_TEACHER_ANALYSIS.md\", \"w\", encoding='utf-8') as f:\n        f.write(report_content)\n    \n    print(\"âœ… Teacheræ¨¡å‹åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° SIMPLIFIED_TEACHER_ANALYSIS.md\")\n    \n    # æ˜¾ç¤ºå…³é”®ç»“æœ\n    print(\"\\nğŸ‰ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®Œæˆï¼\")\n    print(\"\\nğŸ“Š å…³é”®ç»“æœ:\")\n    \n    if min_pair:\n        print(f\"ğŸ† æœ€ä½³äº’è¡¥ç»„åˆ: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})\")\n    \n    if max_pair:\n        print(f\"âš ï¸  æœ€ç›¸ä¼¼ç»„åˆ: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})\")\n    \n    print(f\"ğŸ“ˆ æˆåŠŸè®­ç»ƒçš„Teacheræ¨¡å‹: {list(trained_models.keys())}\")\n    \n    return {\n        'trained_models': list(trained_models.keys()),\n        'jaccard_matrix': jaccard_matrix,\n        'best_complementary': min_pair if min_pair else None,\n        'performance_stats': performance_stats\n    }\n\n\nif __name__ == \"__main__\":\n    run_simple_teacher_experiment()
