#!/usr/bin/env python3
"""
Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®éªŒ

ä½¿ç”¨å®Œæ•´ç‰ˆTeacheræ¨¡å‹é‡æ–°æ‰§è¡Œä¸€è‡´æ€§åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- DeepFMã€AutoIntã€DINçš„å®Œæ•´ç‰ˆæœ¬
- æ–°å¢Transformer4Recã€DCNv2ã€xDeepFM
- é‡æ–°è®¡ç®—Jaccardç›¸ä¼¼åº¦å’ŒKendall Tauç›¸å…³æ€§
- åŸºäºæ–°ç»“æœä¼˜åŒ–ensembleç­–ç•¥
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any
import logging
import time
from collections import defaultdict

# å¯¼å…¥è¯„ä¼°å’Œä¸€è‡´æ€§åˆ†ææ¨¡å—
from evaluation.consistency_analysis import AlgorithmConsistencyEvaluator
from evaluation.metrics import RecommendationMetrics
from models import create_recommender, get_available_algorithms

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_enhanced_movielens_simulation(num_users: int = 1000, num_items: int = 500,
                                       num_interactions: int = 10000) -> pd.DataFrame:
    """åˆ›å»ºå¢å¼ºçš„MovieLensæ¨¡æ‹Ÿæ•°æ®"""
    print(f"ğŸ¬ åˆ›å»ºå¢å¼ºMovieLensæ¨¡æ‹Ÿæ•°æ®...")
    print(f"ç”¨æˆ·æ•°: {num_users}, ç‰©å“æ•°: {num_items}, äº¤äº’æ•°: {num_interactions}")
    
    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§
    
    interactions = []
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºæ¨¡å¼
    user_preferences = {}
    for user_id in range(1, num_users + 1):
        # æ¯ä¸ªç”¨æˆ·æœ‰ä¸åŒçš„è¯„åˆ†åå¥½
        user_preferences[user_id] = {
            'mean_rating': np.random.normal(3.5, 0.5),
            'rating_std': np.random.uniform(0.5, 1.5),
            'activity_level': np.random.exponential(0.1)  # æ´»è·ƒåº¦
        }
    
    # ç”Ÿæˆäº¤äº’æ•°æ®
    for _ in range(num_interactions):
        # æ ¹æ®æ´»è·ƒåº¦é€‰æ‹©ç”¨æˆ·ï¼ˆæ›´æ´»è·ƒçš„ç”¨æˆ·æ›´å¯èƒ½äº§ç”Ÿäº¤äº’ï¼‰
        user_weights = [user_preferences[uid]['activity_level'] for uid in range(1, num_users + 1)]
        user_id = np.random.choice(range(1, num_users + 1), p=user_weights/np.sum(user_weights))
        
        # éšæœºé€‰æ‹©ç‰©å“ï¼ˆå¯ä»¥åŠ å…¥æµè¡Œåº¦åå‘ï¼‰
        item_id = np.random.randint(1, num_items + 1)
        
        # ç”Ÿæˆè¯„åˆ†ï¼ˆåŸºäºç”¨æˆ·åå¥½ï¼‰
        user_pref = user_preferences[user_id]
        rating = np.clip(
            np.random.normal(user_pref['mean_rating'], user_pref['rating_std']),
            1.0, 5.0
        )
        rating = round(rating)
        
        # ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆæ¨¡æ‹Ÿæ—¶åºï¼‰
        timestamp = int(time.time()) + np.random.randint(-86400*30, 86400*30)  # Â±30å¤©
        
        interactions.append({
            'user_id': user_id,
            'item_id': item_id,
            'rating': rating,
            'timestamp': timestamp
        })
    
    train_data = pd.DataFrame(interactions)
    
    # å»é‡ï¼ˆç”¨æˆ·-ç‰©å“å¯¹ï¼‰ä¿ç•™æœ€æ–°çš„äº¤äº’
    train_data = train_data.sort_values('timestamp').groupby(['user_id', 'item_id']).last().reset_index()
    
    print(f"âœ… ç”Ÿæˆäº† {len(train_data)} æ¡å”¯ä¸€äº¤äº’æ•°æ®")
    print(f"è¯„åˆ†åˆ†å¸ƒ: {train_data['rating'].value_counts().sort_index().to_dict()}")
    
    return train_data


class TeacherModelConsistencyExperiment:
    """Teacheræ¨¡å‹ä¸€è‡´æ€§å®éªŒ"""
    
    def __init__(self):
        self.algorithms = [
            'svd',              # åŸºç¡€ç®—æ³•
            'deepfm',           # å®Œæ•´ç‰ˆDeepFM Teacher
            'autoint',          # å®Œæ•´ç‰ˆAutoInt Teacher  
            'din',              # å®Œæ•´ç‰ˆDIN Teacher
            'transformer4rec',  # æ–°Teacheræ¨¡å‹
            'dcnv2',           # æ–°Teacheræ¨¡å‹
            'xdeepfm'          # æ–°Teacheræ¨¡å‹
        ]
        
        self.train_data = None
        self.trained_models = {}
        self.evaluator = AlgorithmConsistencyEvaluator()
        self.metrics = RecommendationMetrics()
        
        # ä¼˜åŒ–çš„Teacheræ¨¡å‹é…ç½®
        self.model_configs = {
            'svd': {
                'n_components': 50,
                'learning_rate': 0.01,
                'regularization': 0.02,
                'epochs': 100
            },
            'deepfm': {
                'embedding_dim': 16,
                'learning_rate': 0.001,
                'epochs': 60,
                'batch_size': 256,
                'early_stopping': True,
                'patience': 8
            },
            'autoint': {
                'embedding_dim': 16,
                'learning_rate': 0.001,
                'epochs': 60,
                'num_heads': 8,
                'num_layers': 6,
                'early_stopping': True,
                'patience': 8
            },
            'din': {
                'embedding_dim': 16,
                'learning_rate': 0.001,
                'epochs': 60,
                'hidden_dim': 128,
                'early_stopping': True,
                'patience': 8
            },
            'transformer4rec': {
                'embedding_dim': 64,
                'num_heads': 8,
                'num_layers': 6,
                'learning_rate': 0.001,
                'epochs': 50,
                'batch_size': 256,
                'early_stopping': True,
                'patience': 8
            },
            'dcnv2': {
                'embedding_dim': 16,
                'cross_layers': 4,
                'deep_layers': [512, 256, 128],
                'learning_rate': 0.001,
                'epochs': 50,
                'batch_size': 256,
                'early_stopping': True,
                'patience': 8
            },
            'xdeepfm': {
                'embedding_dim': 16,
                'cin_layer_sizes': [200, 200, 200],
                'dnn_hidden_dims': [400, 400, 400],
                'learning_rate': 0.001,
                'epochs': 50,
                'batch_size': 256,
                'early_stopping': True,
                'patience': 8
            }
        }
    
    def train_all_models(self, train_data: pd.DataFrame):
        """è®­ç»ƒæ‰€æœ‰Teacheræ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰Teacheræ¨¡å‹...")
        self.train_data = train_data
        
        for algo_name in self.algorithms:
            print(f"\nğŸ“š è®­ç»ƒ {algo_name} (Teacheræ¨¡å‹)...")
            
            try:
                # è·å–é…ç½®
                config = self.model_configs.get(algo_name, {})
                
                # åˆ›å»ºæ¨¡å‹
                model = create_recommender(algo_name, **config)
                if model is None:
                    print(f"âŒ æ— æ³•åˆ›å»ºç®—æ³•: {algo_name}")
                    continue
                
                # è®­ç»ƒæ¨¡å‹
                start_time = time.time()
                model.fit(train_data, **config)
                end_time = time.time()
                
                if model.is_trained:
                    self.trained_models[algo_name] = model
                    print(f"âœ… {algo_name} è®­ç»ƒæˆåŠŸ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
                else:
                    print(f"âŒ {algo_name} è®­ç»ƒå¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ è®­ç»ƒ {algo_name} æ—¶å‡ºé”™: {e}")
        
        print(f"\nğŸ¯ è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒäº† {len(self.trained_models)} ä¸ªTeacheræ¨¡å‹")
        print(f"æˆåŠŸçš„æ¨¡å‹: {list(self.trained_models.keys())}")
    
    def evaluate_individual_performance(self):
        """è¯„ä¼°å•ä¸ªæ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š è¯„ä¼°Teacheræ¨¡å‹ä¸ªä½“æ€§èƒ½...")
        
        results = {}
        
        for algo_name, model in self.trained_models.items():
            print(f"è¯„ä¼° {algo_name}...")
            
            try:
                # ç”Ÿæˆæ¨è
                test_users = self.train_data['user_id'].unique()[:100]  # æµ‹è¯•å‰100ä¸ªç”¨æˆ·
                recommendations = {}
                
                for user_id in test_users:
                    try:
                        recs = model.get_user_recommendations(user_id, top_k=50)
                        if recs:
                            recommendations[user_id] = [rec['item_id'] for rec in recs]
                    except:
                        continue
                
                if not recommendations:
                    print(f"âŒ {algo_name} æ— æ³•ç”Ÿæˆæ¨è")
                    continue
                
                # è®¡ç®—æŒ‡æ ‡
                metrics = self.metrics.calculate_metrics(
                    recommendations, self.train_data, k_values=[10, 50]
                )
                
                results[algo_name] = {
                    'R@10': metrics.get('R@10', 0.0),
                    'N@10': metrics.get('N@10', 0.0),
                    'R@50': metrics.get('R@50', 0.0),
                    'N@50': metrics.get('N@50', 0.0),
                    'Coverage': metrics.get('Coverage', 0.0),
                    'num_recommendations': len(recommendations)
                }
                
                print(f"  R@10: {results[algo_name]['R@10']:.4f}")
                print(f"  N@10: {results[algo_name]['N@10']:.4f}")
                print(f"  R@50: {results[algo_name]['R@50']:.4f}")
                print(f"  N@50: {results[algo_name]['N@50']:.4f}")
                
            except Exception as e:
                print(f"âŒ è¯„ä¼° {algo_name} æ—¶å‡ºé”™: {e}")
        
        return results
    
    def analyze_teacher_consistency(self):
        """åˆ†æTeacheræ¨¡å‹é—´çš„ä¸€è‡´æ€§"""
        print("\nğŸ” åˆ†æTeacheræ¨¡å‹ä¸€è‡´æ€§...")
        
        # ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„æ¨è
        all_recommendations = {}
        test_users = self.train_data['user_id'].unique()[:50]  # æµ‹è¯•50ä¸ªç”¨æˆ·
        
        for algo_name, model in self.trained_models.items():
            print(f"ç”Ÿæˆ {algo_name} çš„æ¨è...")
            recommendations = {}
            
            for user_id in test_users:
                try:
                    recs = model.get_user_recommendations(user_id, top_k=10)
                    if recs:
                        recommendations[user_id] = [rec['item_id'] for rec in recs]
                except:
                    continue
            
            if recommendations:
                all_recommendations[algo_name] = recommendations
                print(f"  æˆåŠŸä¸º {len(recommendations)} ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è")
        
        if len(all_recommendations) < 2:
            print("âŒ æ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æï¼ŒæˆåŠŸçš„æ¨¡å‹å°‘äº2ä¸ª")
            return None
        
        # è®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡
        print("\nè®¡ç®—ä¸€è‡´æ€§æŒ‡æ ‡...")
        consistency_results = self.evaluator.analyze_algorithm_consistency(
            all_recommendations, k_values=[5, 10]
        )
        
        return consistency_results
    
    def generate_teacher_report(self, performance_results, consistency_results):
        """ç”ŸæˆTeacheræ¨¡å‹åˆ†ææŠ¥å‘Š"""
        print("\nğŸ“ ç”ŸæˆTeacheræ¨¡å‹åˆ†ææŠ¥å‘Š...")
        
        report = []
        report.append("# ğŸ“ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†ææŠ¥å‘Š")
        report.append(f"å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # å®éªŒæ¦‚è¿°
        report.append("## ğŸ“Š å®éªŒæ¦‚è¿°")
        report.append(f"- **Teacheræ¨¡å‹æ•°é‡**: {len(self.trained_models)}")
        report.append(f"- **æˆåŠŸè®­ç»ƒæ¨¡å‹**: {list(self.trained_models.keys())}")
        report.append(f"- **æ•°æ®é›†è§„æ¨¡**: {len(self.train_data)} æ¡äº¤äº’")
        report.append(f"- **ç”¨æˆ·æ•°**: {len(self.train_data['user_id'].unique())}")
        report.append(f"- **ç‰©å“æ•°**: {len(self.train_data['item_id'].unique())}")
        report.append("")
        
        # ä¸ªä½“æ€§èƒ½
        if performance_results:
            report.append("## ğŸ† Teacheræ¨¡å‹ä¸ªä½“æ€§èƒ½")
            report.append("")
            report.append("| æ¨¡å‹ | R@10 | N@10 | R@50 | N@50 | Coverage |")
            report.append("|------|------|------|------|------|----------|")
            
            for algo_name, metrics in performance_results.items():
                report.append(f"| {algo_name} | {metrics['R@10']:.4f} | {metrics['N@10']:.4f} | "
                            f"{metrics['R@50']:.4f} | {metrics['N@50']:.4f} | {metrics['Coverage']:.4f} |")
            report.append("")
            
            # æ€§èƒ½æ’å
            sorted_by_r10 = sorted(performance_results.items(), 
                                 key=lambda x: x[1]['R@10'], reverse=True)
            
            report.append("### ğŸ“ˆ æ€§èƒ½æ’å (æŒ‰R@10)")
            for i, (algo_name, metrics) in enumerate(sorted_by_r10, 1):
                report.append(f"{i}. **{algo_name}**: R@10={metrics['R@10']:.4f}")
            report.append("")
        
        # ä¸€è‡´æ€§åˆ†æ
        if consistency_results:
            report.append("## ğŸ”„ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æ")
            report.append("")
            
            if 'jaccard_matrix' in consistency_results:
                report.append("### Jaccardç›¸ä¼¼åº¦çŸ©é˜µ")
                jaccard_matrix = consistency_results['jaccard_matrix']
                algorithms = list(jaccard_matrix.keys())
                
                # æ‰¾åˆ°æœ€ä½å’Œæœ€é«˜Jaccardç›¸ä¼¼åº¦
                min_jaccard = float('inf')
                max_jaccard = 0.0
                min_pair = None
                max_pair = None
                
                for algo1 in algorithms:
                    for algo2 in algorithms:
                        if algo1 != algo2:
                            similarity = jaccard_matrix[algo1][algo2]
                            if similarity < min_jaccard:
                                min_jaccard = similarity
                                min_pair = (algo1, algo2)
                            if similarity > max_jaccard:
                                max_jaccard = similarity
                                max_pair = (algo1, algo2)
                
                report.append(f"- **æœ€å¼ºäº’è¡¥ç»„åˆ**: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})")
                report.append(f"- **æœ€ç›¸ä¼¼ç»„åˆ**: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})")
                report.append("")
            
            # å¤šæ ·æ€§åˆ†æ
            if 'diversity_scores' in consistency_results:
                report.append("### ğŸ“Š Teacheræ¨¡å‹å¤šæ ·æ€§è¯„åˆ†")
                diversity_scores = consistency_results['diversity_scores']
                sorted_diversity = sorted(diversity_scores.items(), 
                                        key=lambda x: x[1], reverse=True)
                
                for i, (algo_name, score) in enumerate(sorted_diversity, 1):
                    report.append(f"{i}. **{algo_name}**: {score:.4f}")
                report.append("")
        
        # Teacheræ¨¡å‹ensembleå»ºè®®
        report.append("## ğŸ¯ Teacheræ¨¡å‹Ensembleç­–ç•¥å»ºè®®")
        report.append("")
        
        if consistency_results and 'jaccard_matrix' in consistency_results:
            # åŸºäºä¸€è‡´æ€§åˆ†æçš„å»ºè®®
            jaccard_matrix = consistency_results['jaccard_matrix']
            algorithms = list(jaccard_matrix.keys())
            
            # æ‰¾åˆ°æœ€äº’è¡¥çš„ç»„åˆ
            min_jaccard = float('inf')
            best_complementary = None
            
            for i, algo1 in enumerate(algorithms):
                for j, algo2 in enumerate(algorithms[i+1:], i+1):
                    similarity = jaccard_matrix[algo1][algo2]
                    if similarity < min_jaccard:
                        min_jaccard = similarity
                        best_complementary = (algo1, algo2)
            
            if best_complementary:
                report.append(f"### ğŸ¥‡ æœ€ä½³äº’è¡¥ç­–ç•¥")
                report.append(f"**æ¨èç»„åˆ**: {best_complementary[0]} + {best_complementary[1]}")
                report.append(f"- Jaccardç›¸ä¼¼åº¦: {min_jaccard:.4f}")
                report.append(f"- ç‰¹ç‚¹: æä½é‡å åº¦ï¼Œæœ€å¤§åŒ–æ¨èå¤šæ ·æ€§")
                report.append("")
            
            # ä¸‰æ¨¡å‹ç»„åˆå»ºè®®
            if len(algorithms) >= 3:
                diversity_scores = consistency_results.get('diversity_scores', {})
                top_3_diverse = sorted(diversity_scores.items(), 
                                     key=lambda x: x[1], reverse=True)[:3]
                
                report.append(f"### ğŸ¥ˆ æœ€ä½³å¤šæ ·åŒ–ç­–ç•¥")
                report.append(f"**æ¨èç»„åˆ**: {' + '.join([algo for algo, _ in top_3_diverse])}")
                report.append(f"- å¤šæ ·æ€§è¯„åˆ†: {[f'{algo}({score:.3f})' for algo, score in top_3_diverse]}")
                report.append(f"- ç‰¹ç‚¹: å¹³è¡¡æ€§èƒ½ä¸å¤šæ ·æ€§ï¼Œç»¼åˆæ•ˆæœæœ€ä½³")
                report.append("")
            
            # è´¨é‡ä¼˜å…ˆå»ºè®®
            if performance_results:
                top_performer = max(performance_results.items(), key=lambda x: x[1]['R@10'])
                report.append(f"### ğŸ¥‰ è´¨é‡ä¼˜å…ˆç­–ç•¥")
                report.append(f"**ä¸»å¯¼æ¨¡å‹**: {top_performer[0]} (R@10={top_performer[1]['R@10']:.4f})")
                report.append(f"- ç‰¹ç‚¹: ä»¥æœ€é«˜æ€§èƒ½æ¨¡å‹ä¸ºä¸»ï¼Œè¾…ä»¥äº’è¡¥æ¨¡å‹")
                report.append("")
        
        # å®æ–½å»ºè®®
        report.append("## ğŸš€ å®æ–½å»ºè®®")
        report.append("")
        report.append("1. **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**:")
        report.append("   - æ¨èä½¿ç”¨æœ€ä½³äº’è¡¥ç­–ç•¥ä»¥è·å¾—æœ€é«˜å¤šæ ·æ€§")
        report.append("   - åœ¨è®¡ç®—èµ„æºæœ‰é™æ—¶ä½¿ç”¨è´¨é‡ä¼˜å…ˆç­–ç•¥")
        report.append("")
        report.append("2. **æ¨¡å‹æ›´æ–°ç­–ç•¥**:")
        report.append("   - Teacheræ¨¡å‹éœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´ï¼Œå»ºè®®ç¦»çº¿è®­ç»ƒ")
        report.append("   - å®šæœŸé‡æ–°è¯„ä¼°ä¸€è‡´æ€§ï¼ŒåŠ¨æ€è°ƒæ•´ensembleæƒé‡")
        report.append("")
        report.append("3. **æ€§èƒ½ç›‘æ§**:")
        report.append("   - ç›‘æ§ensembleä¸å•æ¨¡å‹çš„æ€§èƒ½å·®å¼‚")
        report.append("   - å…³æ³¨ç”¨æˆ·åé¦ˆï¼Œè°ƒæ•´æ¨èç­–ç•¥")
        
        # ä¿å­˜æŠ¥å‘Š
        report_content = "\n".join(report)
        
        with open("TEACHER_MODEL_CONSISTENCY_REPORT.md", "w", encoding='utf-8') as f:
            f.write(report_content)
        
        print("âœ… Teacheræ¨¡å‹åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° TEACHER_MODEL_CONSISTENCY_REPORT.md")
        
        return report_content
    
    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´çš„Teacheræ¨¡å‹å®éªŒ"""
        print("ğŸ“ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®éªŒå¼€å§‹ï¼")
        print("=" * 60)
        
        # 1. åˆ›å»ºæ•°æ®
        train_data = create_enhanced_movielens_simulation(
            num_users=800, num_items=300, num_interactions=8000
        )
        
        # 2. è®­ç»ƒæ‰€æœ‰Teacheræ¨¡å‹
        self.train_all_models(train_data)
        
        if len(self.trained_models) < 2:
            print("âŒ è®­ç»ƒæˆåŠŸçš„æ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
            return
        
        # 3. è¯„ä¼°ä¸ªä½“æ€§èƒ½
        performance_results = self.evaluate_individual_performance()
        
        # 4. åˆ†æä¸€è‡´æ€§
        consistency_results = self.analyze_teacher_consistency()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_teacher_report(performance_results, consistency_results)
        
        print("\nğŸ‰ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®éªŒå®Œæˆï¼")
        print(f"ğŸ“‹ æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ TEACHER_MODEL_CONSISTENCY_REPORT.md")
        
        return {
            'performance_results': performance_results,
            'consistency_results': consistency_results,
            'report': report,
            'trained_models': list(self.trained_models.keys())
        }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®éªŒ")
    print("ä½¿ç”¨å®Œæ•´ç‰ˆTeacheræ¨¡å‹é‡æ–°è¯„ä¼°ç®—æ³•ä¸€è‡´æ€§")
    print("=" * 60)
    
    # æ£€æŸ¥å¯ç”¨ç®—æ³•
    available_algorithms = get_available_algorithms()
    print(f"å¯ç”¨ç®—æ³•: {available_algorithms}")
    
    # è¿è¡Œå®éªŒ
    experiment = TeacherModelConsistencyExperiment()
    results = experiment.run_complete_experiment()
    
    if results:
        print("\nğŸ¯ å®éªŒç»“æœæ‘˜è¦:")
        print(f"- æˆåŠŸè®­ç»ƒæ¨¡å‹: {results['trained_models']}")
        
        if results['performance_results']:
            best_model = max(results['performance_results'].items(), 
                           key=lambda x: x[1]['R@10'])
            print(f"- æœ€ä½³æ€§èƒ½æ¨¡å‹: {best_model[0]} (R@10={best_model[1]['R@10']:.4f})")
        
        if results['consistency_results'] and 'jaccard_matrix' in results['consistency_results']:
            print("- ä¸€è‡´æ€§åˆ†æå®Œæˆï¼Œè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹æŠ¥å‘Š")


if __name__ == "__main__":
    main()
