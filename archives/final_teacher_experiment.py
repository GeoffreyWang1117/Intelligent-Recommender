#!/usr/bin/env python3
"""
ç®€åŒ–CPU Teacheræ¨¡å‹å®éªŒ - å®Œæ•´ä¸€è‡´æ€§åˆ†æ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import time
import logging
from typing import Dict, List
from collections import defaultdict

# å¼ºåˆ¶CPUæ¨¡å¼
import torch
torch.device('cpu')

from models import create_recommender

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def simple_jaccard_similarity(set1: set, set2: set) -> float:
    """è®¡ç®—Jaccardç›¸ä¼¼åº¦"""
    if not set1 and not set2:
        return 1.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0.0


def run_teacher_experiment():
    """è¿è¡ŒTeacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®éªŒ"""
    print("ğŸ“ Teacheræ¨¡å‹å®Œæ•´ä¸€è‡´æ€§åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®
    print("ğŸ“Š åˆ›å»ºæ¨¡æ‹Ÿæ¨èæ•°æ®...")
    np.random.seed(42)
    
    interactions = []
    for _ in range(3000):
        user_id = np.random.randint(1, 201)  # 200ç”¨æˆ·
        item_id = np.random.randint(1, 151)  # 150ç‰©å“
        rating = np.random.choice([3, 4, 5], p=[0.3, 0.4, 0.3])
        timestamp = int(time.time()) + np.random.randint(-86400*30, 86400*30)
        
        interactions.append({
            'user_id': user_id,
            'item_id': item_id,
            'rating': rating,
            'timestamp': timestamp
        })
    
    train_data = pd.DataFrame(interactions)
    train_data = train_data.drop_duplicates(['user_id', 'item_id'])
    
    print(f"âœ… ç”Ÿæˆäº† {len(train_data)} æ¡å”¯ä¸€äº¤äº’æ•°æ®")
    print(f"   ç”¨æˆ·æ•°: {train_data['user_id'].nunique()}")
    print(f"   ç‰©å“æ•°: {train_data['item_id'].nunique()}")
    
    # Teacheræ¨¡å‹é…ç½® - ä¼˜åŒ–ç‰ˆæœ¬
    algorithms = ['deepfm', 'autoint', 'transformer4rec', 'xdeepfm']
    
    model_configs = {
        'deepfm': {
            'embedding_dim': 16,
            'learning_rate': 0.001,
            'epochs': 15,
            'batch_size': 64,
            'early_stopping': False
        },
        'autoint': {
            'embedding_dim': 16,
            'learning_rate': 0.001,
            'epochs': 15,
            'num_heads': 4,
            'num_layers': 3,
            'early_stopping': False
        },
        'transformer4rec': {
            'embedding_dim': 32,
            'num_heads': 4,
            'num_layers': 3,
            'learning_rate': 0.001,
            'epochs': 12,
            'batch_size': 64,
            'early_stopping': False
        },
        'xdeepfm': {
            'embedding_dim': 16,
            'cin_layer_sizes': [64, 32],
            'dnn_hidden_dims': [128, 64],
            'learning_rate': 0.001,
            'epochs': 12,
            'batch_size': 64,
            'early_stopping': False
        }
    }
    
    print(f"ğŸ¯ å°†è®­ç»ƒ {len(algorithms)} ä¸ªTeacheræ¨¡å‹:")
    for algo in algorithms:
        print(f"   - {algo}")
    
    # è®­ç»ƒæ¨¡å‹
    trained_models = {}
    training_times = {}
    
    for algo_name in algorithms:
        print(f"\nğŸ“š è®­ç»ƒTeacheræ¨¡å‹: {algo_name}")
        print(f"   é…ç½®: {model_configs[algo_name]}")
        
        try:
            config = model_configs[algo_name]
            
            start_time = time.time()
            model = create_recommender(algo_name, **config)
            
            if model is None:
                print(f"âŒ æ— æ³•åˆ›å»ºç®—æ³•: {algo_name}")
                continue
            
            # å¼ºåˆ¶CPUæ¨¡å¼
            if hasattr(model, 'device'):
                model.device = torch.device('cpu')
            
            model.fit(train_data, **config)
            end_time = time.time()
            
            training_time = end_time - start_time
            training_times[algo_name] = training_time
            
            if model.is_trained:
                trained_models[algo_name] = model
                print(f"âœ… {algo_name} è®­ç»ƒæˆåŠŸ! è€—æ—¶: {training_time:.2f}ç§’")
            else:
                print(f"âŒ {algo_name} è®­ç»ƒå¤±è´¥ - æ¨¡å‹æœªå®Œæˆè®­ç»ƒ")
                
        except Exception as e:
            print(f"âŒ è®­ç»ƒ {algo_name} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    print(f"\nğŸ¯ è®­ç»ƒé˜¶æ®µå®Œæˆ!")
    print(f"   æˆåŠŸè®­ç»ƒ: {len(trained_models)} ä¸ªTeacheræ¨¡å‹")
    print(f"   æˆåŠŸçš„æ¨¡å‹: {list(trained_models.keys())}")
    
    if len(trained_models) < 2:
        print("âŒ è®­ç»ƒæˆåŠŸçš„æ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ")
        return None
    
    # ç”Ÿæˆæ¨è
    print("\nğŸ“Š ç”Ÿæˆæ¨èå¹¶åˆ†æä¸€è‡´æ€§...")
    test_users = list(train_data['user_id'].unique())[:50]  # æµ‹è¯•50ä¸ªç”¨æˆ·
    
    all_recommendations = {}
    performance_stats = {}
    
    for algo_name, model in trained_models.items():
        print(f"ğŸ” ç”Ÿæˆ {algo_name} çš„æ¨è...")
        
        recommendations = {}
        success_count = 0
        total_rec_count = 0
        
        for user_id in test_users:
            try:
                recs = model.get_user_recommendations(user_id, top_k=10)
                if recs and len(recs) > 0:
                    rec_items = [rec['item_id'] for rec in recs]
                    recommendations[user_id] = rec_items
                    success_count += 1
                    total_rec_count += len(rec_items)
            except Exception as e:
                continue
        
        if recommendations:
            all_recommendations[algo_name] = recommendations
            performance_stats[algo_name] = {
                'success_rate': success_count / len(test_users),
                'avg_rec_length': total_rec_count / success_count if success_count > 0 else 0,
                'total_recommendations': len(recommendations),
                'training_time': training_times.get(algo_name, 0)
            }
            print(f"   âœ… æˆåŠŸä¸º {len(recommendations)} ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è")
            print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_count/len(test_users):.2%}")
    
    # è®¡ç®—ä¸€è‡´æ€§çŸ©é˜µ
    print("\nğŸ” è®¡ç®—Teacheræ¨¡å‹é—´ä¸€è‡´æ€§...")
    
    if len(all_recommendations) < 2:
        print("âŒ æ— æ³•è¿›è¡Œä¸€è‡´æ€§åˆ†æ - æ¨èç”Ÿæˆå¤±è´¥")
        return None
    
    algorithms_list = list(all_recommendations.keys())
    jaccard_matrix = {}
    overlap_stats = {}
    
    print(f"ğŸ“Š åˆ†æ {len(algorithms_list)} ä¸ªæ¨¡å‹é—´çš„ä¸€è‡´æ€§:")
    
    # è®¡ç®—Jaccardç›¸ä¼¼åº¦çŸ©é˜µ
    for i, algo1 in enumerate(algorithms_list):
        jaccard_matrix[algo1] = {}
        overlap_stats[algo1] = {}
        
        for j, algo2 in enumerate(algorithms_list):
            if algo1 == algo2:
                jaccard_matrix[algo1][algo2] = 1.0
                overlap_stats[algo1][algo2] = {'avg_overlap': 1.0, 'user_count': 0}
            else:
                similarities = []
                overlaps = []
                
                # æ‰¾åˆ°ä¸¤ä¸ªç®—æ³•éƒ½æœ‰æ¨èçš„ç”¨æˆ·
                common_users = set(all_recommendations[algo1].keys()) & set(all_recommendations[algo2].keys())
                
                for user_id in common_users:
                    recs1 = set(all_recommendations[algo1][user_id][:10])
                    recs2 = set(all_recommendations[algo2][user_id][:10])
                    
                    # Jaccardç›¸ä¼¼åº¦
                    sim = simple_jaccard_similarity(recs1, recs2)
                    similarities.append(sim)
                    
                    # é‡å æ•°é‡
                    overlap = len(recs1.intersection(recs2))
                    overlaps.append(overlap)
                
                avg_similarity = np.mean(similarities) if similarities else 0.0
                avg_overlap = np.mean(overlaps) if overlaps else 0.0
                
                jaccard_matrix[algo1][algo2] = avg_similarity
                overlap_stats[algo1][algo2] = {
                    'avg_overlap': avg_overlap,
                    'user_count': len(common_users)
                }
        
        print(f"   âœ… å®Œæˆ {algo1} çš„ä¸€è‡´æ€§è®¡ç®—")
    
    # åˆ†æç»“æœ
    print("\nğŸ“ˆ åˆ†æTeacheræ¨¡å‹ä¸€è‡´æ€§ç»“æœ...")
    
    # æ‰¾åˆ°æœ€ä½å’Œæœ€é«˜ç›¸ä¼¼åº¦
    min_jaccard = float('inf')
    max_jaccard = 0.0
    min_pair = None
    max_pair = None
    
    all_similarities = []
    
    for algo1 in algorithms_list:
        for algo2 in algorithms_list:
            if algo1 != algo2:
                similarity = jaccard_matrix[algo1][algo2]
                all_similarities.append(similarity)
                
                if similarity < min_jaccard:
                    min_jaccard = similarity
                    min_pair = (algo1, algo2)
                if similarity > max_jaccard:
                    max_jaccard = similarity
                    max_pair = (algo1, algo2)
    
    avg_jaccard = np.mean(all_similarities) if all_similarities else 0.0
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print("\nğŸ“ ç”ŸæˆTeacheræ¨¡å‹åˆ†ææŠ¥å‘Š...")
    
    report = []
    report.append("# ğŸ“ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†ææŠ¥å‘Š")
    report.append(f"**å®éªŒæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    report.append("## ğŸ“Š å®éªŒæ¦‚è¿°")
    report.append(f"- **è®­ç»ƒçš„Teacheræ¨¡å‹**: {', '.join(algorithms)}")
    report.append(f"- **æˆåŠŸè®­ç»ƒæ¨¡å‹**: {', '.join(trained_models.keys())}")
    report.append(f"- **æ•°æ®é›†è§„æ¨¡**: {len(train_data)} æ¡äº¤äº’")
    report.append(f"- **æµ‹è¯•ç”¨æˆ·æ•°**: {len(test_users)}")
    report.append(f"- **è¿è¡Œæ¨¡å¼**: CPUä¼˜åŒ–æ¨¡å¼")
    report.append("")
    
    # è®­ç»ƒæ€§èƒ½
    report.append("## â±ï¸ Teacheræ¨¡å‹è®­ç»ƒæ€§èƒ½")
    report.append("")
    report.append("| æ¨¡å‹ | è®­ç»ƒæ—¶é—´(ç§’) | çŠ¶æ€ |")
    report.append("|------|-------------|------|")
    
    for algo in algorithms:
        if algo in trained_models:
            train_time = training_times.get(algo, 0)
            report.append(f"| {algo} | {train_time:.2f} | âœ… æˆåŠŸ |")
        else:
            report.append(f"| {algo} | - | âŒ å¤±è´¥ |")
    report.append("")
    
    # æ¨èæ€§èƒ½ç»Ÿè®¡
    report.append("## ğŸ† Teacheræ¨¡å‹æ¨èæ€§èƒ½")
    report.append("")
    report.append("| æ¨¡å‹ | æˆåŠŸç‡ | å¹³å‡æ¨èæ•° | æ€»æ¨èæ•° | è®­ç»ƒæ—¶é—´(ç§’) |")
    report.append("|------|--------|------------|----------|-------------|")
    
    for algo_name, stats in performance_stats.items():
        report.append(f"| {algo_name} | {stats['success_rate']:.2%} | {stats['avg_rec_length']:.1f} | {stats['total_recommendations']} | {stats['training_time']:.2f} |")
    report.append("")
    
    # ä¸€è‡´æ€§åˆ†æç»“æœ
    report.append("## ğŸ”„ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æ")
    report.append("")
    
    report.append("### ğŸ“Š å…³é”®æŒ‡æ ‡")
    report.append(f"- **å¹³å‡Jaccardç›¸ä¼¼åº¦**: {avg_jaccard:.4f}")
    if min_pair:
        report.append(f"- **æœ€å¼ºäº’è¡¥ç»„åˆ**: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})")
    if max_pair:
        report.append(f"- **æœ€ç›¸ä¼¼ç»„åˆ**: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})")
    report.append("")
    
    # Jaccardç›¸ä¼¼åº¦çŸ©é˜µ
    report.append("### ğŸ”¢ Jaccardç›¸ä¼¼åº¦çŸ©é˜µ")
    report.append("")
    
    # åˆ›å»ºè¡¨æ ¼
    header = "| ç®—æ³• |" + "".join([f" {algo} |" for algo in algorithms_list])
    separator = "|" + "".join(["------|" for _ in range(len(algorithms_list) + 1)])
    
    report.append(header)
    report.append(separator)
    
    for algo1 in algorithms_list:
        row = f"| **{algo1}** |"
        for algo2 in algorithms_list:
            if algo1 == algo2:
                row += " 1.0000 |"
            else:
                similarity = jaccard_matrix[algo1][algo2]
                row += f" {similarity:.4f} |"
        report.append(row)
    
    report.append("")
    
    # Teacher ensembleå»ºè®®
    report.append("## ğŸ¯ Teacheræ¨¡å‹Ensembleç­–ç•¥å»ºè®®")
    report.append("")
    
    if min_pair and max_pair:
        report.append("### ğŸ¥‡ æœ€ä½³Teacher Ensembleç»„åˆ")
        report.append("")
        report.append(f"**æœ€å¼ºäº’è¡¥ç­–ç•¥**: {min_pair[0]} + {min_pair[1]}")
        report.append(f"- **Jaccardç›¸ä¼¼åº¦**: {min_jaccard:.4f}")
        report.append(f"- **ç‰¹ç‚¹**: æ¨èé‡å åº¦æœ€ä½ï¼Œå¤šæ ·æ€§æœ€é«˜")
        report.append(f"- **é€‚ç”¨åœºæ™¯**: éœ€è¦æœ€å¤§åŒ–æ¨èè¦†ç›–é¢çš„åœºæ™¯")
        report.append("")
        
        report.append(f"**æœ€å¼ºä¸€è‡´ç­–ç•¥**: {max_pair[0]} + {max_pair[1]}")
        report.append(f"- **Jaccardç›¸ä¼¼åº¦**: {max_jaccard:.4f}")  
        report.append(f"- **ç‰¹ç‚¹**: æ¨èé«˜åº¦ä¸€è‡´ï¼Œé£æ ¼ç›¸ä¼¼")
        report.append(f"- **é€‚ç”¨åœºæ™¯**: éœ€è¦ç¨³å®šå¯é æ¨èçš„åœºæ™¯")
        report.append("")
    
    # å¤šæ¨¡å‹ç»„åˆåˆ†æ
    if len(algorithms_list) >= 3:
        # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„å¹³å‡å¤šæ ·æ€§
        avg_diversities = {}
        for algo in algorithms_list:
            other_sims = [jaccard_matrix[algo][other] for other in algorithms_list if other != algo]
            avg_diversities[algo] = np.mean(other_sims)
        
        # æœ€å¤šæ ·åŒ–çš„3ä¸ªæ¨¡å‹
        most_diverse_3 = sorted(avg_diversities.items(), key=lambda x: x[1])[:3]
        
        report.append("### ğŸ¥ˆ å¤šæ ·åŒ–Teacherç»„åˆ")
        diverse_names = [algo for algo, _ in most_diverse_3]
        report.append(f"**æ¨èç»„åˆ**: {' + '.join(diverse_names)}")
        report.append("- **é€‰æ‹©ä¾æ®**: å¹³å‡ç›¸ä¼¼åº¦æœ€ä½çš„3ä¸ªæ¨¡å‹")
        report.append("- **ç‰¹ç‚¹**: å¹³è¡¡å¤šæ ·æ€§ä¸ç¨³å®šæ€§")
        report.append("")
    
    # å®æ–½å»ºè®®
    report.append("## ğŸš€ å®æ–½å»ºè®®")
    report.append("")
    report.append("### 1. Teacheræ¨¡å‹ç‰¹ç‚¹")
    report.append("- **deepfm**: ç‰¹å¾äº¤äº’å»ºæ¨¡ï¼Œé€‚åˆç¨€ç–ç‰¹å¾")
    report.append("- **autoint**: è‡ªåŠ¨ç‰¹å¾äº¤äº’ï¼Œæ³¨æ„åŠ›æœºåˆ¶")
    report.append("- **transformer4rec**: åºåˆ—å»ºæ¨¡ï¼Œé€‚åˆæ—¶åºæ¨è")
    report.append("- **xdeepfm**: æ˜¾å¼+éšå¼ç‰¹å¾äº¤äº’ï¼Œæ¨¡å‹å®¹é‡å¤§")
    report.append("")
    
    report.append("### 2. Ensembleç­–ç•¥")
    if min_pair:
        report.append(f"- **å¤šæ ·æ€§ä¼˜å…ˆ**: ä½¿ç”¨ {min_pair[0]} + {min_pair[1]} ç»„åˆ")
    if avg_jaccard < 0.3:
        report.append("- **ä½ä¸€è‡´æ€§**: å½“å‰æ¨¡å‹å·®å¼‚è¾ƒå¤§ï¼Œé€‚åˆensemble")
    elif avg_jaccard > 0.7:
        report.append("- **é«˜ä¸€è‡´æ€§**: æ¨¡å‹ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨å†—ä½™")
    else:
        report.append("- **ä¸­ç­‰ä¸€è‡´æ€§**: æ¨¡å‹é—´æœ‰ä¸€å®šå·®å¼‚ï¼Œensembleæ•ˆæœå¯æœŸ")
    report.append("")
    
    report.append("### 3. ä¼˜åŒ–æ–¹å‘")
    report.append("- **è®­ç»ƒä¼˜åŒ–**: å¢åŠ æ•°æ®é‡å’Œè®­ç»ƒè½®æ•°")
    report.append("- **ç¡¬ä»¶å‡çº§**: ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ")
    report.append("- **å‚æ•°è°ƒä¼˜**: é’ˆå¯¹ä¸åŒæ¨¡å‹ä¼˜åŒ–è¶…å‚æ•°")
    report.append("- **å®šæœŸæ›´æ–°**: é‡æ–°è¯„ä¼°æ¨¡å‹ä¸€è‡´æ€§")
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = "\n".join(report)
    
    with open("TEACHER_MODEL_ANALYSIS_REPORT.md", "w", encoding='utf-8') as f:
        f.write(report_content)
    
    print("âœ… Teacheræ¨¡å‹åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° TEACHER_MODEL_ANALYSIS_REPORT.md")
    
    # æ˜¾ç¤ºå…³é”®ç»“æœ
    print("\nğŸ‰ Teacheræ¨¡å‹ä¸€è‡´æ€§åˆ†æå®Œæˆï¼")
    print("\nğŸ“Š å…³é”®ç»“æœ:")
    print(f"ğŸ“ˆ æˆåŠŸè®­ç»ƒçš„Teacheræ¨¡å‹: {list(trained_models.keys())}")
    print(f"ğŸ“Š å¹³å‡Jaccardç›¸ä¼¼åº¦: {avg_jaccard:.4f}")
    
    if min_pair:
        print(f"ğŸ† æœ€ä½³äº’è¡¥ç»„åˆ: {min_pair[0]} + {min_pair[1]} (Jaccard={min_jaccard:.4f})")
    
    if max_pair:
        print(f"âš ï¸  æœ€ç›¸ä¼¼ç»„åˆ: {max_pair[0]} + {max_pair[1]} (Jaccard={max_jaccard:.4f})")
    
    # è¾“å‡ºä¸€è‡´æ€§çŸ©é˜µ
    print("\nğŸ“‹ Jaccardç›¸ä¼¼åº¦çŸ©é˜µ:")
    print("     ", end="")
    for algo in algorithms_list:
        print(f"{algo:>10}", end="")
    print()
    
    for algo1 in algorithms_list:
        print(f"{algo1:>8}", end="")
        for algo2 in algorithms_list:
            if algo1 == algo2:
                print(f"{'1.0000':>10}", end="")
            else:
                print(f"{jaccard_matrix[algo1][algo2]:>10.4f}", end="")
        print()
    
    return {
        'trained_models': list(trained_models.keys()),
        'jaccard_matrix': jaccard_matrix,
        'best_complementary': min_pair,
        'most_similar': max_pair,
        'avg_jaccard': avg_jaccard,
        'performance_stats': performance_stats
    }


if __name__ == "__main__":
    result = run_teacher_experiment()
    if result:
        print(f"\nâœ… å®éªŒæˆåŠŸå®Œæˆï¼è¯¦ç»†æŠ¥å‘Šè¯·æŸ¥çœ‹ TEACHER_MODEL_ANALYSIS_REPORT.md")
    else:
        print(f"\nâŒ å®éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
