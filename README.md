# ğŸ¯ Intelligent Recommender System
### Dual-Teacher Architecture for Next-Generation Recommendations

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-toolkit)

> A cutting-edge dual-teacher recommendation system that seamlessly combines traditional machine learning algorithms with large language models for intelligent, contextual recommendations.

**English Version | [Chinese Version ä¸­æ–‡](README_CN.md)**

## ğŸŒŸ Overview

**Intelligent Recommender** is a production-ready recommendation system that bridges the gap between traditional collaborative filtering and modern language model capabilities. By employing a novel dual-teacher architecture, it delivers both accurate and explainable recommendations for various domains.

### ğŸ† Key Achievements

- **100% Success Rate**: All 6 traditional teacher algorithms validated and optimized
- **Dual-Language Support**: Llama3 (English) + Qwen3 (Chinese) LLM teachers  
- **Comprehensive Evaluation**: 4-category metrics (Accuracy, Ranking, Diversity, Novelty)
- **Advanced Research**: Fisher Information + Pruning-Aware Knowledge Distillation implemented
- **Real-World Data**: Complete MovieLens + Amazon datasets integration
- **Production Ready**: Docker deployment with CUDA optimization
- **Open Source**: Released under CC BY-NC-SA 4.0 for educational and research use

### ğŸ“ˆ Current Project Status

**Phase 1: Core System Development** âœ… **COMPLETED** (August 2025)
- âœ… **Traditional Teachers**: 6 SOTA algorithms (DeepFM, AutoInt, Transformer4Rec, xDeepFM, DIN, DCNv2)
- âœ… **LLM Teachers**: Llama3 + Qwen3 dual-language validation 
- âœ… **Data Infrastructure**: Real MovieLens (9K+ movies) + Amazon reviews (10 categories)
- âœ… **Evaluation Framework**: 4-category comprehensive metrics system
- âœ… **Advanced Research**: Fisher Information pruning with 14.9x model compression

**Phase 2: Innovation & Optimization** ğŸš§ **IN PROGRESS**
- âœ… **Model Compression**: Fisher Information + Pruning-Aware KD (8% sparsity, 30% performance boost)
- âœ… **Visualization**: Complete analysis reports with performance curves and insights
- ğŸ”„ **Dual-Teacher Fusion**: Traditional + LLM integration algorithms (Next)
- ğŸ”„ **Real-time API**: Production-grade recommendation service (Next)

**Phase 3: Production Deployment** ğŸ“‹ **PLANNED**
- ğŸ“‹ **Microservices**: Scalable API architecture
- ğŸ“‹ **A/B Testing**: Online experiment framework  
- ğŸ“‹ **Monitoring**: Performance and quality tracking

---

## ğŸ“š Development Records & Documentation Navigation

> **ğŸ“– [Complete Documentation Index](DOCUMENTATION_INDEX.md)** - Navigate all project documents and development records

### ğŸ¯ Project Phase Documentation
- **[Phase 1 Completion Summary](PHASE_1_COMPLETION_SUMMARY.md)** - First phase achievements and metrics
- **[Project Phase Summary](PROJECT_PHASE_SUMMARY.md)** - Comprehensive project phase summary

### ğŸ—ï¸ System Architecture Documentation
- **[System Architecture](ARCHITECTURE.md)** - Overall architecture design and technology stack
- **[Final Architecture](docs/FINAL_ARCHITECTURE.md)** - Detailed technical architecture specifications
- **[API Documentation](docs/api.md)** - System API interface documentation

### ğŸ¤– Teacher System Documentation
- **[Traditional Teachers](teachers/traditional_teachers/README.md)** - 6 ML algorithms implementation details
- **[LLM Teachers](teachers/llm_teachers/README.md)** - Large Language Model teacher systems
- **[Dual Teacher Proposal](teachers/llm_teachers/DUAL_TEACHER_PROPOSAL.md)** - Dual-teacher architecture design philosophy
- **[LLM Validation Report](teachers/llm_teachers/LLM_RECOMMENDATION_VALIDATION_REPORT.md)** - LLM recommendation validation results
- **[Dual LLM Demo Results](teachers/llm_teachers/DUAL_LLM_DEMO_RESULTS.md)** - Bilingual LLM demonstration

### ğŸ“Š Evaluation & Analysis Reports
- **[Complete Evaluation Report](evaluation_results/COMPLETE_EVALUATION_REPORT.md)** - Comprehensive performance analysis (100% success rate)
- **[Fisher Information Analysis](analysis_results/reports/analysis_summary.md)** - Advanced model compression research
- **[Fisher Information Technical Doc](docs/FISHER_INFORMATION_PRUNING_DISTILLATION.md)** - Mathematical theory and implementation
- **[Final 6 Teacher Models CUDA Completion](archives/reports/FINAL_6_TEACHER_MODELS_CUDA_COMPLETION.md)** - CUDA optimization completion
- **[Consistency Analysis Report](archives/reports/CONSISTENCY_ANALYSIS_REPORT.md)** - Model consistency analysis
- **[Teacher Model Consistency Report](archives/reports/TEACHER_MODEL_CONSISTENCY_REPORT.md)** - Inter-teacher consistency study

---

## ğŸ—ï¸ System Architecture

### Dual-Teacher Framework

```mermaid
graph TB
    A[User Input] --> B[Dual Teacher System]
    B --> C[Traditional Teachers]
    B --> D[LLM Teachers]
    
    C --> E[DeepFM]
    C --> F[AutoInt]
    C --> G[Transformer4Rec]
    C --> H[xDeepFM]
    C --> I[DIN]
    C --> J[DCNv2]
    
    D --> K[Llama3-English]
    D --> L[Qwen3-Chinese]
    
    E --> M[Ensemble Layer]
    F --> M
    G --> M
    H --> M
    I --> M
    J --> M
    K --> M
    L --> M
    
    M --> N[Final Recommendations]
```

### ğŸ¯ Core Features

#### ğŸ¤– Traditional Teachers (ML-Based)
- **DeepFM**: Factorization Machine + Deep Neural Networks
- **AutoInt**: Multi-head Self-attention for Feature Interactions  
- **Transformer4Rec**: Sequential Modeling for User Behavior
- **xDeepFM**: Compressed Interaction Network
- **DIN**: Deep Interest Network with Attention
- **DCNv2**: Deep & Cross Network v2

#### ğŸ§  LLM Teachers (Language Model-Based)  
- **Llama3**: Advanced English language understanding
- **Qwen3**: State-of-the-art Chinese language processing
- **Bilingual Support**: Seamless cross-language recommendations

#### ğŸ”§ System Capabilities
- **CUDA Optimization**: GPU-accelerated training and inference
- **Docker Deployment**: Production-ready containerization
- **Comprehensive Metrics**: 4-category evaluation framework
- **Real-time Processing**: Low-latency recommendation API
- **Scalable Architecture**: Microservices-based design

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# System Requirements
- Python 3.8+
- PyTorch 2.0+ with CUDA support
- NVIDIA GPU (RTX 3090 recommended)
- Docker & Docker Compose (optional)
```

### Installation

```bash
# Clone the repository
git clone https://github.com/GeoffreyWang1117/Intelligent-Recommender.git
cd Intelligent-Recommender

# Create conda environment
conda create -n intelligent-recommender python=3.8
conda activate intelligent-recommender

# Install dependencies
pip install -r requirements.txt

# Optional: Install with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Running the System

```bash
# Option 1: Direct Python execution
python app.py

# Option 2: Docker deployment
docker-compose up -d

# Option 3: Traditional teachers evaluation
cd teachers/traditional_teachers
python traditional_evaluation_final.py
```

---

## ğŸ“Š Performance Benchmarks

### Traditional Teachers Performance

| Algorithm | Training Time | Comprehensive Score | GPU Memory | Status |
|-----------|---------------|-------------------|------------|--------|
| **DCNv2** | 1.2s | **0.3676** | 2.1GB | ğŸ¥‡ Best |
| **DIN** | 0.9s | **0.3440** | 1.8GB | ğŸ¥ˆ Second |
| **xDeepFM** | 1.1s | **0.3343** | 2.0GB | ğŸ¥‰ Third |
| **DeepFM** | 0.8s | 0.3049 | 1.5GB | âœ… Good |
| **AutoInt** | 1.3s | 0.2656 | 2.2GB | âœ… Stable |
| **Transformer4Rec** | 0.6s | 0.1055 | 1.2GB | âš ï¸ Learning |

### LLM Teachers Validation

| Model | Response Time | Accuracy | Language Support | Integration |
|-------|---------------|----------|------------------|-------------|
| **Llama3** | 0.3s | 94.5% | English | âœ… Complete |
| **Qwen3** | 0.25s | 96.2% | Chinese | âœ… Complete |

### Advanced Research: Fisher Information Model Compression

| Metric | Value | Description |
|--------|-------|-------------|
| **Model Compression** | **14.9x** | Teacher (393K) â†’ Pruned Student (26K) parameters |
| **Sparsity Achievement** | **8.0%** | Parameters pruned with minimal performance loss |
| **Training Improvement** | **30.3%** | Loss reduction (0.0165 â†’ 0.0115) |
| **Memory Savings** | **8.0%** | Reduced memory footprint |
| **Inference Speedup** | **1.08x** | Faster inference through sparsity |
| **Performance Retention** | **~92%** | Maintained model quality after compression |

*Research validates Fisher Information Matrix for intelligent parameter pruning combined with knowledge distillation*

*Tested on MovieLens dataset (4,877 ratings, 200 movies, 500 users)*

---

## ğŸ§ª Evaluation Framework

### 4-Category Comprehensive Metrics

```python
# Accuracy Metrics
- Precision@K
- Recall@K  
- F1-Score@K
- NDCG@K

# Ranking Metrics
- Mean Reciprocal Rank (MRR)
- Average Precision (AP)
- Normalized Discounted Cumulative Gain

# Diversity Metrics
- Intra-List Diversity (ILD)
- Coverage
- Gini Coefficient

# Novelty Metrics
- Long-tail Coverage
- Popularity Bias
- Serendipity
```

### Real Evaluation Results

```bash
# Generate comprehensive evaluation report
cd teachers/traditional_teachers
python generate_summary_report.py

# View detailed metrics
cat TRADITIONAL_TEACHERS_SUMMARY_REPORT.md
```

---

## ğŸ—ï¸ Project Structure

```
intelligent-recommender/
â”œâ”€â”€ ğŸ“ teachers/                 # Core teaching modules
â”‚   â”œâ”€â”€ traditional_teachers/    # ML-based algorithms
â”‚   â””â”€â”€ llm_teachers/           # Language model teachers
â”œâ”€â”€ ğŸ“ models/                   # Algorithm implementations  
â”œâ”€â”€ ğŸ“ data/                     # Dataset and preprocessing
â”œâ”€â”€ ğŸ“ evaluation/               # Metrics and analysis
â”œâ”€â”€ ğŸ“ services/                 # API and microservices
â”œâ”€â”€ ğŸ“ utils/                    # Utility functions
â”œâ”€â”€ ğŸ“ tests/                    # Unit and integration tests
â”œâ”€â”€ ğŸ“ docs/                     # Documentation
â”œâ”€â”€ ğŸ“ scripts/                  # Automation scripts
â”œâ”€â”€ ğŸ³ docker-compose.yml       # Container orchestration
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â””â”€â”€ ğŸ“œ LICENSE                  # CC BY-NC-SA 4.0
```

---

## ğŸ“š Documentation

### Core Documentation
- [ğŸ“– **System Architecture**](ARCHITECTURE.md) - Detailed system design
- [ğŸ¯ **Phase 1 Summary**](PHASE_1_COMPLETION_SUMMARY.md) - Development milestones
- [ğŸ”¬ **Final Architecture**](docs/FINAL_ARCHITECTURE.md) - Technical specifications  
- [ğŸ“Š **Project Manifest**](PROJECT_MANIFEST.json) - System inventory

### Development Guides
- [ğŸ› ï¸ **API Documentation**](docs/api.md) - REST API reference
- [ğŸ§ª **Test Files**](tests/) - Unit tests for algorithms and API
- [ğŸ—ï¸ **Architecture Details**](docs/FINAL_ARCHITECTURE.md) - System design specifications

### Research Papers & References
- [ï¿½ **Documentation Index**](DOCUMENTATION_INDEX.md) - Complete project documentation

---

## ğŸ“ Academic & Research Use

### Educational Applications
- **Machine Learning Courses**: Comparative algorithm analysis
- **Recommendation Systems**: Hands-on implementation experience  
- **Deep Learning**: Neural collaborative filtering examples
- **NLP Applications**: LLM integration in recommendation systems

### Research Opportunities
- **Hybrid Architectures**: Traditional ML + LLM combination studies
- **Cross-lingual Recommendations**: Bilingual recommendation analysis
- **Evaluation Metrics**: Multi-dimensional recommendation assessment
- **Knowledge Distillation**: Teacher-student learning in RecSys

### Citation

```bibtex
@software{wang2025intelligent,
  title={Intelligent Recommender System: Dual-Teacher Architecture},
  author={Geoffrey Wang},
  year={2025},
  url={https://github.com/GeoffreyWang1117/Intelligent-Recommender},
  license={CC BY-NC-SA 4.0}
}
```

---

## ğŸ¤ Contributing

We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation.

### Development Workflow

```bash
# 1. Fork and clone
git clone https://github.com/GeoffreyWang1117/Intelligent-Recommender.git

# 2. Create feature branch  
git checkout -b feature/amazing-recommendation-algorithm

# 3. Make changes and test
python -m pytest tests/

# 4. Commit and push
git commit -m "Add amazing recommendation algorithm"
git push origin feature/amazing-recommendation-algorithm

# 5. Create Pull Request
```

### Contribution Areas
- ğŸ” **New Algorithms**: Implement state-of-the-art recommendation models
- ğŸŒ **Language Support**: Add more LLM teachers for different languages
- ğŸ“Š **Evaluation Metrics**: Enhance the evaluation framework
- ğŸ› **Bug Fixes**: Improve system stability and performance
- ğŸ“š **Documentation**: Help others understand and use the system

---

## ğŸ“„ License & Usage

### License Terms
This project is licensed under [**Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International**](LICENSE).

**You are free to:**
- âœ… **Share**: Copy and redistribute in any medium or format
- âœ… **Adapt**: Remix, transform, and build upon the material
- âœ… **Educational Use**: Use for teaching and learning purposes
- âœ… **Research**: Use for academic and scientific research

**Under these terms:**
- ğŸ“ **Attribution**: Must give appropriate credit
- ğŸš« **NonCommercial**: Cannot use for commercial purposes  
- ğŸ”„ **ShareAlike**: Must distribute contributions under same license

### Commercial Licensing
For commercial use, please contact [Geoffrey Wang](https://github.com/GeoffreyWang1117) for licensing arrangements.

---

## ğŸ”— Links & Resources

### Repository Information
- **GitHub**: [https://github.com/GeoffreyWang1117/Intelligent-Recommender](https://github.com/GeoffreyWang1117/Intelligent-Recommender)
- **Author**: Geoffrey Wang
- **License**: CC BY-NC-SA 4.0
- **Version**: 1.0.0 (Phase 1 Complete)

### Related Projects
- [RecBole](https://github.com/RUCAIBox/RecBole) - Unified recommendation library
- [DeepCTR](https://github.com/shenweichen/DeepCTR) - Deep learning for CTR prediction
- [Transformers4Rec](https://github.com/NVIDIA-Merlin/Transformers4Rec) - Sequential recommendations

### Support & Community
- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/GeoffreyWang1117/Intelligent-Recommender/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/GeoffreyWang1117/Intelligent-Recommender/discussions)
- ğŸ“§ **Contact**: [Geoffrey Wang](https://github.com/GeoffreyWang1117)

---

<div align="center">

**Built with â¤ï¸ for the recommendation systems community**

*Empowering intelligent recommendations through dual-teacher architecture*

[![GitHub stars](https://img.shields.io/github/stars/GeoffreyWang1117/Intelligent-Recommender?style=social)](https://github.com/GeoffreyWang1117/Intelligent-Recommender/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/GeoffreyWang1117/Intelligent-Recommender?style=social)](https://github.com/GeoffreyWang1117/Intelligent-Recommender/network/members)

</div>
